{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_translate v4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emukans/en-lv-translator/blob/master/bert_translate_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgYAJIYFPm1T",
        "colab_type": "text"
      },
      "source": [
        "#Encode text embeddings with pre-trained BERT model using MS-COCO dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9HFhzFeKslp",
        "colab_type": "code",
        "outputId": "daf16d89-2bdd-4526-bf58-9a83387a0b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install 'gast==0.2.2'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=3d673093740ae0465f8edc364922e9dcb92a248239a4e81c86f0f67520dc2e0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc2 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMgIc2gqPgvV",
        "colab_type": "code",
        "outputId": "8647d9b7-5477-413c-81b9-faf6c4433bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# You'll generate plots of attention in order to see which parts of an image\n",
        "# our model focuses on during captioning\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn includes many helpful utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import collections\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjHg7d17FBoV",
        "colab_type": "code",
        "outputId": "95d7a4ad-3e54-4fe2-bc45-5d7e99631569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "tfe = tf.contrib.eager\n",
        "tfe.enable_eager_execution()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V8SOot7Jnel",
        "colab_type": "text"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNuHp0iMH0kU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "#   multi_cased_L-12_H-768_A-12: cased multilingual\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "\n",
        "LAYERS = [-1,-2,-3,-4]  # Take into account only last 4 layers\n",
        "NUM_TPU_CORES = 8\n",
        "MAX_SEQ_LENGTH = 128\n",
        "BERT_CONFIG = BERT_PRETRAINED_DIR + '/bert_config.json'\n",
        "CHKPT_DIR = BERT_PRETRAINED_DIR + '/bert_model.ckpt'\n",
        "VOCAB_FILE = BERT_PRETRAINED_DIR + '/vocab.txt'\n",
        "INIT_CHECKPOINT = BERT_PRETRAINED_DIR + '/bert_model.ckpt'\n",
        "BATCH_SIZE = 128\n",
        "MAX_DIMENSION = 768  # 1024 for Large model\n",
        "\n",
        "\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brrlmsMz16Eg",
        "colab_type": "text"
      },
      "source": [
        "##Prepare MS-COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKx_u0AP8qxM",
        "colab_type": "text"
      },
      "source": [
        "###Load BERT embeddings if exists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHPs7UfM7zjD",
        "colab_type": "code",
        "outputId": "504cb2f4-cfe3-4b57-ed32-c5f5ae06b091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR1MuYA2krdH",
        "colab_type": "text"
      },
      "source": [
        "###Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqKWrPuDZS0P",
        "colab_type": "code",
        "outputId": "d4144d37-5108-4ac6-8afe-cc8eb89a07a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# !gcloud auth application-default login\n",
        "# !gcloud auth login"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?code_challenge=CxH4dtw1B_3liWc1Lnttq-Ps-crA-fiD0U2wiFxuja8&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
            "\n",
            "\n",
            "Enter verification code: 4/yQH4CL0T6iVbjU0bsEqXkKU_kMrsa5Mvzq6Jh9S1lXg-R50JT9JsdZk\n",
            "\n",
            "You are now logged in as [eduardmukan@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNfKJAkBAcVJ",
        "colab_type": "code",
        "outputId": "2f756559-5d60-44ed-eb0c-afb8cb0132bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import zipfile\n",
        "\n",
        "!gsutil -m cp gs://translator-lv-en/annotations.zip annotations.zip\n",
        "\n",
        "with zipfile.ZipFile('annotations.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://translator-lv-en/annotations.zip...\n",
            "- [1/1 files][ 17.1 MiB/ 17.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/17.1 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7S8oYCLpYEM",
        "colab_type": "text"
      },
      "source": [
        "###Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E204u4sw7Hsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_en_annotations = []\n",
        "annotation_en_file = 'annotations/annotations.en'\n",
        "with open(annotation_en_file, 'r') as f:\n",
        "    raw_en_annotations = f.readlines()\n",
        "\n",
        "def prepare_caption(caption: str):\n",
        "  return f'<start> {caption.strip()} <end>'\n",
        "\n",
        "prepared_en_caption_list = shuffle(raw_en_annotations, random_state=1)\n",
        "prepared_en_caption_list = [prepare_caption(caption) for caption in prepared_en_caption_list]\n",
        "\n",
        "raw_lv_annotations = []\n",
        "annotation_lv_file = 'annotations/annotations.lv'\n",
        "with open(annotation_lv_file, 'r') as f:\n",
        "    raw_lv_annotations = f.readlines()\n",
        "\n",
        "prepared_lv_caption_list = shuffle(raw_lv_annotations, random_state=1)\n",
        "prepared_lv_caption_list = [prepare_caption(caption) for caption in prepared_lv_caption_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V72cwi6pC-T",
        "colab_type": "code",
        "outputId": "4ad6d2c8-3cd2-411b-9eb7-f8727a106ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(prepared_en_caption_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "591823"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F3_z7wszY0D",
        "colab_type": "text"
      },
      "source": [
        "##Prepare BERT pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEqzjKCk6BeD",
        "colab_type": "code",
        "outputId": "8c403dc2-c595-45f0-de48-922afb9ffc06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/32/e3d405806ea525fd74c2c79164c3f7bc0b0b9811f27990484c6d6874c76f/sentence-transformers-0.2.5.1.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hCollecting transformers==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 19.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (1.12.31)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->sentence-transformers) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.9.5)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (1.15.31)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers==2.3.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers==2.3.0->sentence-transformers) (2.8.1)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.5.1-cp36-none-any.whl size=67076 sha256=50f3fbb2170501a0e5baea0b6a554d499841d23090f206919521980f030f25fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/ca/b4/7ca542b411730a8840f8e090df2ddacffa1c4dd9f209684c19\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=0598c9d02a5d003cf1f6c45a81ddec6d2ab3030cabb4036dfcd4af2804768a1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.38 sentence-transformers-0.2.5.1 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ujc6MhX6PN5",
        "colab_type": "code",
        "outputId": "ab680c72-caf7-49a4-db53-98524639c96c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:19<00:00, 20.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2jKY2Z56Vxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embeddings1 = model.encode(prepared_en_caption_list[:100000])\n",
        "np.save('gdrive/My Drive/bert_translate/word_embeddings_batch1', word_embeddings1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXmrqKhvIvgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embeddings2 = model.encode(prepared_en_caption_list[100000:200000])\n",
        "np.save('gdrive/My Drive/bert_translate/word_embeddings_batch2', word_embeddings2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "434Urc7yIv5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embeddings3 = model.encode(prepared_en_caption_list[200000:300000])\n",
        "np.save('gdrive/My Drive/bert_translate/word_embeddings_batch3', word_embeddings3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_tEf4QIwUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embeddings4 = model.encode(prepared_en_caption_list[300000:400000])\n",
        "np.save('gdrive/My Drive/bert_translate/word_embeddings_batch4', word_embeddings4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMkXYKaJVUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embeddings5 = model.encode(prepared_en_caption_list[400000:500000])\n",
        "np.save('gdrive/My Drive/bert_translate/word_embeddings_batch5', word_embeddings5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rs6t64LJaOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embeddings6 = model.encode(prepared_en_caption_list[500000:])\n",
        "np.save('gdrive/My Drive/bert_translate/word_embeddings_batch6', word_embeddings6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlAXnl3W9AJM",
        "colab_type": "text"
      },
      "source": [
        "##Part from image captioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxM6-bFF_hxU",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess and tokenize the captions\n",
        "\n",
        "* First, you'll tokenize the captions (for example, by splitting on spaces). This gives us a  vocabulary of all of the unique words in the data (for example, \"surfing\", \"football\", and so on).\n",
        "* Next, you'll limit the vocabulary size to the top 5,000 words (to save memory). You'll replace all other words with the token \"UNK\" (unknown).\n",
        "* You then create word-to-index and index-to-word mappings.\n",
        "* Finally, you pad all sequences to be the same length as the longest one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21WTFvKVVZh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the maximum length of any caption in our dataset\n",
        "def calc_max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW-_pYk9_kB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose the top 5000 words from the vocabulary\n",
        "top_k = 5000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
        "                                                  oov_token=\"<unk>\",\n",
        "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
        "tokenizer.fit_on_texts(prepared_en_caption_list)\n",
        "train_seqs = tokenizer.texts_to_sequences(prepared_en_caption_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGjZO8S24qyO",
        "colab_type": "code",
        "outputId": "063d7a8a-22fc-4018-ac54-951711ca9044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokenizer.word_counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJTsm09_ABze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.word_index['<pad>'] = 0\n",
        "tokenizer.index_word[0] = '<pad>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qox-81CAICv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the tokenized vectors\n",
        "train_seqs = tokenizer.texts_to_sequences(prepared_en_caption_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xjjXPVwAQjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad each vector to the max_length of the captions\n",
        "# If you do not provide a max_length value, pad_sequences calculates it automatically\n",
        "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLTtLYrdAYRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculates the max_length, which is used to store the attention weights\n",
        "max_length = calc_max_length(train_seqs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDiwVh9fAhob",
        "colab_type": "text"
      },
      "source": [
        "## Split the data into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKk6NKuVAcET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training and validation sets using an 80-20 split\n",
        "word_train, word_val, cap_train, cap_val = train_test_split(word_embeddings,\n",
        "                                                                    cap_vector,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C-TqxuTBOU1",
        "colab_type": "code",
        "outputId": "587a0a5e-6127-48b6-cdbf-2022d5f3a838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(word_train), len(cap_train), len(word_val), len(cap_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 800, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orwnJYuhBXeW",
        "colab_type": "text"
      },
      "source": [
        "## Create a tf.data dataset for training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ka6nblcBT_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "vocab_size = top_k + 1\n",
        "num_steps = len(word_train) // BATCH_SIZE\n",
        "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
        "# These two variables represent that vector shape\n",
        "features_shape = 768\n",
        "# attention_features_shape = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3WLH4xCdep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((word_train, cap_train))\n",
        "\n",
        "# Shuffle and batch\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-bUXGteC0mB",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "Fun fact: the decoder below is identical to the one in the example for [Neural Machine Translation with Attention](../sequences/nmt_with_attention.ipynb).\n",
        "\n",
        "The model architecture is inspired by the [Show, Attend and Tell](https://arxiv.org/pdf/1502.03044.pdf) paper.\n",
        "\n",
        "* In this example, you extract the features from the lower convolutional layer of InceptionV3 giving us a vector of shape (8, 8, 2048).\n",
        "* You squash that to a shape of (64, 2048).\n",
        "* This vector is then passed through the CNN Encoder (which consists of a single Fully connected layer).\n",
        "* The RNN (here GRU) attends over the image to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg7eu-h1CuzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, features, hidden):\n",
        "    # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
        "\n",
        "    # hidden shape == (batch_size, hidden_size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "\n",
        "    # score shape == (batch_size, 64, hidden_size)\n",
        "    score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "    # attention_weights shape == (batch_size, 64, 1)\n",
        "    # you get 1 at the last axis because you are applying score to self.V\n",
        "    attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * features\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3YR7EUTCyJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_Encoder(tf.keras.Model):\n",
        "    # Since you have already extracted the features and dumped it using pickle\n",
        "    # This encoder passes those features through a Fully connected layer\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "        # shape after fc == (batch_size, 64, embedding_dim)\n",
        "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDm_yqAGC5vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN_Decoder(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units, vocab_size):\n",
        "    super(RNN_Decoder, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc1 = tf.keras.layers.Dense(self.units)\n",
        "    self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    self.attention = BahdanauAttention(self.units)\n",
        "\n",
        "  def call(self, x, features, hidden):\n",
        "    # defining attention as a separate model\n",
        "    context_vector, attention_weights = self.attention(features, hidden)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # shape == (batch_size, max_length, hidden_size)\n",
        "    x = self.fc1(output)\n",
        "\n",
        "    # x shape == (batch_size * max_length, hidden_size)\n",
        "    x = tf.reshape(x, (-1, x.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size * max_length, vocab)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "    # return x, state\n",
        "\n",
        "  def reset_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, self.units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws0dM0TiC8Q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = CNN_Encoder(embedding_dim)\n",
        "decoder = RNN_Decoder(embedding_dim, units, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGg5GdPMC-Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h94W251DF1D",
        "colab_type": "text"
      },
      "source": [
        "## Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V781__hUDBGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./gdrive/My Drive/bert_translate/checkpoints/train\"\n",
        "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
        "                           decoder=decoder,\n",
        "                           optimizer = optimizer)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji3VrermDIcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_epoch = 0\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
        "  # restoring the latest checkpoint in checkpoint_path\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6pZoO-aDNUV",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "* You extract the features stored in the respective `.npy` files and then pass those features through the encoder.\n",
        "* The encoder output, hidden state(initialized to 0) and the decoder input (which is the start token) is passed to the decoder.\n",
        "* The decoder returns the predictions and the decoder hidden state.\n",
        "* The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "* Use teacher forcing to decide the next input to the decoder.\n",
        "* Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
        "* The final step is to calculate the gradients and apply it to the optimizer and backpropagate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgd67c3CDKom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding this in a separate cell because if you run the training cell\n",
        "# many times, the loss_plot array will be reset\n",
        "loss_plot = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObDxVa6iDPu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(img_tensor, target):\n",
        "  loss = 0\n",
        "\n",
        "  # initializing the hidden state for each batch\n",
        "  # because the captions are not related from image to image\n",
        "  hidden = decoder.reset_state(batch_size=target.shape[0])\n",
        "\n",
        "  dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "      features = encoder(img_tensor)\n",
        "\n",
        "      for i in range(1, target.shape[1]):\n",
        "          # passing the features through the decoder\n",
        "          predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
        "          loss += loss_function(target[:, i], predictions)\n",
        "\n",
        "          # using teacher forcing\n",
        "          dec_input = tf.expand_dims(target[:, i], 1)\n",
        "\n",
        "  total_loss = (loss / int(target.shape[1]))\n",
        "\n",
        "  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "  return loss, total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P620ZDiKT8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_annotation(img_tensor):\n",
        "  img_tensor = tf.expand_dims(img_tensor, 0)\n",
        "  features = encoder(img_tensor)\n",
        "  hidden = decoder.reset_state(batch_size=1)\n",
        "  dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
        "  result = []\n",
        "  for i in range(max_length):\n",
        "    predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
        "    predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
        "\n",
        "    result.append(tokenizer.index_word[predicted_id])\n",
        "\n",
        "    if tokenizer.index_word[predicted_id] == '<end>':\n",
        "        return result\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ56jA-nDUg1",
        "colab_type": "code",
        "outputId": "c3079a14-64ea-42d2-ad73-b5a3609a076b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "    last_tensor = None\n",
        "    last_target = None\n",
        "\n",
        "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
        "        last_tensor = img_tensor\n",
        "        last_target = target\n",
        "        batch_loss, t_loss = train_step(img_tensor, target)\n",
        "        total_loss += t_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "              epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
        "    # storing the epoch end loss value to plot later\n",
        "    loss_plot.append(total_loss / num_steps)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print('Real:')\n",
        "      print(' '.join([tokenizer.index_word[predicted_id.numpy()] for predicted_id in last_target[-1]]))\n",
        "      print('Predicted:')\n",
        "      print(' '.join(evaluate_annotation(last_tensor[-1])))\n",
        "      ckpt_manager.save()\n",
        "\n",
        "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
        "                                         total_loss/num_steps))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 Batch 0 Loss 2.3226\n",
            "Epoch 2 Loss 2.389612\n",
            "Time taken for 1 epoch 122.62391757965088 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.2076\n",
            "Epoch 3 Loss 2.247705\n",
            "Time taken for 1 epoch 5.440316200256348 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.1104\n",
            "Epoch 4 Loss 2.138435\n",
            "Time taken for 1 epoch 5.437166452407837 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.0462\n",
            "Epoch 5 Loss 2.065433\n",
            "Time taken for 1 epoch 5.525684118270874 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.9628\n",
            "Epoch 6 Loss 2.007074\n",
            "Time taken for 1 epoch 5.565618276596069 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.9207\n",
            "Epoch 7 Loss 1.954520\n",
            "Time taken for 1 epoch 5.47625994682312 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.8632\n",
            "Epoch 8 Loss 1.897700\n",
            "Time taken for 1 epoch 5.504452228546143 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.8115\n",
            "Epoch 9 Loss 1.845598\n",
            "Time taken for 1 epoch 5.551137924194336 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.7575\n",
            "Epoch 10 Loss 1.789579\n",
            "Time taken for 1 epoch 5.736809253692627 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 1.7078\n",
            "Epoch 11 Loss 1.739188\n",
            "Time taken for 1 epoch 5.587237119674683 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 1.6776\n",
            "Epoch 12 Loss 1.699115\n",
            "Time taken for 1 epoch 5.6137754917144775 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 1.6143\n",
            "Epoch 13 Loss 1.636268\n",
            "Time taken for 1 epoch 5.668812990188599 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 1.5404\n",
            "Epoch 14 Loss 1.599736\n",
            "Time taken for 1 epoch 5.669038772583008 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 1.5611\n",
            "Epoch 15 Loss 1.572698\n",
            "Time taken for 1 epoch 5.611490726470947 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 1.4858\n",
            "Epoch 16 Loss 1.521954\n",
            "Time taken for 1 epoch 5.631035566329956 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 1.4410\n",
            "Epoch 17 Loss 1.489442\n",
            "Time taken for 1 epoch 6.474038124084473 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 1.4734\n",
            "Epoch 18 Loss 1.477979\n",
            "Time taken for 1 epoch 6.181876182556152 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 1.4325\n",
            "Epoch 19 Loss 1.420334\n",
            "Time taken for 1 epoch 5.4877917766571045 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 1.4437\n",
            "Epoch 20 Loss 1.405378\n",
            "Time taken for 1 epoch 6.898774147033691 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 1.3385\n",
            "Epoch 21 Loss 1.367537\n",
            "Time taken for 1 epoch 7.052034378051758 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 1.3409\n",
            "Epoch 22 Loss 1.371025\n",
            "Time taken for 1 epoch 5.506286144256592 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 1.2907\n",
            "Epoch 23 Loss 1.358736\n",
            "Time taken for 1 epoch 5.590533256530762 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 1.2427\n",
            "Epoch 24 Loss 1.302841\n",
            "Time taken for 1 epoch 5.480007171630859 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 1.2399\n",
            "Epoch 25 Loss 1.277394\n",
            "Time taken for 1 epoch 5.524686098098755 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 1.1893\n",
            "Epoch 26 Loss 1.257769\n",
            "Time taken for 1 epoch 5.544147729873657 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 1.4115\n",
            "Epoch 27 Loss 1.282799\n",
            "Time taken for 1 epoch 5.459886789321899 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 1.1898\n",
            "Epoch 28 Loss 1.245430\n",
            "Time taken for 1 epoch 5.511971712112427 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 1.2142\n",
            "Epoch 29 Loss 1.230461\n",
            "Time taken for 1 epoch 5.486684083938599 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 1.2424\n",
            "Epoch 30 Loss 1.239379\n",
            "Time taken for 1 epoch 5.589491605758667 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 1.2109\n",
            "Epoch 31 Loss 1.220168\n",
            "Time taken for 1 epoch 5.475905418395996 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 1.1866\n",
            "Epoch 32 Loss 1.211505\n",
            "Time taken for 1 epoch 5.49894905090332 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 1.1504\n",
            "Epoch 33 Loss 1.203421\n",
            "Time taken for 1 epoch 5.446475028991699 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 1.1229\n",
            "Epoch 34 Loss 1.174507\n",
            "Time taken for 1 epoch 5.477711915969849 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 1.0577\n",
            "Epoch 35 Loss 1.136441\n",
            "Time taken for 1 epoch 5.52607536315918 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 1.1441\n",
            "Epoch 36 Loss 1.151492\n",
            "Time taken for 1 epoch 5.492510080337524 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 1.0713\n",
            "Epoch 37 Loss 1.142649\n",
            "Time taken for 1 epoch 5.562091827392578 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 1.0747\n",
            "Epoch 38 Loss 1.140623\n",
            "Time taken for 1 epoch 5.542486906051636 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 1.0550\n",
            "Epoch 39 Loss 1.126534\n",
            "Time taken for 1 epoch 5.5642547607421875 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 1.0719\n",
            "Epoch 40 Loss 1.104897\n",
            "Time taken for 1 epoch 5.5119664669036865 sec\n",
            "\n",
            "Epoch 41 Batch 0 Loss 1.0418\n",
            "Epoch 41 Loss 1.087553\n",
            "Time taken for 1 epoch 5.54331636428833 sec\n",
            "\n",
            "Epoch 42 Batch 0 Loss 1.0358\n",
            "Epoch 42 Loss 1.061625\n",
            "Time taken for 1 epoch 5.530118942260742 sec\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.9830\n",
            "Epoch 43 Loss 1.052091\n",
            "Time taken for 1 epoch 5.573117733001709 sec\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.9778\n",
            "Epoch 44 Loss 1.071517\n",
            "Time taken for 1 epoch 5.506802320480347 sec\n",
            "\n",
            "Epoch 45 Batch 0 Loss 1.0097\n",
            "Epoch 45 Loss 1.038158\n",
            "Time taken for 1 epoch 5.546265363693237 sec\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.9364\n",
            "Epoch 46 Loss 1.015932\n",
            "Time taken for 1 epoch 6.173994541168213 sec\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.9439\n",
            "Epoch 47 Loss 1.035251\n",
            "Time taken for 1 epoch 5.496503829956055 sec\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.9510\n",
            "Epoch 48 Loss 1.037951\n",
            "Time taken for 1 epoch 5.483561754226685 sec\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.9176\n",
            "Epoch 49 Loss 1.019194\n",
            "Time taken for 1 epoch 5.440216541290283 sec\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.9055\n",
            "Epoch 50 Loss 0.978189\n",
            "Time taken for 1 epoch 5.438713312149048 sec\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.9047\n",
            "Epoch 51 Loss 0.951031\n",
            "Time taken for 1 epoch 5.473463296890259 sec\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.8963\n",
            "Epoch 52 Loss 0.941746\n",
            "Time taken for 1 epoch 5.470929145812988 sec\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.8735\n",
            "Epoch 53 Loss 0.920553\n",
            "Time taken for 1 epoch 5.52702522277832 sec\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.8445\n",
            "Epoch 54 Loss 0.923895\n",
            "Time taken for 1 epoch 5.52959418296814 sec\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.9244\n",
            "Epoch 55 Loss 0.935028\n",
            "Time taken for 1 epoch 5.430898904800415 sec\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.8828\n",
            "Epoch 56 Loss 0.925121\n",
            "Time taken for 1 epoch 5.514386177062988 sec\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.8214\n",
            "Epoch 57 Loss 0.923763\n",
            "Time taken for 1 epoch 5.447874307632446 sec\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.9031\n",
            "Epoch 58 Loss 0.986549\n",
            "Time taken for 1 epoch 5.450433731079102 sec\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.8720\n",
            "Epoch 59 Loss 0.999219\n",
            "Time taken for 1 epoch 5.474066734313965 sec\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.9056\n",
            "Epoch 60 Loss 1.012136\n",
            "Time taken for 1 epoch 5.496474742889404 sec\n",
            "\n",
            "Epoch 61 Batch 0 Loss 0.8896\n",
            "Epoch 61 Loss 0.966046\n",
            "Time taken for 1 epoch 5.443329572677612 sec\n",
            "\n",
            "Epoch 62 Batch 0 Loss 0.9580\n",
            "Epoch 62 Loss 0.916341\n",
            "Time taken for 1 epoch 5.438553333282471 sec\n",
            "\n",
            "Epoch 63 Batch 0 Loss 0.7791\n",
            "Epoch 63 Loss 0.896375\n",
            "Time taken for 1 epoch 5.40442681312561 sec\n",
            "\n",
            "Epoch 64 Batch 0 Loss 0.7762\n",
            "Epoch 64 Loss 0.857052\n",
            "Time taken for 1 epoch 5.4773242473602295 sec\n",
            "\n",
            "Epoch 65 Batch 0 Loss 0.7685\n",
            "Epoch 65 Loss 0.836509\n",
            "Time taken for 1 epoch 5.480729103088379 sec\n",
            "\n",
            "Epoch 66 Batch 0 Loss 0.7466\n",
            "Epoch 66 Loss 0.829873\n",
            "Time taken for 1 epoch 5.49010705947876 sec\n",
            "\n",
            "Epoch 67 Batch 0 Loss 0.7158\n",
            "Epoch 67 Loss 0.805620\n",
            "Time taken for 1 epoch 5.554333686828613 sec\n",
            "\n",
            "Epoch 68 Batch 0 Loss 0.7391\n",
            "Epoch 68 Loss 0.792993\n",
            "Time taken for 1 epoch 5.409971237182617 sec\n",
            "\n",
            "Epoch 69 Batch 0 Loss 0.7250\n",
            "Epoch 69 Loss 0.795353\n",
            "Time taken for 1 epoch 5.411401033401489 sec\n",
            "\n",
            "Epoch 70 Batch 0 Loss 0.7089\n",
            "Epoch 70 Loss 0.779249\n",
            "Time taken for 1 epoch 5.508566379547119 sec\n",
            "\n",
            "Epoch 71 Batch 0 Loss 0.7048\n",
            "Epoch 71 Loss 0.768406\n",
            "Time taken for 1 epoch 5.502521276473999 sec\n",
            "\n",
            "Epoch 72 Batch 0 Loss 0.6774\n",
            "Epoch 72 Loss 0.748997\n",
            "Time taken for 1 epoch 5.7035746574401855 sec\n",
            "\n",
            "Epoch 73 Batch 0 Loss 0.6708\n",
            "Epoch 73 Loss 0.741714\n",
            "Time taken for 1 epoch 6.342283010482788 sec\n",
            "\n",
            "Epoch 74 Batch 0 Loss 0.7160\n",
            "Epoch 74 Loss 0.758557\n",
            "Time taken for 1 epoch 5.916338205337524 sec\n",
            "\n",
            "Epoch 75 Batch 0 Loss 0.7016\n",
            "Epoch 75 Loss 0.821176\n",
            "Time taken for 1 epoch 5.517160654067993 sec\n",
            "\n",
            "Epoch 76 Batch 0 Loss 0.7014\n",
            "Epoch 76 Loss 0.818804\n",
            "Time taken for 1 epoch 5.492408514022827 sec\n",
            "\n",
            "Epoch 77 Batch 0 Loss 0.7497\n",
            "Epoch 77 Loss 0.799712\n",
            "Time taken for 1 epoch 5.457824230194092 sec\n",
            "\n",
            "Epoch 78 Batch 0 Loss 0.6668\n",
            "Epoch 78 Loss 0.765122\n",
            "Time taken for 1 epoch 5.432562351226807 sec\n",
            "\n",
            "Epoch 79 Batch 0 Loss 0.6875\n",
            "Epoch 79 Loss 0.729525\n",
            "Time taken for 1 epoch 5.482558965682983 sec\n",
            "\n",
            "Epoch 80 Batch 0 Loss 0.6044\n",
            "Epoch 80 Loss 0.688697\n",
            "Time taken for 1 epoch 5.420167922973633 sec\n",
            "\n",
            "Epoch 81 Batch 0 Loss 0.6270\n",
            "Epoch 81 Loss 0.662635\n",
            "Time taken for 1 epoch 5.4825215339660645 sec\n",
            "\n",
            "Epoch 82 Batch 0 Loss 0.5896\n",
            "Epoch 82 Loss 0.651405\n",
            "Time taken for 1 epoch 5.434046983718872 sec\n",
            "\n",
            "Epoch 83 Batch 0 Loss 0.5840\n",
            "Epoch 83 Loss 0.644831\n",
            "Time taken for 1 epoch 5.486709833145142 sec\n",
            "\n",
            "Epoch 84 Batch 0 Loss 0.6029\n",
            "Epoch 84 Loss 0.660443\n",
            "Time taken for 1 epoch 5.423377275466919 sec\n",
            "\n",
            "Epoch 85 Batch 0 Loss 0.5832\n",
            "Epoch 85 Loss 0.651056\n",
            "Time taken for 1 epoch 5.456414222717285 sec\n",
            "\n",
            "Epoch 86 Batch 0 Loss 0.5918\n",
            "Epoch 86 Loss 0.655862\n",
            "Time taken for 1 epoch 5.441965103149414 sec\n",
            "\n",
            "Epoch 87 Batch 0 Loss 0.5751\n",
            "Epoch 87 Loss 0.658760\n",
            "Time taken for 1 epoch 5.4229583740234375 sec\n",
            "\n",
            "Epoch 88 Batch 0 Loss 0.6201\n",
            "Epoch 88 Loss 0.659921\n",
            "Time taken for 1 epoch 5.476428031921387 sec\n",
            "\n",
            "Epoch 89 Batch 0 Loss 0.5805\n",
            "Epoch 89 Loss 0.637823\n",
            "Time taken for 1 epoch 5.483991384506226 sec\n",
            "\n",
            "Epoch 90 Batch 0 Loss 0.5888\n",
            "Epoch 90 Loss 0.623252\n",
            "Time taken for 1 epoch 5.645835876464844 sec\n",
            "\n",
            "Epoch 91 Batch 0 Loss 0.5785\n",
            "Epoch 91 Loss 0.589584\n",
            "Time taken for 1 epoch 5.5713465213775635 sec\n",
            "\n",
            "Epoch 92 Batch 0 Loss 0.5181\n",
            "Epoch 92 Loss 0.570314\n",
            "Time taken for 1 epoch 5.5491719245910645 sec\n",
            "\n",
            "Epoch 93 Batch 0 Loss 0.5286\n",
            "Epoch 93 Loss 0.560412\n",
            "Time taken for 1 epoch 5.52925705909729 sec\n",
            "\n",
            "Epoch 94 Batch 0 Loss 0.5074\n",
            "Epoch 94 Loss 0.561314\n",
            "Time taken for 1 epoch 5.555715322494507 sec\n",
            "\n",
            "Epoch 95 Batch 0 Loss 0.5361\n",
            "Epoch 95 Loss 0.560861\n",
            "Time taken for 1 epoch 5.554748058319092 sec\n",
            "\n",
            "Epoch 96 Batch 0 Loss 0.5243\n",
            "Epoch 96 Loss 0.554610\n",
            "Time taken for 1 epoch 5.6544554233551025 sec\n",
            "\n",
            "Epoch 97 Batch 0 Loss 0.5372\n",
            "Epoch 97 Loss 0.536759\n",
            "Time taken for 1 epoch 5.578596353530884 sec\n",
            "\n",
            "Epoch 98 Batch 0 Loss 0.5329\n",
            "Epoch 98 Loss 0.529587\n",
            "Time taken for 1 epoch 5.574203968048096 sec\n",
            "\n",
            "Epoch 99 Batch 0 Loss 0.5325\n",
            "Epoch 99 Loss 0.526198\n",
            "Time taken for 1 epoch 5.535218954086304 sec\n",
            "\n",
            "Epoch 100 Batch 0 Loss 0.4733\n",
            "Epoch 100 Loss 0.533542\n",
            "Time taken for 1 epoch 5.515287160873413 sec\n",
            "\n",
            "Epoch 101 Batch 0 Loss 0.4784\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "outside flying outside tiles tiles tiles and cows outside tiles tiles and tiles and tiles tiles and big tiles and tiles and tiles outside\n",
            "Epoch 101 Loss 0.526656\n",
            "Time taken for 1 epoch 6.757699251174927 sec\n",
            "\n",
            "Epoch 102 Batch 0 Loss 0.5466\n",
            "Epoch 102 Loss 0.536230\n",
            "Time taken for 1 epoch 5.722743511199951 sec\n",
            "\n",
            "Epoch 103 Batch 0 Loss 0.5243\n",
            "Epoch 103 Loss 0.538276\n",
            "Time taken for 1 epoch 5.514040231704712 sec\n",
            "\n",
            "Epoch 104 Batch 0 Loss 0.5155\n",
            "Epoch 104 Loss 0.524432\n",
            "Time taken for 1 epoch 5.516216516494751 sec\n",
            "\n",
            "Epoch 105 Batch 0 Loss 0.4851\n",
            "Epoch 105 Loss 0.513525\n",
            "Time taken for 1 epoch 5.547703266143799 sec\n",
            "\n",
            "Epoch 106 Batch 0 Loss 0.5098\n",
            "Epoch 106 Loss 0.494062\n",
            "Time taken for 1 epoch 5.503193616867065 sec\n",
            "\n",
            "Epoch 107 Batch 0 Loss 0.4656\n",
            "Epoch 107 Loss 0.484065\n",
            "Time taken for 1 epoch 5.525904417037964 sec\n",
            "\n",
            "Epoch 108 Batch 0 Loss 0.4279\n",
            "Epoch 108 Loss 0.462313\n",
            "Time taken for 1 epoch 5.585083484649658 sec\n",
            "\n",
            "Epoch 109 Batch 0 Loss 0.4506\n",
            "Epoch 109 Loss 0.453975\n",
            "Time taken for 1 epoch 5.596198797225952 sec\n",
            "\n",
            "Epoch 110 Batch 0 Loss 0.4492\n",
            "Epoch 110 Loss 0.446330\n",
            "Time taken for 1 epoch 5.5328168869018555 sec\n",
            "\n",
            "Epoch 111 Batch 0 Loss 0.4230\n",
            "Epoch 111 Loss 0.443767\n",
            "Time taken for 1 epoch 5.462429046630859 sec\n",
            "\n",
            "Epoch 112 Batch 0 Loss 0.4016\n",
            "Epoch 112 Loss 0.423733\n",
            "Time taken for 1 epoch 5.542312860488892 sec\n",
            "\n",
            "Epoch 113 Batch 0 Loss 0.3941\n",
            "Epoch 113 Loss 0.437114\n",
            "Time taken for 1 epoch 5.540508031845093 sec\n",
            "\n",
            "Epoch 114 Batch 0 Loss 0.3959\n",
            "Epoch 114 Loss 0.445325\n",
            "Time taken for 1 epoch 5.593509674072266 sec\n",
            "\n",
            "Epoch 115 Batch 0 Loss 0.4431\n",
            "Epoch 115 Loss 0.475372\n",
            "Time taken for 1 epoch 5.502270698547363 sec\n",
            "\n",
            "Epoch 116 Batch 0 Loss 0.4723\n",
            "Epoch 116 Loss 0.479944\n",
            "Time taken for 1 epoch 5.4880523681640625 sec\n",
            "\n",
            "Epoch 117 Batch 0 Loss 0.4798\n",
            "Epoch 117 Loss 0.473503\n",
            "Time taken for 1 epoch 5.544113636016846 sec\n",
            "\n",
            "Epoch 118 Batch 0 Loss 0.4430\n",
            "Epoch 118 Loss 0.458237\n",
            "Time taken for 1 epoch 5.497647523880005 sec\n",
            "\n",
            "Epoch 119 Batch 0 Loss 0.4139\n",
            "Epoch 119 Loss 0.432937\n",
            "Time taken for 1 epoch 5.459644079208374 sec\n",
            "\n",
            "Epoch 120 Batch 0 Loss 0.3816\n",
            "Epoch 120 Loss 0.407411\n",
            "Time taken for 1 epoch 5.498488426208496 sec\n",
            "\n",
            "Epoch 121 Batch 0 Loss 0.3755\n",
            "Epoch 121 Loss 0.393358\n",
            "Time taken for 1 epoch 5.4691643714904785 sec\n",
            "\n",
            "Epoch 122 Batch 0 Loss 0.3592\n",
            "Epoch 122 Loss 0.379784\n",
            "Time taken for 1 epoch 5.518771171569824 sec\n",
            "\n",
            "Epoch 123 Batch 0 Loss 0.3460\n",
            "Epoch 123 Loss 0.376907\n",
            "Time taken for 1 epoch 5.508905649185181 sec\n",
            "\n",
            "Epoch 124 Batch 0 Loss 0.3370\n",
            "Epoch 124 Loss 0.372245\n",
            "Time taken for 1 epoch 5.465161561965942 sec\n",
            "\n",
            "Epoch 125 Batch 0 Loss 0.3466\n",
            "Epoch 125 Loss 0.364435\n",
            "Time taken for 1 epoch 5.5446107387542725 sec\n",
            "\n",
            "Epoch 126 Batch 0 Loss 0.3732\n",
            "Epoch 126 Loss 0.358662\n",
            "Time taken for 1 epoch 5.480636358261108 sec\n",
            "\n",
            "Epoch 127 Batch 0 Loss 0.3670\n",
            "Epoch 127 Loss 0.362471\n",
            "Time taken for 1 epoch 5.558274507522583 sec\n",
            "\n",
            "Epoch 128 Batch 0 Loss 0.3591\n",
            "Epoch 128 Loss 0.372973\n",
            "Time taken for 1 epoch 5.753552198410034 sec\n",
            "\n",
            "Epoch 129 Batch 0 Loss 0.3571\n",
            "Epoch 129 Loss 0.378889\n",
            "Time taken for 1 epoch 6.4522318840026855 sec\n",
            "\n",
            "Epoch 130 Batch 0 Loss 0.4530\n",
            "Epoch 130 Loss 0.396082\n",
            "Time taken for 1 epoch 5.972660541534424 sec\n",
            "\n",
            "Epoch 131 Batch 0 Loss 0.4197\n",
            "Epoch 131 Loss 0.380642\n",
            "Time taken for 1 epoch 5.62562894821167 sec\n",
            "\n",
            "Epoch 132 Batch 0 Loss 0.3731\n",
            "Epoch 132 Loss 0.364314\n",
            "Time taken for 1 epoch 5.499607086181641 sec\n",
            "\n",
            "Epoch 133 Batch 0 Loss 0.3555\n",
            "Epoch 133 Loss 0.366508\n",
            "Time taken for 1 epoch 5.479405164718628 sec\n",
            "\n",
            "Epoch 134 Batch 0 Loss 0.3461\n",
            "Epoch 134 Loss 0.360997\n",
            "Time taken for 1 epoch 5.493957757949829 sec\n",
            "\n",
            "Epoch 135 Batch 0 Loss 0.3352\n",
            "Epoch 135 Loss 0.362657\n",
            "Time taken for 1 epoch 5.532593011856079 sec\n",
            "\n",
            "Epoch 136 Batch 0 Loss 0.3314\n",
            "Epoch 136 Loss 0.372541\n",
            "Time taken for 1 epoch 5.552658796310425 sec\n",
            "\n",
            "Epoch 137 Batch 0 Loss 0.3388\n",
            "Epoch 137 Loss 0.374390\n",
            "Time taken for 1 epoch 5.619004487991333 sec\n",
            "\n",
            "Epoch 138 Batch 0 Loss 0.3279\n",
            "Epoch 138 Loss 0.364474\n",
            "Time taken for 1 epoch 5.67833137512207 sec\n",
            "\n",
            "Epoch 139 Batch 0 Loss 0.3168\n",
            "Epoch 139 Loss 0.351698\n",
            "Time taken for 1 epoch 5.609732151031494 sec\n",
            "\n",
            "Epoch 140 Batch 0 Loss 0.3262\n",
            "Epoch 140 Loss 0.337128\n",
            "Time taken for 1 epoch 5.557015895843506 sec\n",
            "\n",
            "Epoch 141 Batch 0 Loss 0.3033\n",
            "Epoch 141 Loss 0.326558\n",
            "Time taken for 1 epoch 5.4933037757873535 sec\n",
            "\n",
            "Epoch 142 Batch 0 Loss 0.2992\n",
            "Epoch 142 Loss 0.317948\n",
            "Time taken for 1 epoch 5.531525135040283 sec\n",
            "\n",
            "Epoch 143 Batch 0 Loss 0.2840\n",
            "Epoch 143 Loss 0.306078\n",
            "Time taken for 1 epoch 5.504084348678589 sec\n",
            "\n",
            "Epoch 144 Batch 0 Loss 0.2756\n",
            "Epoch 144 Loss 0.298790\n",
            "Time taken for 1 epoch 5.47160267829895 sec\n",
            "\n",
            "Epoch 145 Batch 0 Loss 0.2739\n",
            "Epoch 145 Loss 0.294844\n",
            "Time taken for 1 epoch 5.571664333343506 sec\n",
            "\n",
            "Epoch 146 Batch 0 Loss 0.2662\n",
            "Epoch 146 Loss 0.297685\n",
            "Time taken for 1 epoch 5.5877087116241455 sec\n",
            "\n",
            "Epoch 147 Batch 0 Loss 0.2669\n",
            "Epoch 147 Loss 0.309665\n",
            "Time taken for 1 epoch 5.4825029373168945 sec\n",
            "\n",
            "Epoch 148 Batch 0 Loss 0.2733\n",
            "Epoch 148 Loss 0.337970\n",
            "Time taken for 1 epoch 5.476578235626221 sec\n",
            "\n",
            "Epoch 149 Batch 0 Loss 0.3206\n",
            "Epoch 149 Loss 0.366562\n",
            "Time taken for 1 epoch 5.470912456512451 sec\n",
            "\n",
            "Epoch 150 Batch 0 Loss 0.3266\n",
            "Epoch 150 Loss 0.391358\n",
            "Time taken for 1 epoch 5.52971339225769 sec\n",
            "\n",
            "Epoch 151 Batch 0 Loss 0.4133\n",
            "Epoch 151 Loss 0.450006\n",
            "Time taken for 1 epoch 5.520897150039673 sec\n",
            "\n",
            "Epoch 152 Batch 0 Loss 0.4199\n",
            "Epoch 152 Loss 0.483449\n",
            "Time taken for 1 epoch 5.576063871383667 sec\n",
            "\n",
            "Epoch 153 Batch 0 Loss 0.4607\n",
            "Epoch 153 Loss 0.467451\n",
            "Time taken for 1 epoch 5.514787912368774 sec\n",
            "\n",
            "Epoch 154 Batch 0 Loss 0.4296\n",
            "Epoch 154 Loss 0.427990\n",
            "Time taken for 1 epoch 5.413025856018066 sec\n",
            "\n",
            "Epoch 155 Batch 0 Loss 0.4006\n",
            "Epoch 155 Loss 0.389705\n",
            "Time taken for 1 epoch 5.449463844299316 sec\n",
            "\n",
            "Epoch 156 Batch 0 Loss 0.3476\n",
            "Epoch 156 Loss 0.341330\n",
            "Time taken for 1 epoch 5.963543653488159 sec\n",
            "\n",
            "Epoch 157 Batch 0 Loss 0.2999\n",
            "Epoch 157 Loss 0.315224\n",
            "Time taken for 1 epoch 5.732171297073364 sec\n",
            "\n",
            "Epoch 158 Batch 0 Loss 0.2776\n",
            "Epoch 158 Loss 0.291112\n",
            "Time taken for 1 epoch 5.521584510803223 sec\n",
            "\n",
            "Epoch 159 Batch 0 Loss 0.2629\n",
            "Epoch 159 Loss 0.277808\n",
            "Time taken for 1 epoch 5.62855863571167 sec\n",
            "\n",
            "Epoch 160 Batch 0 Loss 0.2492\n",
            "Epoch 160 Loss 0.270688\n",
            "Time taken for 1 epoch 5.69724178314209 sec\n",
            "\n",
            "Epoch 161 Batch 0 Loss 0.2516\n",
            "Epoch 161 Loss 0.270644\n",
            "Time taken for 1 epoch 5.597773790359497 sec\n",
            "\n",
            "Epoch 162 Batch 0 Loss 0.2588\n",
            "Epoch 162 Loss 0.270209\n",
            "Time taken for 1 epoch 5.542850732803345 sec\n",
            "\n",
            "Epoch 163 Batch 0 Loss 0.2428\n",
            "Epoch 163 Loss 0.270590\n",
            "Time taken for 1 epoch 5.604151487350464 sec\n",
            "\n",
            "Epoch 164 Batch 0 Loss 0.2435\n",
            "Epoch 164 Loss 0.271377\n",
            "Time taken for 1 epoch 5.608285427093506 sec\n",
            "\n",
            "Epoch 165 Batch 0 Loss 0.2391\n",
            "Epoch 165 Loss 0.273484\n",
            "Time taken for 1 epoch 5.561837196350098 sec\n",
            "\n",
            "Epoch 166 Batch 0 Loss 0.2437\n",
            "Epoch 166 Loss 0.278019\n",
            "Time taken for 1 epoch 5.58967399597168 sec\n",
            "\n",
            "Epoch 167 Batch 0 Loss 0.2516\n",
            "Epoch 167 Loss 0.277110\n",
            "Time taken for 1 epoch 5.643880128860474 sec\n",
            "\n",
            "Epoch 168 Batch 0 Loss 0.2568\n",
            "Epoch 168 Loss 0.279993\n",
            "Time taken for 1 epoch 5.572758197784424 sec\n",
            "\n",
            "Epoch 169 Batch 0 Loss 0.2586\n",
            "Epoch 169 Loss 0.284395\n",
            "Time taken for 1 epoch 5.675809860229492 sec\n",
            "\n",
            "Epoch 170 Batch 0 Loss 0.2571\n",
            "Epoch 170 Loss 0.282443\n",
            "Time taken for 1 epoch 5.595444679260254 sec\n",
            "\n",
            "Epoch 171 Batch 0 Loss 0.2532\n",
            "Epoch 171 Loss 0.282488\n",
            "Time taken for 1 epoch 5.679605722427368 sec\n",
            "\n",
            "Epoch 172 Batch 0 Loss 0.2550\n",
            "Epoch 172 Loss 0.280766\n",
            "Time taken for 1 epoch 5.579391002655029 sec\n",
            "\n",
            "Epoch 173 Batch 0 Loss 0.2609\n",
            "Epoch 173 Loss 0.278991\n",
            "Time taken for 1 epoch 5.542361259460449 sec\n",
            "\n",
            "Epoch 174 Batch 0 Loss 0.2716\n",
            "Epoch 174 Loss 0.273597\n",
            "Time taken for 1 epoch 5.598952531814575 sec\n",
            "\n",
            "Epoch 175 Batch 0 Loss 0.2639\n",
            "Epoch 175 Loss 0.273818\n",
            "Time taken for 1 epoch 5.5825722217559814 sec\n",
            "\n",
            "Epoch 176 Batch 0 Loss 0.2631\n",
            "Epoch 176 Loss 0.269879\n",
            "Time taken for 1 epoch 5.527414083480835 sec\n",
            "\n",
            "Epoch 177 Batch 0 Loss 0.2575\n",
            "Epoch 177 Loss 0.263709\n",
            "Time taken for 1 epoch 5.498185873031616 sec\n",
            "\n",
            "Epoch 178 Batch 0 Loss 0.2592\n",
            "Epoch 178 Loss 0.261421\n",
            "Time taken for 1 epoch 5.5537614822387695 sec\n",
            "\n",
            "Epoch 179 Batch 0 Loss 0.2542\n",
            "Epoch 179 Loss 0.259374\n",
            "Time taken for 1 epoch 5.608931303024292 sec\n",
            "\n",
            "Epoch 180 Batch 0 Loss 0.2422\n",
            "Epoch 180 Loss 0.255893\n",
            "Time taken for 1 epoch 5.606814384460449 sec\n",
            "\n",
            "Epoch 181 Batch 0 Loss 0.2397\n",
            "Epoch 181 Loss 0.253883\n",
            "Time taken for 1 epoch 5.789503335952759 sec\n",
            "\n",
            "Epoch 182 Batch 0 Loss 0.2344\n",
            "Epoch 182 Loss 0.254454\n",
            "Time taken for 1 epoch 5.746642589569092 sec\n",
            "\n",
            "Epoch 183 Batch 0 Loss 0.2312\n",
            "Epoch 183 Loss 0.253903\n",
            "Time taken for 1 epoch 5.722972393035889 sec\n",
            "\n",
            "Epoch 184 Batch 0 Loss 0.2334\n",
            "Epoch 184 Loss 0.254894\n",
            "Time taken for 1 epoch 6.343472719192505 sec\n",
            "\n",
            "Epoch 185 Batch 0 Loss 0.2370\n",
            "Epoch 185 Loss 0.254899\n",
            "Time taken for 1 epoch 6.507193088531494 sec\n",
            "\n",
            "Epoch 186 Batch 0 Loss 0.2473\n",
            "Epoch 186 Loss 0.261246\n",
            "Time taken for 1 epoch 6.224096059799194 sec\n",
            "\n",
            "Epoch 187 Batch 0 Loss 0.2392\n",
            "Epoch 187 Loss 0.258131\n",
            "Time taken for 1 epoch 6.38881516456604 sec\n",
            "\n",
            "Epoch 188 Batch 0 Loss 0.2283\n",
            "Epoch 188 Loss 0.253607\n",
            "Time taken for 1 epoch 5.522047758102417 sec\n",
            "\n",
            "Epoch 189 Batch 0 Loss 0.2246\n",
            "Epoch 189 Loss 0.252491\n",
            "Time taken for 1 epoch 5.60482120513916 sec\n",
            "\n",
            "Epoch 190 Batch 0 Loss 0.2245\n",
            "Epoch 190 Loss 0.249899\n",
            "Time taken for 1 epoch 5.581920862197876 sec\n",
            "\n",
            "Epoch 191 Batch 0 Loss 0.2195\n",
            "Epoch 191 Loss 0.253125\n",
            "Time taken for 1 epoch 5.65141749382019 sec\n",
            "\n",
            "Epoch 192 Batch 0 Loss 0.2241\n",
            "Epoch 192 Loss 0.254221\n",
            "Time taken for 1 epoch 5.656902313232422 sec\n",
            "\n",
            "Epoch 193 Batch 0 Loss 0.2281\n",
            "Epoch 193 Loss 0.264464\n",
            "Time taken for 1 epoch 5.780815601348877 sec\n",
            "\n",
            "Epoch 194 Batch 0 Loss 0.2303\n",
            "Epoch 194 Loss 0.264439\n",
            "Time taken for 1 epoch 5.686927556991577 sec\n",
            "\n",
            "Epoch 195 Batch 0 Loss 0.2358\n",
            "Epoch 195 Loss 0.260831\n",
            "Time taken for 1 epoch 5.686421871185303 sec\n",
            "\n",
            "Epoch 196 Batch 0 Loss 0.2453\n",
            "Epoch 196 Loss 0.262080\n",
            "Time taken for 1 epoch 5.612512826919556 sec\n",
            "\n",
            "Epoch 197 Batch 0 Loss 0.2480\n",
            "Epoch 197 Loss 0.269529\n",
            "Time taken for 1 epoch 5.620668888092041 sec\n",
            "\n",
            "Epoch 198 Batch 0 Loss 0.2583\n",
            "Epoch 198 Loss 0.280603\n",
            "Time taken for 1 epoch 5.624186992645264 sec\n",
            "\n",
            "Epoch 199 Batch 0 Loss 0.2866\n",
            "Epoch 199 Loss 0.302621\n",
            "Time taken for 1 epoch 5.601732969284058 sec\n",
            "\n",
            "Epoch 200 Batch 0 Loss 0.3172\n",
            "Epoch 200 Loss 0.359375\n",
            "Time taken for 1 epoch 5.684675455093384 sec\n",
            "\n",
            "Epoch 201 Batch 0 Loss 0.3799\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "corner outside view view view view view outside view outside tiles and supplies and outside view outside outside view outside view view outside view\n",
            "Epoch 201 Loss 0.451442\n",
            "Time taken for 1 epoch 6.423980236053467 sec\n",
            "\n",
            "Epoch 202 Batch 0 Loss 0.6168\n",
            "Epoch 202 Loss 0.573193\n",
            "Time taken for 1 epoch 5.653632640838623 sec\n",
            "\n",
            "Epoch 203 Batch 0 Loss 0.6894\n",
            "Epoch 203 Loss 0.682158\n",
            "Time taken for 1 epoch 5.615541696548462 sec\n",
            "\n",
            "Epoch 204 Batch 0 Loss 0.6883\n",
            "Epoch 204 Loss 0.678050\n",
            "Time taken for 1 epoch 5.70440673828125 sec\n",
            "\n",
            "Epoch 205 Batch 0 Loss 0.5025\n",
            "Epoch 205 Loss 0.579583\n",
            "Time taken for 1 epoch 5.64689564704895 sec\n",
            "\n",
            "Epoch 206 Batch 0 Loss 0.4622\n",
            "Epoch 206 Loss 0.486112\n",
            "Time taken for 1 epoch 5.626784563064575 sec\n",
            "\n",
            "Epoch 207 Batch 0 Loss 0.3817\n",
            "Epoch 207 Loss 0.425471\n",
            "Time taken for 1 epoch 5.757641792297363 sec\n",
            "\n",
            "Epoch 208 Batch 0 Loss 0.3703\n",
            "Epoch 208 Loss 0.373849\n",
            "Time taken for 1 epoch 5.7133708000183105 sec\n",
            "\n",
            "Epoch 209 Batch 0 Loss 0.2957\n",
            "Epoch 209 Loss 0.315372\n",
            "Time taken for 1 epoch 5.657844543457031 sec\n",
            "\n",
            "Epoch 210 Batch 0 Loss 0.2495\n",
            "Epoch 210 Loss 0.274362\n",
            "Time taken for 1 epoch 6.3061699867248535 sec\n",
            "\n",
            "Epoch 211 Batch 0 Loss 0.2315\n",
            "Epoch 211 Loss 0.255966\n",
            "Time taken for 1 epoch 5.555030345916748 sec\n",
            "\n",
            "Epoch 212 Batch 0 Loss 0.2218\n",
            "Epoch 212 Loss 0.243266\n",
            "Time taken for 1 epoch 5.600976467132568 sec\n",
            "\n",
            "Epoch 213 Batch 0 Loss 0.2153\n",
            "Epoch 213 Loss 0.235747\n",
            "Time taken for 1 epoch 5.58236026763916 sec\n",
            "\n",
            "Epoch 214 Batch 0 Loss 0.2121\n",
            "Epoch 214 Loss 0.231543\n",
            "Time taken for 1 epoch 5.614725828170776 sec\n",
            "\n",
            "Epoch 215 Batch 0 Loss 0.2092\n",
            "Epoch 215 Loss 0.228137\n",
            "Time taken for 1 epoch 5.6103150844573975 sec\n",
            "\n",
            "Epoch 216 Batch 0 Loss 0.2078\n",
            "Epoch 216 Loss 0.227275\n",
            "Time taken for 1 epoch 5.611633777618408 sec\n",
            "\n",
            "Epoch 217 Batch 0 Loss 0.2090\n",
            "Epoch 217 Loss 0.226358\n",
            "Time taken for 1 epoch 5.673081159591675 sec\n",
            "\n",
            "Epoch 218 Batch 0 Loss 0.2100\n",
            "Epoch 218 Loss 0.226693\n",
            "Time taken for 1 epoch 5.669534921646118 sec\n",
            "\n",
            "Epoch 219 Batch 0 Loss 0.2075\n",
            "Epoch 219 Loss 0.228911\n",
            "Time taken for 1 epoch 5.581523180007935 sec\n",
            "\n",
            "Epoch 220 Batch 0 Loss 0.2093\n",
            "Epoch 220 Loss 0.228689\n",
            "Time taken for 1 epoch 5.616358757019043 sec\n",
            "\n",
            "Epoch 221 Batch 0 Loss 0.2094\n",
            "Epoch 221 Loss 0.225500\n",
            "Time taken for 1 epoch 5.662945747375488 sec\n",
            "\n",
            "Epoch 222 Batch 0 Loss 0.2069\n",
            "Epoch 222 Loss 0.224115\n",
            "Time taken for 1 epoch 5.669234991073608 sec\n",
            "\n",
            "Epoch 223 Batch 0 Loss 0.2032\n",
            "Epoch 223 Loss 0.222009\n",
            "Time taken for 1 epoch 5.605611801147461 sec\n",
            "\n",
            "Epoch 224 Batch 0 Loss 0.2049\n",
            "Epoch 224 Loss 0.224988\n",
            "Time taken for 1 epoch 5.625720024108887 sec\n",
            "\n",
            "Epoch 225 Batch 0 Loss 0.2193\n",
            "Epoch 225 Loss 0.227890\n",
            "Time taken for 1 epoch 5.708267450332642 sec\n",
            "\n",
            "Epoch 226 Batch 0 Loss 0.2175\n",
            "Epoch 226 Loss 0.228477\n",
            "Time taken for 1 epoch 5.6443071365356445 sec\n",
            "\n",
            "Epoch 227 Batch 0 Loss 0.2080\n",
            "Epoch 227 Loss 0.229022\n",
            "Time taken for 1 epoch 5.601605653762817 sec\n",
            "\n",
            "Epoch 228 Batch 0 Loss 0.2071\n",
            "Epoch 228 Loss 0.225436\n",
            "Time taken for 1 epoch 5.529289960861206 sec\n",
            "\n",
            "Epoch 229 Batch 0 Loss 0.2170\n",
            "Epoch 229 Loss 0.227444\n",
            "Time taken for 1 epoch 5.568256139755249 sec\n",
            "\n",
            "Epoch 230 Batch 0 Loss 0.2106\n",
            "Epoch 230 Loss 0.236138\n",
            "Time taken for 1 epoch 5.57901406288147 sec\n",
            "\n",
            "Epoch 231 Batch 0 Loss 0.2133\n",
            "Epoch 231 Loss 0.239349\n",
            "Time taken for 1 epoch 5.639853239059448 sec\n",
            "\n",
            "Epoch 232 Batch 0 Loss 0.2141\n",
            "Epoch 232 Loss 0.236748\n",
            "Time taken for 1 epoch 5.653329849243164 sec\n",
            "\n",
            "Epoch 233 Batch 0 Loss 0.2200\n",
            "Epoch 233 Loss 0.232366\n",
            "Time taken for 1 epoch 5.652137994766235 sec\n",
            "\n",
            "Epoch 234 Batch 0 Loss 0.2156\n",
            "Epoch 234 Loss 0.229734\n",
            "Time taken for 1 epoch 5.581853628158569 sec\n",
            "\n",
            "Epoch 235 Batch 0 Loss 0.2156\n",
            "Epoch 235 Loss 0.228184\n",
            "Time taken for 1 epoch 5.617778539657593 sec\n",
            "\n",
            "Epoch 236 Batch 0 Loss 0.2084\n",
            "Epoch 236 Loss 0.228311\n",
            "Time taken for 1 epoch 5.632988929748535 sec\n",
            "\n",
            "Epoch 237 Batch 0 Loss 0.2055\n",
            "Epoch 237 Loss 0.225222\n",
            "Time taken for 1 epoch 5.596536159515381 sec\n",
            "\n",
            "Epoch 238 Batch 0 Loss 0.1997\n",
            "Epoch 238 Loss 0.224393\n",
            "Time taken for 1 epoch 5.771152496337891 sec\n",
            "\n",
            "Epoch 239 Batch 0 Loss 0.2037\n",
            "Epoch 239 Loss 0.223193\n",
            "Time taken for 1 epoch 6.45880389213562 sec\n",
            "\n",
            "Epoch 240 Batch 0 Loss 0.2117\n",
            "Epoch 240 Loss 0.222822\n",
            "Time taken for 1 epoch 5.967885255813599 sec\n",
            "\n",
            "Epoch 241 Batch 0 Loss 0.2155\n",
            "Epoch 241 Loss 0.222946\n",
            "Time taken for 1 epoch 5.668520927429199 sec\n",
            "\n",
            "Epoch 242 Batch 0 Loss 0.2029\n",
            "Epoch 242 Loss 0.222026\n",
            "Time taken for 1 epoch 5.627978086471558 sec\n",
            "\n",
            "Epoch 243 Batch 0 Loss 0.2028\n",
            "Epoch 243 Loss 0.218919\n",
            "Time taken for 1 epoch 5.575240612030029 sec\n",
            "\n",
            "Epoch 244 Batch 0 Loss 0.2051\n",
            "Epoch 244 Loss 0.220916\n",
            "Time taken for 1 epoch 5.612286329269409 sec\n",
            "\n",
            "Epoch 245 Batch 0 Loss 0.1985\n",
            "Epoch 245 Loss 0.225442\n",
            "Time taken for 1 epoch 5.563692569732666 sec\n",
            "\n",
            "Epoch 246 Batch 0 Loss 0.2000\n",
            "Epoch 246 Loss 0.225951\n",
            "Time taken for 1 epoch 5.689673662185669 sec\n",
            "\n",
            "Epoch 247 Batch 0 Loss 0.2056\n",
            "Epoch 247 Loss 0.224237\n",
            "Time taken for 1 epoch 5.634470701217651 sec\n",
            "\n",
            "Epoch 248 Batch 0 Loss 0.2073\n",
            "Epoch 248 Loss 0.229294\n",
            "Time taken for 1 epoch 5.628784894943237 sec\n",
            "\n",
            "Epoch 249 Batch 0 Loss 0.2058\n",
            "Epoch 249 Loss 0.229732\n",
            "Time taken for 1 epoch 5.581187963485718 sec\n",
            "\n",
            "Epoch 250 Batch 0 Loss 0.2097\n",
            "Epoch 250 Loss 0.228508\n",
            "Time taken for 1 epoch 5.587370157241821 sec\n",
            "\n",
            "Epoch 251 Batch 0 Loss 0.2370\n",
            "Epoch 251 Loss 0.227420\n",
            "Time taken for 1 epoch 5.60565972328186 sec\n",
            "\n",
            "Epoch 252 Batch 0 Loss 0.2546\n",
            "Epoch 252 Loss 0.228372\n",
            "Time taken for 1 epoch 5.664011001586914 sec\n",
            "\n",
            "Epoch 253 Batch 0 Loss 0.3322\n",
            "Epoch 253 Loss 0.238531\n",
            "Time taken for 1 epoch 5.634152173995972 sec\n",
            "\n",
            "Epoch 254 Batch 0 Loss 0.2729\n",
            "Epoch 254 Loss 0.239162\n",
            "Time taken for 1 epoch 5.700048208236694 sec\n",
            "\n",
            "Epoch 255 Batch 0 Loss 0.2701\n",
            "Epoch 255 Loss 0.238994\n",
            "Time taken for 1 epoch 5.567693471908569 sec\n",
            "\n",
            "Epoch 256 Batch 0 Loss 0.2599\n",
            "Epoch 256 Loss 0.237730\n",
            "Time taken for 1 epoch 5.58229398727417 sec\n",
            "\n",
            "Epoch 257 Batch 0 Loss 0.2556\n",
            "Epoch 257 Loss 0.234524\n",
            "Time taken for 1 epoch 5.621478319168091 sec\n",
            "\n",
            "Epoch 258 Batch 0 Loss 0.2265\n",
            "Epoch 258 Loss 0.229775\n",
            "Time taken for 1 epoch 5.71358323097229 sec\n",
            "\n",
            "Epoch 259 Batch 0 Loss 0.2124\n",
            "Epoch 259 Loss 0.228712\n",
            "Time taken for 1 epoch 5.7330334186553955 sec\n",
            "\n",
            "Epoch 260 Batch 0 Loss 0.2153\n",
            "Epoch 260 Loss 0.221026\n",
            "Time taken for 1 epoch 5.651579141616821 sec\n",
            "\n",
            "Epoch 261 Batch 0 Loss 0.2033\n",
            "Epoch 261 Loss 0.216556\n",
            "Time taken for 1 epoch 5.589184284210205 sec\n",
            "\n",
            "Epoch 262 Batch 0 Loss 0.2023\n",
            "Epoch 262 Loss 0.213734\n",
            "Time taken for 1 epoch 5.6726977825164795 sec\n",
            "\n",
            "Epoch 263 Batch 0 Loss 0.1985\n",
            "Epoch 263 Loss 0.213498\n",
            "Time taken for 1 epoch 5.649345874786377 sec\n",
            "\n",
            "Epoch 264 Batch 0 Loss 0.1969\n",
            "Epoch 264 Loss 0.213315\n",
            "Time taken for 1 epoch 6.445502758026123 sec\n",
            "\n",
            "Epoch 265 Batch 0 Loss 0.1992\n",
            "Epoch 265 Loss 0.213818\n",
            "Time taken for 1 epoch 5.68072509765625 sec\n",
            "\n",
            "Epoch 266 Batch 0 Loss 0.2079\n",
            "Epoch 266 Loss 0.219219\n",
            "Time taken for 1 epoch 5.6621057987213135 sec\n",
            "\n",
            "Epoch 267 Batch 0 Loss 0.2126\n",
            "Epoch 267 Loss 0.224640\n",
            "Time taken for 1 epoch 5.626096248626709 sec\n",
            "\n",
            "Epoch 268 Batch 0 Loss 0.2047\n",
            "Epoch 268 Loss 0.223681\n",
            "Time taken for 1 epoch 5.596648454666138 sec\n",
            "\n",
            "Epoch 269 Batch 0 Loss 0.2088\n",
            "Epoch 269 Loss 0.228033\n",
            "Time taken for 1 epoch 5.588197469711304 sec\n",
            "\n",
            "Epoch 270 Batch 0 Loss 0.2202\n",
            "Epoch 270 Loss 0.229946\n",
            "Time taken for 1 epoch 5.616903305053711 sec\n",
            "\n",
            "Epoch 271 Batch 0 Loss 0.2170\n",
            "Epoch 271 Loss 0.231328\n",
            "Time taken for 1 epoch 5.639162302017212 sec\n",
            "\n",
            "Epoch 272 Batch 0 Loss 0.2121\n",
            "Epoch 272 Loss 0.235185\n",
            "Time taken for 1 epoch 5.568845748901367 sec\n",
            "\n",
            "Epoch 273 Batch 0 Loss 0.2109\n",
            "Epoch 273 Loss 0.234893\n",
            "Time taken for 1 epoch 5.63024640083313 sec\n",
            "\n",
            "Epoch 274 Batch 0 Loss 0.2278\n",
            "Epoch 274 Loss 0.256019\n",
            "Time taken for 1 epoch 5.643362045288086 sec\n",
            "\n",
            "Epoch 275 Batch 0 Loss 0.2302\n",
            "Epoch 275 Loss 0.277846\n",
            "Time taken for 1 epoch 5.759089231491089 sec\n",
            "\n",
            "Epoch 276 Batch 0 Loss 0.2429\n",
            "Epoch 276 Loss 0.318851\n",
            "Time taken for 1 epoch 5.70711612701416 sec\n",
            "\n",
            "Epoch 277 Batch 0 Loss 0.2679\n",
            "Epoch 277 Loss 0.366975\n",
            "Time taken for 1 epoch 5.702519655227661 sec\n",
            "\n",
            "Epoch 278 Batch 0 Loss 0.3242\n",
            "Epoch 278 Loss 0.389286\n",
            "Time taken for 1 epoch 5.703058242797852 sec\n",
            "\n",
            "Epoch 279 Batch 0 Loss 0.3703\n",
            "Epoch 279 Loss 0.419072\n",
            "Time taken for 1 epoch 5.713547945022583 sec\n",
            "\n",
            "Epoch 280 Batch 0 Loss 0.3500\n",
            "Epoch 280 Loss 0.425222\n",
            "Time taken for 1 epoch 5.582313537597656 sec\n",
            "\n",
            "Epoch 281 Batch 0 Loss 0.4084\n",
            "Epoch 281 Loss 0.466858\n",
            "Time taken for 1 epoch 5.588909149169922 sec\n",
            "\n",
            "Epoch 282 Batch 0 Loss 0.4306\n",
            "Epoch 282 Loss 0.466490\n",
            "Time taken for 1 epoch 5.657034635543823 sec\n",
            "\n",
            "Epoch 283 Batch 0 Loss 0.4258\n",
            "Epoch 283 Loss 0.422724\n",
            "Time taken for 1 epoch 5.6827521324157715 sec\n",
            "\n",
            "Epoch 284 Batch 0 Loss 0.3475\n",
            "Epoch 284 Loss 0.388107\n",
            "Time taken for 1 epoch 5.64395809173584 sec\n",
            "\n",
            "Epoch 285 Batch 0 Loss 0.3421\n",
            "Epoch 285 Loss 0.332026\n",
            "Time taken for 1 epoch 5.57671594619751 sec\n",
            "\n",
            "Epoch 286 Batch 0 Loss 0.3109\n",
            "Epoch 286 Loss 0.281791\n",
            "Time taken for 1 epoch 5.59246301651001 sec\n",
            "\n",
            "Epoch 287 Batch 0 Loss 0.2552\n",
            "Epoch 287 Loss 0.249341\n",
            "Time taken for 1 epoch 5.575752258300781 sec\n",
            "\n",
            "Epoch 288 Batch 0 Loss 0.2255\n",
            "Epoch 288 Loss 0.229950\n",
            "Time taken for 1 epoch 5.603298187255859 sec\n",
            "\n",
            "Epoch 289 Batch 0 Loss 0.2057\n",
            "Epoch 289 Loss 0.220258\n",
            "Time taken for 1 epoch 5.5873870849609375 sec\n",
            "\n",
            "Epoch 290 Batch 0 Loss 0.2000\n",
            "Epoch 290 Loss 0.214101\n",
            "Time taken for 1 epoch 5.526248216629028 sec\n",
            "\n",
            "Epoch 291 Batch 0 Loss 0.1984\n",
            "Epoch 291 Loss 0.212321\n",
            "Time taken for 1 epoch 5.552808046340942 sec\n",
            "\n",
            "Epoch 292 Batch 0 Loss 0.1964\n",
            "Epoch 292 Loss 0.211342\n",
            "Time taken for 1 epoch 5.561177015304565 sec\n",
            "\n",
            "Epoch 293 Batch 0 Loss 0.1960\n",
            "Epoch 293 Loss 0.210939\n",
            "Time taken for 1 epoch 5.968092679977417 sec\n",
            "\n",
            "Epoch 294 Batch 0 Loss 0.1933\n",
            "Epoch 294 Loss 0.209879\n",
            "Time taken for 1 epoch 6.660921096801758 sec\n",
            "\n",
            "Epoch 295 Batch 0 Loss 0.1882\n",
            "Epoch 295 Loss 0.210963\n",
            "Time taken for 1 epoch 5.924515008926392 sec\n",
            "\n",
            "Epoch 296 Batch 0 Loss 0.1949\n",
            "Epoch 296 Loss 0.209959\n",
            "Time taken for 1 epoch 5.56428074836731 sec\n",
            "\n",
            "Epoch 297 Batch 0 Loss 0.2030\n",
            "Epoch 297 Loss 0.211427\n",
            "Time taken for 1 epoch 5.515213251113892 sec\n",
            "\n",
            "Epoch 298 Batch 0 Loss 0.1968\n",
            "Epoch 298 Loss 0.210864\n",
            "Time taken for 1 epoch 5.562306642532349 sec\n",
            "\n",
            "Epoch 299 Batch 0 Loss 0.2008\n",
            "Epoch 299 Loss 0.210039\n",
            "Time taken for 1 epoch 5.603968381881714 sec\n",
            "\n",
            "Epoch 300 Batch 0 Loss 0.2049\n",
            "Epoch 300 Loss 0.208433\n",
            "Time taken for 1 epoch 5.6522297859191895 sec\n",
            "\n",
            "Epoch 301 Batch 0 Loss 0.1927\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "be herd of outside of coconut outside of smoke outside of outside flying outside view outside outside of outside of outside of outside of\n",
            "Epoch 301 Loss 0.206396\n",
            "Time taken for 1 epoch 6.203644752502441 sec\n",
            "\n",
            "Epoch 302 Batch 0 Loss 0.1927\n",
            "Epoch 302 Loss 0.204557\n",
            "Time taken for 1 epoch 5.626201391220093 sec\n",
            "\n",
            "Epoch 303 Batch 0 Loss 0.1943\n",
            "Epoch 303 Loss 0.205531\n",
            "Time taken for 1 epoch 5.62658429145813 sec\n",
            "\n",
            "Epoch 304 Batch 0 Loss 0.1883\n",
            "Epoch 304 Loss 0.204258\n",
            "Time taken for 1 epoch 5.626578330993652 sec\n",
            "\n",
            "Epoch 305 Batch 0 Loss 0.1885\n",
            "Epoch 305 Loss 0.203420\n",
            "Time taken for 1 epoch 5.570728302001953 sec\n",
            "\n",
            "Epoch 306 Batch 0 Loss 0.1893\n",
            "Epoch 306 Loss 0.203764\n",
            "Time taken for 1 epoch 5.594902038574219 sec\n",
            "\n",
            "Epoch 307 Batch 0 Loss 0.1891\n",
            "Epoch 307 Loss 0.204419\n",
            "Time taken for 1 epoch 5.648239612579346 sec\n",
            "\n",
            "Epoch 308 Batch 0 Loss 0.1876\n",
            "Epoch 308 Loss 0.204743\n",
            "Time taken for 1 epoch 5.6681227684021 sec\n",
            "\n",
            "Epoch 309 Batch 0 Loss 0.1906\n",
            "Epoch 309 Loss 0.207621\n",
            "Time taken for 1 epoch 5.607712030410767 sec\n",
            "\n",
            "Epoch 310 Batch 0 Loss 0.1928\n",
            "Epoch 310 Loss 0.206142\n",
            "Time taken for 1 epoch 5.542603254318237 sec\n",
            "\n",
            "Epoch 311 Batch 0 Loss 0.1910\n",
            "Epoch 311 Loss 0.206885\n",
            "Time taken for 1 epoch 5.575284242630005 sec\n",
            "\n",
            "Epoch 312 Batch 0 Loss 0.1882\n",
            "Epoch 312 Loss 0.207327\n",
            "Time taken for 1 epoch 5.568553924560547 sec\n",
            "\n",
            "Epoch 313 Batch 0 Loss 0.1886\n",
            "Epoch 313 Loss 0.208071\n",
            "Time taken for 1 epoch 5.5578320026397705 sec\n",
            "\n",
            "Epoch 314 Batch 0 Loss 0.1859\n",
            "Epoch 314 Loss 0.209575\n",
            "Time taken for 1 epoch 5.533776521682739 sec\n",
            "\n",
            "Epoch 315 Batch 0 Loss 0.1842\n",
            "Epoch 315 Loss 0.209982\n",
            "Time taken for 1 epoch 5.539013385772705 sec\n",
            "\n",
            "Epoch 316 Batch 0 Loss 0.1861\n",
            "Epoch 316 Loss 0.206996\n",
            "Time taken for 1 epoch 5.575146198272705 sec\n",
            "\n",
            "Epoch 317 Batch 0 Loss 0.1869\n",
            "Epoch 317 Loss 0.205746\n",
            "Time taken for 1 epoch 5.690679311752319 sec\n",
            "\n",
            "Epoch 318 Batch 0 Loss 0.1860\n",
            "Epoch 318 Loss 0.204446\n",
            "Time taken for 1 epoch 6.302819490432739 sec\n",
            "\n",
            "Epoch 319 Batch 0 Loss 0.1903\n",
            "Epoch 319 Loss 0.204195\n",
            "Time taken for 1 epoch 5.584164619445801 sec\n",
            "\n",
            "Epoch 320 Batch 0 Loss 0.1899\n",
            "Epoch 320 Loss 0.203822\n",
            "Time taken for 1 epoch 5.547691345214844 sec\n",
            "\n",
            "Epoch 321 Batch 0 Loss 0.1857\n",
            "Epoch 321 Loss 0.202564\n",
            "Time taken for 1 epoch 5.578200817108154 sec\n",
            "\n",
            "Epoch 322 Batch 0 Loss 0.1852\n",
            "Epoch 322 Loss 0.201863\n",
            "Time taken for 1 epoch 5.612336158752441 sec\n",
            "\n",
            "Epoch 323 Batch 0 Loss 0.1857\n",
            "Epoch 323 Loss 0.202683\n",
            "Time taken for 1 epoch 5.54547905921936 sec\n",
            "\n",
            "Epoch 324 Batch 0 Loss 0.1856\n",
            "Epoch 324 Loss 0.203410\n",
            "Time taken for 1 epoch 5.581974267959595 sec\n",
            "\n",
            "Epoch 325 Batch 0 Loss 0.1908\n",
            "Epoch 325 Loss 0.205656\n",
            "Time taken for 1 epoch 5.493154048919678 sec\n",
            "\n",
            "Epoch 326 Batch 0 Loss 0.1956\n",
            "Epoch 326 Loss 0.212441\n",
            "Time taken for 1 epoch 5.537036895751953 sec\n",
            "\n",
            "Epoch 327 Batch 0 Loss 0.1883\n",
            "Epoch 327 Loss 0.216903\n",
            "Time taken for 1 epoch 5.558417320251465 sec\n",
            "\n",
            "Epoch 328 Batch 0 Loss 0.1936\n",
            "Epoch 328 Loss 0.215982\n",
            "Time taken for 1 epoch 5.492340564727783 sec\n",
            "\n",
            "Epoch 329 Batch 0 Loss 0.1990\n",
            "Epoch 329 Loss 0.219473\n",
            "Time taken for 1 epoch 5.566072463989258 sec\n",
            "\n",
            "Epoch 330 Batch 0 Loss 0.1955\n",
            "Epoch 330 Loss 0.215343\n",
            "Time taken for 1 epoch 5.624666690826416 sec\n",
            "\n",
            "Epoch 331 Batch 0 Loss 0.1914\n",
            "Epoch 331 Loss 0.212103\n",
            "Time taken for 1 epoch 5.6784508228302 sec\n",
            "\n",
            "Epoch 332 Batch 0 Loss 0.1903\n",
            "Epoch 332 Loss 0.211926\n",
            "Time taken for 1 epoch 5.675597667694092 sec\n",
            "\n",
            "Epoch 333 Batch 0 Loss 0.1886\n",
            "Epoch 333 Loss 0.210576\n",
            "Time taken for 1 epoch 5.572968244552612 sec\n",
            "\n",
            "Epoch 334 Batch 0 Loss 0.1917\n",
            "Epoch 334 Loss 0.206694\n",
            "Time taken for 1 epoch 5.579278230667114 sec\n",
            "\n",
            "Epoch 335 Batch 0 Loss 0.1916\n",
            "Epoch 335 Loss 0.205280\n",
            "Time taken for 1 epoch 5.536018371582031 sec\n",
            "\n",
            "Epoch 336 Batch 0 Loss 0.1877\n",
            "Epoch 336 Loss 0.205019\n",
            "Time taken for 1 epoch 5.572048664093018 sec\n",
            "\n",
            "Epoch 337 Batch 0 Loss 0.1880\n",
            "Epoch 337 Loss 0.205213\n",
            "Time taken for 1 epoch 5.582769155502319 sec\n",
            "\n",
            "Epoch 338 Batch 0 Loss 0.1855\n",
            "Epoch 338 Loss 0.205356\n",
            "Time taken for 1 epoch 5.555575370788574 sec\n",
            "\n",
            "Epoch 339 Batch 0 Loss 0.1832\n",
            "Epoch 339 Loss 0.202739\n",
            "Time taken for 1 epoch 5.586564540863037 sec\n",
            "\n",
            "Epoch 340 Batch 0 Loss 0.1864\n",
            "Epoch 340 Loss 0.202945\n",
            "Time taken for 1 epoch 5.5921735763549805 sec\n",
            "\n",
            "Epoch 341 Batch 0 Loss 0.1830\n",
            "Epoch 341 Loss 0.201630\n",
            "Time taken for 1 epoch 5.556381464004517 sec\n",
            "\n",
            "Epoch 342 Batch 0 Loss 0.1840\n",
            "Epoch 342 Loss 0.201423\n",
            "Time taken for 1 epoch 5.570273399353027 sec\n",
            "\n",
            "Epoch 343 Batch 0 Loss 0.1842\n",
            "Epoch 343 Loss 0.201205\n",
            "Time taken for 1 epoch 5.596001863479614 sec\n",
            "\n",
            "Epoch 344 Batch 0 Loss 0.1815\n",
            "Epoch 344 Loss 0.199886\n",
            "Time taken for 1 epoch 5.5860443115234375 sec\n",
            "\n",
            "Epoch 345 Batch 0 Loss 0.1826\n",
            "Epoch 345 Loss 0.200689\n",
            "Time taken for 1 epoch 5.555057525634766 sec\n",
            "\n",
            "Epoch 346 Batch 0 Loss 0.1808\n",
            "Epoch 346 Loss 0.203453\n",
            "Time taken for 1 epoch 5.554354667663574 sec\n",
            "\n",
            "Epoch 347 Batch 0 Loss 0.1847\n",
            "Epoch 347 Loss 0.202825\n",
            "Time taken for 1 epoch 5.537323713302612 sec\n",
            "\n",
            "Epoch 348 Batch 0 Loss 0.1892\n",
            "Epoch 348 Loss 0.204035\n",
            "Time taken for 1 epoch 5.748977422714233 sec\n",
            "\n",
            "Epoch 349 Batch 0 Loss 0.1848\n",
            "Epoch 349 Loss 0.203035\n",
            "Time taken for 1 epoch 7.452304124832153 sec\n",
            "\n",
            "Epoch 350 Batch 0 Loss 0.1868\n",
            "Epoch 350 Loss 0.201758\n",
            "Time taken for 1 epoch 7.254519701004028 sec\n",
            "\n",
            "Epoch 351 Batch 0 Loss 0.1871\n",
            "Epoch 351 Loss 0.202406\n",
            "Time taken for 1 epoch 5.784536123275757 sec\n",
            "\n",
            "Epoch 352 Batch 0 Loss 0.1849\n",
            "Epoch 352 Loss 0.203908\n",
            "Time taken for 1 epoch 5.5398406982421875 sec\n",
            "\n",
            "Epoch 353 Batch 0 Loss 0.1830\n",
            "Epoch 353 Loss 0.204176\n",
            "Time taken for 1 epoch 5.582425594329834 sec\n",
            "\n",
            "Epoch 354 Batch 0 Loss 0.1830\n",
            "Epoch 354 Loss 0.205242\n",
            "Time taken for 1 epoch 5.566483020782471 sec\n",
            "\n",
            "Epoch 355 Batch 0 Loss 0.1843\n",
            "Epoch 355 Loss 0.206808\n",
            "Time taken for 1 epoch 5.648881435394287 sec\n",
            "\n",
            "Epoch 356 Batch 0 Loss 0.1875\n",
            "Epoch 356 Loss 0.208393\n",
            "Time taken for 1 epoch 5.703837156295776 sec\n",
            "\n",
            "Epoch 357 Batch 0 Loss 0.1909\n",
            "Epoch 357 Loss 0.213698\n",
            "Time taken for 1 epoch 5.698930025100708 sec\n",
            "\n",
            "Epoch 358 Batch 0 Loss 0.1932\n",
            "Epoch 358 Loss 0.216151\n",
            "Time taken for 1 epoch 5.695736885070801 sec\n",
            "\n",
            "Epoch 359 Batch 0 Loss 0.1903\n",
            "Epoch 359 Loss 0.216814\n",
            "Time taken for 1 epoch 5.608967542648315 sec\n",
            "\n",
            "Epoch 360 Batch 0 Loss 0.1880\n",
            "Epoch 360 Loss 0.222370\n",
            "Time taken for 1 epoch 5.5604424476623535 sec\n",
            "\n",
            "Epoch 361 Batch 0 Loss 0.1965\n",
            "Epoch 361 Loss 0.239163\n",
            "Time taken for 1 epoch 5.502573251724243 sec\n",
            "\n",
            "Epoch 362 Batch 0 Loss 0.2020\n",
            "Epoch 362 Loss 0.278616\n",
            "Time taken for 1 epoch 5.5509703159332275 sec\n",
            "\n",
            "Epoch 363 Batch 0 Loss 0.2390\n",
            "Epoch 363 Loss 0.320502\n",
            "Time taken for 1 epoch 5.6043219566345215 sec\n",
            "\n",
            "Epoch 364 Batch 0 Loss 0.3885\n",
            "Epoch 364 Loss 0.412155\n",
            "Time taken for 1 epoch 5.5776801109313965 sec\n",
            "\n",
            "Epoch 365 Batch 0 Loss 0.5987\n",
            "Epoch 365 Loss 0.539308\n",
            "Time taken for 1 epoch 5.576034784317017 sec\n",
            "\n",
            "Epoch 366 Batch 0 Loss 1.3131\n",
            "Epoch 366 Loss 0.648216\n",
            "Time taken for 1 epoch 5.571971416473389 sec\n",
            "\n",
            "Epoch 367 Batch 0 Loss 1.0541\n",
            "Epoch 367 Loss 0.671762\n",
            "Time taken for 1 epoch 5.590486764907837 sec\n",
            "\n",
            "Epoch 368 Batch 0 Loss 0.8738\n",
            "Epoch 368 Loss 0.588978\n",
            "Time taken for 1 epoch 5.578386306762695 sec\n",
            "\n",
            "Epoch 369 Batch 0 Loss 0.6520\n",
            "Epoch 369 Loss 0.516266\n",
            "Time taken for 1 epoch 5.63679051399231 sec\n",
            "\n",
            "Epoch 370 Batch 0 Loss 0.5191\n",
            "Epoch 370 Loss 0.413421\n",
            "Time taken for 1 epoch 5.519574403762817 sec\n",
            "\n",
            "Epoch 371 Batch 0 Loss 0.3776\n",
            "Epoch 371 Loss 0.351660\n",
            "Time taken for 1 epoch 5.56981897354126 sec\n",
            "\n",
            "Epoch 372 Batch 0 Loss 0.3490\n",
            "Epoch 372 Loss 0.306630\n",
            "Time taken for 1 epoch 6.270885229110718 sec\n",
            "\n",
            "Epoch 373 Batch 0 Loss 0.2692\n",
            "Epoch 373 Loss 0.268098\n",
            "Time taken for 1 epoch 5.640601873397827 sec\n",
            "\n",
            "Epoch 374 Batch 0 Loss 0.2519\n",
            "Epoch 374 Loss 0.244604\n",
            "Time taken for 1 epoch 5.580234050750732 sec\n",
            "\n",
            "Epoch 375 Batch 0 Loss 0.2272\n",
            "Epoch 375 Loss 0.220628\n",
            "Time taken for 1 epoch 5.558684349060059 sec\n",
            "\n",
            "Epoch 376 Batch 0 Loss 0.2100\n",
            "Epoch 376 Loss 0.210958\n",
            "Time taken for 1 epoch 5.4642860889434814 sec\n",
            "\n",
            "Epoch 377 Batch 0 Loss 0.2041\n",
            "Epoch 377 Loss 0.207204\n",
            "Time taken for 1 epoch 5.510453462600708 sec\n",
            "\n",
            "Epoch 378 Batch 0 Loss 0.1988\n",
            "Epoch 378 Loss 0.204453\n",
            "Time taken for 1 epoch 5.537598609924316 sec\n",
            "\n",
            "Epoch 379 Batch 0 Loss 0.1951\n",
            "Epoch 379 Loss 0.203134\n",
            "Time taken for 1 epoch 5.5867838859558105 sec\n",
            "\n",
            "Epoch 380 Batch 0 Loss 0.1922\n",
            "Epoch 380 Loss 0.201585\n",
            "Time taken for 1 epoch 5.473495721817017 sec\n",
            "\n",
            "Epoch 381 Batch 0 Loss 0.1907\n",
            "Epoch 381 Loss 0.201080\n",
            "Time taken for 1 epoch 5.49333643913269 sec\n",
            "\n",
            "Epoch 382 Batch 0 Loss 0.1902\n",
            "Epoch 382 Loss 0.200441\n",
            "Time taken for 1 epoch 5.548545598983765 sec\n",
            "\n",
            "Epoch 383 Batch 0 Loss 0.1917\n",
            "Epoch 383 Loss 0.200196\n",
            "Time taken for 1 epoch 5.461814641952515 sec\n",
            "\n",
            "Epoch 384 Batch 0 Loss 0.1917\n",
            "Epoch 384 Loss 0.199907\n",
            "Time taken for 1 epoch 5.578626871109009 sec\n",
            "\n",
            "Epoch 385 Batch 0 Loss 0.1897\n",
            "Epoch 385 Loss 0.199464\n",
            "Time taken for 1 epoch 5.602954387664795 sec\n",
            "\n",
            "Epoch 386 Batch 0 Loss 0.1890\n",
            "Epoch 386 Loss 0.199021\n",
            "Time taken for 1 epoch 5.536536931991577 sec\n",
            "\n",
            "Epoch 387 Batch 0 Loss 0.1885\n",
            "Epoch 387 Loss 0.199090\n",
            "Time taken for 1 epoch 5.522319793701172 sec\n",
            "\n",
            "Epoch 388 Batch 0 Loss 0.1880\n",
            "Epoch 388 Loss 0.198818\n",
            "Time taken for 1 epoch 5.544016122817993 sec\n",
            "\n",
            "Epoch 389 Batch 0 Loss 0.1878\n",
            "Epoch 389 Loss 0.199660\n",
            "Time taken for 1 epoch 5.520087003707886 sec\n",
            "\n",
            "Epoch 390 Batch 0 Loss 0.1876\n",
            "Epoch 390 Loss 0.200285\n",
            "Time taken for 1 epoch 5.516717910766602 sec\n",
            "\n",
            "Epoch 391 Batch 0 Loss 0.1882\n",
            "Epoch 391 Loss 0.201435\n",
            "Time taken for 1 epoch 5.495628833770752 sec\n",
            "\n",
            "Epoch 392 Batch 0 Loss 0.1914\n",
            "Epoch 392 Loss 0.202115\n",
            "Time taken for 1 epoch 5.5126729011535645 sec\n",
            "\n",
            "Epoch 393 Batch 0 Loss 0.1912\n",
            "Epoch 393 Loss 0.204547\n",
            "Time taken for 1 epoch 5.585126876831055 sec\n",
            "\n",
            "Epoch 394 Batch 0 Loss 0.1872\n",
            "Epoch 394 Loss 0.205487\n",
            "Time taken for 1 epoch 5.558260679244995 sec\n",
            "\n",
            "Epoch 395 Batch 0 Loss 0.1905\n",
            "Epoch 395 Loss 0.205012\n",
            "Time taken for 1 epoch 5.542774677276611 sec\n",
            "\n",
            "Epoch 396 Batch 0 Loss 0.1909\n",
            "Epoch 396 Loss 0.206411\n",
            "Time taken for 1 epoch 5.6285560131073 sec\n",
            "\n",
            "Epoch 397 Batch 0 Loss 0.1866\n",
            "Epoch 397 Loss 0.203909\n",
            "Time taken for 1 epoch 5.535760402679443 sec\n",
            "\n",
            "Epoch 398 Batch 0 Loss 0.1885\n",
            "Epoch 398 Loss 0.201860\n",
            "Time taken for 1 epoch 5.601446628570557 sec\n",
            "\n",
            "Epoch 399 Batch 0 Loss 0.1899\n",
            "Epoch 399 Loss 0.201240\n",
            "Time taken for 1 epoch 5.605133533477783 sec\n",
            "\n",
            "Epoch 400 Batch 0 Loss 0.1862\n",
            "Epoch 400 Loss 0.199442\n",
            "Time taken for 1 epoch 5.5330421924591064 sec\n",
            "\n",
            "Epoch 401 Batch 0 Loss 0.1863\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "smoke laying on coconut herd of outside view jets outside herd of smoke standing outside view outside at sunset outside view outside at sunset\n",
            "Epoch 401 Loss 0.197878\n",
            "Time taken for 1 epoch 6.169795989990234 sec\n",
            "\n",
            "Epoch 402 Batch 0 Loss 0.1862\n",
            "Epoch 402 Loss 0.198099\n",
            "Time taken for 1 epoch 5.466485261917114 sec\n",
            "\n",
            "Epoch 403 Batch 0 Loss 0.1854\n",
            "Epoch 403 Loss 0.197217\n",
            "Time taken for 1 epoch 5.619102716445923 sec\n",
            "\n",
            "Epoch 404 Batch 0 Loss 0.1846\n",
            "Epoch 404 Loss 0.197554\n",
            "Time taken for 1 epoch 6.48595118522644 sec\n",
            "\n",
            "Epoch 405 Batch 0 Loss 0.1845\n",
            "Epoch 405 Loss 0.198168\n",
            "Time taken for 1 epoch 6.008816957473755 sec\n",
            "\n",
            "Epoch 406 Batch 0 Loss 0.1850\n",
            "Epoch 406 Loss 0.197961\n",
            "Time taken for 1 epoch 5.5748960971832275 sec\n",
            "\n",
            "Epoch 407 Batch 0 Loss 0.1848\n",
            "Epoch 407 Loss 0.198507\n",
            "Time taken for 1 epoch 5.5411365032196045 sec\n",
            "\n",
            "Epoch 408 Batch 0 Loss 0.1839\n",
            "Epoch 408 Loss 0.201486\n",
            "Time taken for 1 epoch 5.545781373977661 sec\n",
            "\n",
            "Epoch 409 Batch 0 Loss 0.1846\n",
            "Epoch 409 Loss 0.203176\n",
            "Time taken for 1 epoch 5.563012361526489 sec\n",
            "\n",
            "Epoch 410 Batch 0 Loss 0.1856\n",
            "Epoch 410 Loss 0.203374\n",
            "Time taken for 1 epoch 5.6247406005859375 sec\n",
            "\n",
            "Epoch 411 Batch 0 Loss 0.1864\n",
            "Epoch 411 Loss 0.205256\n",
            "Time taken for 1 epoch 5.636569976806641 sec\n",
            "\n",
            "Epoch 412 Batch 0 Loss 0.1916\n",
            "Epoch 412 Loss 0.206452\n",
            "Time taken for 1 epoch 5.547579288482666 sec\n",
            "\n",
            "Epoch 413 Batch 0 Loss 0.1929\n",
            "Epoch 413 Loss 0.206726\n",
            "Time taken for 1 epoch 5.621769189834595 sec\n",
            "\n",
            "Epoch 414 Batch 0 Loss 0.1909\n",
            "Epoch 414 Loss 0.202759\n",
            "Time taken for 1 epoch 5.576801538467407 sec\n",
            "\n",
            "Epoch 415 Batch 0 Loss 0.1882\n",
            "Epoch 415 Loss 0.199033\n",
            "Time taken for 1 epoch 5.567729711532593 sec\n",
            "\n",
            "Epoch 416 Batch 0 Loss 0.1898\n",
            "Epoch 416 Loss 0.199308\n",
            "Time taken for 1 epoch 5.555110692977905 sec\n",
            "\n",
            "Epoch 417 Batch 0 Loss 0.1867\n",
            "Epoch 417 Loss 0.198077\n",
            "Time taken for 1 epoch 5.574136972427368 sec\n",
            "\n",
            "Epoch 418 Batch 0 Loss 0.1870\n",
            "Epoch 418 Loss 0.197379\n",
            "Time taken for 1 epoch 5.585176706314087 sec\n",
            "\n",
            "Epoch 419 Batch 0 Loss 0.1852\n",
            "Epoch 419 Loss 0.198593\n",
            "Time taken for 1 epoch 5.617387533187866 sec\n",
            "\n",
            "Epoch 420 Batch 0 Loss 0.1849\n",
            "Epoch 420 Loss 0.198954\n",
            "Time taken for 1 epoch 5.542595863342285 sec\n",
            "\n",
            "Epoch 421 Batch 0 Loss 0.1827\n",
            "Epoch 421 Loss 0.198398\n",
            "Time taken for 1 epoch 5.6134302616119385 sec\n",
            "\n",
            "Epoch 422 Batch 0 Loss 0.1826\n",
            "Epoch 422 Loss 0.198514\n",
            "Time taken for 1 epoch 5.585618495941162 sec\n",
            "\n",
            "Epoch 423 Batch 0 Loss 0.1842\n",
            "Epoch 423 Loss 0.198196\n",
            "Time taken for 1 epoch 5.560080289840698 sec\n",
            "\n",
            "Epoch 424 Batch 0 Loss 0.1848\n",
            "Epoch 424 Loss 0.198866\n",
            "Time taken for 1 epoch 5.583728790283203 sec\n",
            "\n",
            "Epoch 425 Batch 0 Loss 0.1836\n",
            "Epoch 425 Loss 0.198710\n",
            "Time taken for 1 epoch 5.593790292739868 sec\n",
            "\n",
            "Epoch 426 Batch 0 Loss 0.1858\n",
            "Epoch 426 Loss 0.198494\n",
            "Time taken for 1 epoch 5.689557790756226 sec\n",
            "\n",
            "Epoch 427 Batch 0 Loss 0.1850\n",
            "Epoch 427 Loss 0.198631\n",
            "Time taken for 1 epoch 6.259113073348999 sec\n",
            "\n",
            "Epoch 428 Batch 0 Loss 0.1817\n",
            "Epoch 428 Loss 0.197843\n",
            "Time taken for 1 epoch 5.649948358535767 sec\n",
            "\n",
            "Epoch 429 Batch 0 Loss 0.1827\n",
            "Epoch 429 Loss 0.198380\n",
            "Time taken for 1 epoch 5.663751840591431 sec\n",
            "\n",
            "Epoch 430 Batch 0 Loss 0.1843\n",
            "Epoch 430 Loss 0.199609\n",
            "Time taken for 1 epoch 5.562050104141235 sec\n",
            "\n",
            "Epoch 431 Batch 0 Loss 0.1845\n",
            "Epoch 431 Loss 0.198213\n",
            "Time taken for 1 epoch 5.5766565799713135 sec\n",
            "\n",
            "Epoch 432 Batch 0 Loss 0.1870\n",
            "Epoch 432 Loss 0.197671\n",
            "Time taken for 1 epoch 5.513075828552246 sec\n",
            "\n",
            "Epoch 433 Batch 0 Loss 0.1858\n",
            "Epoch 433 Loss 0.198222\n",
            "Time taken for 1 epoch 5.553545951843262 sec\n",
            "\n",
            "Epoch 434 Batch 0 Loss 0.1863\n",
            "Epoch 434 Loss 0.202456\n",
            "Time taken for 1 epoch 5.603227615356445 sec\n",
            "\n",
            "Epoch 435 Batch 0 Loss 0.1889\n",
            "Epoch 435 Loss 0.208478\n",
            "Time taken for 1 epoch 5.56428337097168 sec\n",
            "\n",
            "Epoch 436 Batch 0 Loss 0.1880\n",
            "Epoch 436 Loss 0.216431\n",
            "Time taken for 1 epoch 5.601260662078857 sec\n",
            "\n",
            "Epoch 437 Batch 0 Loss 0.1918\n",
            "Epoch 437 Loss 0.231955\n",
            "Time taken for 1 epoch 5.594360589981079 sec\n",
            "\n",
            "Epoch 438 Batch 0 Loss 0.2211\n",
            "Epoch 438 Loss 0.265455\n",
            "Time taken for 1 epoch 5.529155254364014 sec\n",
            "\n",
            "Epoch 439 Batch 0 Loss 0.2651\n",
            "Epoch 439 Loss 0.305848\n",
            "Time taken for 1 epoch 5.580028772354126 sec\n",
            "\n",
            "Epoch 440 Batch 0 Loss 0.3299\n",
            "Epoch 440 Loss 0.333821\n",
            "Time taken for 1 epoch 5.547574758529663 sec\n",
            "\n",
            "Epoch 441 Batch 0 Loss 0.3167\n",
            "Epoch 441 Loss 0.345249\n",
            "Time taken for 1 epoch 5.514214754104614 sec\n",
            "\n",
            "Epoch 442 Batch 0 Loss 0.2778\n",
            "Epoch 442 Loss 0.327995\n",
            "Time taken for 1 epoch 5.574490308761597 sec\n",
            "\n",
            "Epoch 443 Batch 0 Loss 0.2899\n",
            "Epoch 443 Loss 0.311089\n",
            "Time taken for 1 epoch 5.56046199798584 sec\n",
            "\n",
            "Epoch 444 Batch 0 Loss 0.2711\n",
            "Epoch 444 Loss 0.343551\n",
            "Time taken for 1 epoch 5.526301383972168 sec\n",
            "\n",
            "Epoch 445 Batch 0 Loss 0.2529\n",
            "Epoch 445 Loss 0.386518\n",
            "Time taken for 1 epoch 5.584906816482544 sec\n",
            "\n",
            "Epoch 446 Batch 0 Loss 0.2963\n",
            "Epoch 446 Loss 0.355944\n",
            "Time taken for 1 epoch 5.53500771522522 sec\n",
            "\n",
            "Epoch 447 Batch 0 Loss 0.2727\n",
            "Epoch 447 Loss 0.321680\n",
            "Time taken for 1 epoch 5.502896070480347 sec\n",
            "\n",
            "Epoch 448 Batch 0 Loss 0.2310\n",
            "Epoch 448 Loss 0.277975\n",
            "Time taken for 1 epoch 5.557286262512207 sec\n",
            "\n",
            "Epoch 449 Batch 0 Loss 0.2294\n",
            "Epoch 449 Loss 0.248758\n",
            "Time taken for 1 epoch 5.555132865905762 sec\n",
            "\n",
            "Epoch 450 Batch 0 Loss 0.2118\n",
            "Epoch 450 Loss 0.225148\n",
            "Time taken for 1 epoch 5.578333616256714 sec\n",
            "\n",
            "Epoch 451 Batch 0 Loss 0.1923\n",
            "Epoch 451 Loss 0.210255\n",
            "Time taken for 1 epoch 5.515902280807495 sec\n",
            "\n",
            "Epoch 452 Batch 0 Loss 0.1894\n",
            "Epoch 452 Loss 0.202450\n",
            "Time taken for 1 epoch 5.513815641403198 sec\n",
            "\n",
            "Epoch 453 Batch 0 Loss 0.1833\n",
            "Epoch 453 Loss 0.199096\n",
            "Time taken for 1 epoch 5.568795442581177 sec\n",
            "\n",
            "Epoch 454 Batch 0 Loss 0.1824\n",
            "Epoch 454 Loss 0.197577\n",
            "Time taken for 1 epoch 5.6266865730285645 sec\n",
            "\n",
            "Epoch 455 Batch 0 Loss 0.1826\n",
            "Epoch 455 Loss 0.197706\n",
            "Time taken for 1 epoch 5.602935075759888 sec\n",
            "\n",
            "Epoch 456 Batch 0 Loss 0.1831\n",
            "Epoch 456 Loss 0.197806\n",
            "Time taken for 1 epoch 5.5938520431518555 sec\n",
            "\n",
            "Epoch 457 Batch 0 Loss 0.1812\n",
            "Epoch 457 Loss 0.197738\n",
            "Time taken for 1 epoch 5.597916841506958 sec\n",
            "\n",
            "Epoch 458 Batch 0 Loss 0.1815\n",
            "Epoch 458 Loss 0.198616\n",
            "Time taken for 1 epoch 5.542659044265747 sec\n",
            "\n",
            "Epoch 459 Batch 0 Loss 0.1820\n",
            "Epoch 459 Loss 0.199238\n",
            "Time taken for 1 epoch 6.204158782958984 sec\n",
            "\n",
            "Epoch 460 Batch 0 Loss 0.1822\n",
            "Epoch 460 Loss 0.199477\n",
            "Time taken for 1 epoch 6.5328428745269775 sec\n",
            "\n",
            "Epoch 461 Batch 0 Loss 0.1820\n",
            "Epoch 461 Loss 0.199057\n",
            "Time taken for 1 epoch 5.571139574050903 sec\n",
            "\n",
            "Epoch 462 Batch 0 Loss 0.1820\n",
            "Epoch 462 Loss 0.197848\n",
            "Time taken for 1 epoch 5.568312406539917 sec\n",
            "\n",
            "Epoch 463 Batch 0 Loss 0.1839\n",
            "Epoch 463 Loss 0.198379\n",
            "Time taken for 1 epoch 5.595883369445801 sec\n",
            "\n",
            "Epoch 464 Batch 0 Loss 0.1859\n",
            "Epoch 464 Loss 0.198789\n",
            "Time taken for 1 epoch 5.600642919540405 sec\n",
            "\n",
            "Epoch 465 Batch 0 Loss 0.1826\n",
            "Epoch 465 Loss 0.197652\n",
            "Time taken for 1 epoch 5.554492473602295 sec\n",
            "\n",
            "Epoch 466 Batch 0 Loss 0.1834\n",
            "Epoch 466 Loss 0.198396\n",
            "Time taken for 1 epoch 5.570378065109253 sec\n",
            "\n",
            "Epoch 467 Batch 0 Loss 0.1824\n",
            "Epoch 467 Loss 0.198366\n",
            "Time taken for 1 epoch 5.636728763580322 sec\n",
            "\n",
            "Epoch 468 Batch 0 Loss 0.1845\n",
            "Epoch 468 Loss 0.198229\n",
            "Time taken for 1 epoch 5.667118549346924 sec\n",
            "\n",
            "Epoch 469 Batch 0 Loss 0.1834\n",
            "Epoch 469 Loss 0.198932\n",
            "Time taken for 1 epoch 5.6959779262542725 sec\n",
            "\n",
            "Epoch 470 Batch 0 Loss 0.1813\n",
            "Epoch 470 Loss 0.198735\n",
            "Time taken for 1 epoch 5.614472150802612 sec\n",
            "\n",
            "Epoch 471 Batch 0 Loss 0.1825\n",
            "Epoch 471 Loss 0.198202\n",
            "Time taken for 1 epoch 5.643967628479004 sec\n",
            "\n",
            "Epoch 472 Batch 0 Loss 0.1828\n",
            "Epoch 472 Loss 0.199700\n",
            "Time taken for 1 epoch 5.583772420883179 sec\n",
            "\n",
            "Epoch 473 Batch 0 Loss 0.1815\n",
            "Epoch 473 Loss 0.198778\n",
            "Time taken for 1 epoch 5.5220255851745605 sec\n",
            "\n",
            "Epoch 474 Batch 0 Loss 0.1825\n",
            "Epoch 474 Loss 0.199614\n",
            "Time taken for 1 epoch 5.566670179367065 sec\n",
            "\n",
            "Epoch 475 Batch 0 Loss 0.1835\n",
            "Epoch 475 Loss 0.200682\n",
            "Time taken for 1 epoch 5.601015567779541 sec\n",
            "\n",
            "Epoch 476 Batch 0 Loss 0.1833\n",
            "Epoch 476 Loss 0.197689\n",
            "Time taken for 1 epoch 5.657932281494141 sec\n",
            "\n",
            "Epoch 477 Batch 0 Loss 0.1823\n",
            "Epoch 477 Loss 0.197683\n",
            "Time taken for 1 epoch 5.621054410934448 sec\n",
            "\n",
            "Epoch 478 Batch 0 Loss 0.1799\n",
            "Epoch 478 Loss 0.197237\n",
            "Time taken for 1 epoch 5.549234390258789 sec\n",
            "\n",
            "Epoch 479 Batch 0 Loss 0.1826\n",
            "Epoch 479 Loss 0.198065\n",
            "Time taken for 1 epoch 5.53984260559082 sec\n",
            "\n",
            "Epoch 480 Batch 0 Loss 0.1825\n",
            "Epoch 480 Loss 0.197809\n",
            "Time taken for 1 epoch 5.5723488330841064 sec\n",
            "\n",
            "Epoch 481 Batch 0 Loss 0.1823\n",
            "Epoch 481 Loss 0.197795\n",
            "Time taken for 1 epoch 6.167275428771973 sec\n",
            "\n",
            "Epoch 482 Batch 0 Loss 0.1853\n",
            "Epoch 482 Loss 0.196584\n",
            "Time taken for 1 epoch 5.77140736579895 sec\n",
            "\n",
            "Epoch 483 Batch 0 Loss 0.1889\n",
            "Epoch 483 Loss 0.198080\n",
            "Time taken for 1 epoch 5.518365383148193 sec\n",
            "\n",
            "Epoch 484 Batch 0 Loss 0.1846\n",
            "Epoch 484 Loss 0.198376\n",
            "Time taken for 1 epoch 5.530998468399048 sec\n",
            "\n",
            "Epoch 485 Batch 0 Loss 0.1848\n",
            "Epoch 485 Loss 0.198575\n",
            "Time taken for 1 epoch 5.5268614292144775 sec\n",
            "\n",
            "Epoch 486 Batch 0 Loss 0.1834\n",
            "Epoch 486 Loss 0.201316\n",
            "Time taken for 1 epoch 5.567541122436523 sec\n",
            "\n",
            "Epoch 487 Batch 0 Loss 0.1853\n",
            "Epoch 487 Loss 0.200381\n",
            "Time taken for 1 epoch 5.549649477005005 sec\n",
            "\n",
            "Epoch 488 Batch 0 Loss 0.1869\n",
            "Epoch 488 Loss 0.198363\n",
            "Time taken for 1 epoch 5.5637006759643555 sec\n",
            "\n",
            "Epoch 489 Batch 0 Loss 0.1866\n",
            "Epoch 489 Loss 0.198642\n",
            "Time taken for 1 epoch 5.532562255859375 sec\n",
            "\n",
            "Epoch 490 Batch 0 Loss 0.1867\n",
            "Epoch 490 Loss 0.197351\n",
            "Time taken for 1 epoch 5.633245468139648 sec\n",
            "\n",
            "Epoch 491 Batch 0 Loss 0.1881\n",
            "Epoch 491 Loss 0.197443\n",
            "Time taken for 1 epoch 5.53812050819397 sec\n",
            "\n",
            "Epoch 492 Batch 0 Loss 0.1860\n",
            "Epoch 492 Loss 0.196532\n",
            "Time taken for 1 epoch 5.545506715774536 sec\n",
            "\n",
            "Epoch 493 Batch 0 Loss 0.1828\n",
            "Epoch 493 Loss 0.196211\n",
            "Time taken for 1 epoch 5.545318603515625 sec\n",
            "\n",
            "Epoch 494 Batch 0 Loss 0.1837\n",
            "Epoch 494 Loss 0.197077\n",
            "Time taken for 1 epoch 5.53838849067688 sec\n",
            "\n",
            "Epoch 495 Batch 0 Loss 0.1818\n",
            "Epoch 495 Loss 0.196753\n",
            "Time taken for 1 epoch 5.603239297866821 sec\n",
            "\n",
            "Epoch 496 Batch 0 Loss 0.1815\n",
            "Epoch 496 Loss 0.196280\n",
            "Time taken for 1 epoch 5.536275386810303 sec\n",
            "\n",
            "Epoch 497 Batch 0 Loss 0.1811\n",
            "Epoch 497 Loss 0.197989\n",
            "Time taken for 1 epoch 5.514953374862671 sec\n",
            "\n",
            "Epoch 498 Batch 0 Loss 0.1813\n",
            "Epoch 498 Loss 0.197081\n",
            "Time taken for 1 epoch 5.5390098094940186 sec\n",
            "\n",
            "Epoch 499 Batch 0 Loss 0.1829\n",
            "Epoch 499 Loss 0.197566\n",
            "Time taken for 1 epoch 5.577744245529175 sec\n",
            "\n",
            "Epoch 500 Batch 0 Loss 0.1842\n",
            "Epoch 500 Loss 0.197861\n",
            "Time taken for 1 epoch 5.520804166793823 sec\n",
            "\n",
            "Epoch 501 Batch 0 Loss 0.1831\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "coconut outside flying outside herd of smoke outside herd of outside of coconut outside herd of smoke outside kitten herd of outside standing outside\n",
            "Epoch 501 Loss 0.196442\n",
            "Time taken for 1 epoch 6.1700122356414795 sec\n",
            "\n",
            "Epoch 502 Batch 0 Loss 0.1832\n",
            "Epoch 502 Loss 0.196215\n",
            "Time taken for 1 epoch 5.546503067016602 sec\n",
            "\n",
            "Epoch 503 Batch 0 Loss 0.1811\n",
            "Epoch 503 Loss 0.195197\n",
            "Time taken for 1 epoch 5.555927276611328 sec\n",
            "\n",
            "Epoch 504 Batch 0 Loss 0.1807\n",
            "Epoch 504 Loss 0.194776\n",
            "Time taken for 1 epoch 5.557477235794067 sec\n",
            "\n",
            "Epoch 505 Batch 0 Loss 0.1811\n",
            "Epoch 505 Loss 0.195523\n",
            "Time taken for 1 epoch 5.564814567565918 sec\n",
            "\n",
            "Epoch 506 Batch 0 Loss 0.1808\n",
            "Epoch 506 Loss 0.195625\n",
            "Time taken for 1 epoch 5.569365978240967 sec\n",
            "\n",
            "Epoch 507 Batch 0 Loss 0.1809\n",
            "Epoch 507 Loss 0.196196\n",
            "Time taken for 1 epoch 5.535959005355835 sec\n",
            "\n",
            "Epoch 508 Batch 0 Loss 0.1814\n",
            "Epoch 508 Loss 0.196492\n",
            "Time taken for 1 epoch 5.544604301452637 sec\n",
            "\n",
            "Epoch 509 Batch 0 Loss 0.1831\n",
            "Epoch 509 Loss 0.196651\n",
            "Time taken for 1 epoch 5.56223464012146 sec\n",
            "\n",
            "Epoch 510 Batch 0 Loss 0.1832\n",
            "Epoch 510 Loss 0.197004\n",
            "Time taken for 1 epoch 5.535209655761719 sec\n",
            "\n",
            "Epoch 511 Batch 0 Loss 0.1807\n",
            "Epoch 511 Loss 0.196470\n",
            "Time taken for 1 epoch 5.556835889816284 sec\n",
            "\n",
            "Epoch 512 Batch 0 Loss 0.1828\n",
            "Epoch 512 Loss 0.196779\n",
            "Time taken for 1 epoch 5.573622703552246 sec\n",
            "\n",
            "Epoch 513 Batch 0 Loss 0.1848\n",
            "Epoch 513 Loss 0.197961\n",
            "Time taken for 1 epoch 5.696249723434448 sec\n",
            "\n",
            "Epoch 514 Batch 0 Loss 0.1833\n",
            "Epoch 514 Loss 0.199256\n",
            "Time taken for 1 epoch 5.770530462265015 sec\n",
            "\n",
            "Epoch 515 Batch 0 Loss 0.1846\n",
            "Epoch 515 Loss 0.198040\n",
            "Time taken for 1 epoch 6.625075817108154 sec\n",
            "\n",
            "Epoch 516 Batch 0 Loss 0.1846\n",
            "Epoch 516 Loss 0.198377\n",
            "Time taken for 1 epoch 5.972463369369507 sec\n",
            "\n",
            "Epoch 517 Batch 0 Loss 0.1823\n",
            "Epoch 517 Loss 0.198510\n",
            "Time taken for 1 epoch 5.63855767250061 sec\n",
            "\n",
            "Epoch 518 Batch 0 Loss 0.1829\n",
            "Epoch 518 Loss 0.201296\n",
            "Time taken for 1 epoch 5.603123426437378 sec\n",
            "\n",
            "Epoch 519 Batch 0 Loss 0.1811\n",
            "Epoch 519 Loss 0.200243\n",
            "Time taken for 1 epoch 5.596764802932739 sec\n",
            "\n",
            "Epoch 520 Batch 0 Loss 0.1840\n",
            "Epoch 520 Loss 0.201842\n",
            "Time taken for 1 epoch 5.641830682754517 sec\n",
            "\n",
            "Epoch 521 Batch 0 Loss 0.1895\n",
            "Epoch 521 Loss 0.205959\n",
            "Time taken for 1 epoch 5.578206300735474 sec\n",
            "\n",
            "Epoch 522 Batch 0 Loss 0.1955\n",
            "Epoch 522 Loss 0.218788\n",
            "Time taken for 1 epoch 5.597676515579224 sec\n",
            "\n",
            "Epoch 523 Batch 0 Loss 0.1995\n",
            "Epoch 523 Loss 0.246064\n",
            "Time taken for 1 epoch 5.662925720214844 sec\n",
            "\n",
            "Epoch 524 Batch 0 Loss 0.2302\n",
            "Epoch 524 Loss 0.284984\n",
            "Time taken for 1 epoch 5.576306104660034 sec\n",
            "\n",
            "Epoch 525 Batch 0 Loss 0.2893\n",
            "Epoch 525 Loss 0.339586\n",
            "Time taken for 1 epoch 5.6322877407073975 sec\n",
            "\n",
            "Epoch 526 Batch 0 Loss 0.3338\n",
            "Epoch 526 Loss 0.395393\n",
            "Time taken for 1 epoch 5.515917062759399 sec\n",
            "\n",
            "Epoch 527 Batch 0 Loss 0.3654\n",
            "Epoch 527 Loss 0.443372\n",
            "Time taken for 1 epoch 5.554374694824219 sec\n",
            "\n",
            "Epoch 528 Batch 0 Loss 0.3615\n",
            "Epoch 528 Loss 0.459610\n",
            "Time taken for 1 epoch 5.565292835235596 sec\n",
            "\n",
            "Epoch 529 Batch 0 Loss 0.4482\n",
            "Epoch 529 Loss 0.502154\n",
            "Time taken for 1 epoch 5.570293426513672 sec\n",
            "\n",
            "Epoch 530 Batch 0 Loss 0.4471\n",
            "Epoch 530 Loss 0.522483\n",
            "Time taken for 1 epoch 5.582064867019653 sec\n",
            "\n",
            "Epoch 531 Batch 0 Loss 0.4171\n",
            "Epoch 531 Loss 0.463251\n",
            "Time taken for 1 epoch 5.601051330566406 sec\n",
            "\n",
            "Epoch 532 Batch 0 Loss 0.3886\n",
            "Epoch 532 Loss 0.387000\n",
            "Time taken for 1 epoch 5.572681903839111 sec\n",
            "\n",
            "Epoch 533 Batch 0 Loss 0.3353\n",
            "Epoch 533 Loss 0.322885\n",
            "Time taken for 1 epoch 5.603546142578125 sec\n",
            "\n",
            "Epoch 534 Batch 0 Loss 0.2718\n",
            "Epoch 534 Loss 0.275612\n",
            "Time taken for 1 epoch 5.546897888183594 sec\n",
            "\n",
            "Epoch 535 Batch 0 Loss 0.2248\n",
            "Epoch 535 Loss 0.238307\n",
            "Time taken for 1 epoch 5.6899261474609375 sec\n",
            "\n",
            "Epoch 536 Batch 0 Loss 0.2132\n",
            "Epoch 536 Loss 0.218280\n",
            "Time taken for 1 epoch 6.149783611297607 sec\n",
            "\n",
            "Epoch 537 Batch 0 Loss 0.1988\n",
            "Epoch 537 Loss 0.206379\n",
            "Time taken for 1 epoch 5.51349663734436 sec\n",
            "\n",
            "Epoch 538 Batch 0 Loss 0.1921\n",
            "Epoch 538 Loss 0.201522\n",
            "Time taken for 1 epoch 5.545125722885132 sec\n",
            "\n",
            "Epoch 539 Batch 0 Loss 0.1880\n",
            "Epoch 539 Loss 0.199159\n",
            "Time taken for 1 epoch 5.525010347366333 sec\n",
            "\n",
            "Epoch 540 Batch 0 Loss 0.1870\n",
            "Epoch 540 Loss 0.198828\n",
            "Time taken for 1 epoch 5.53499174118042 sec\n",
            "\n",
            "Epoch 541 Batch 0 Loss 0.1844\n",
            "Epoch 541 Loss 0.197434\n",
            "Time taken for 1 epoch 5.601967811584473 sec\n",
            "\n",
            "Epoch 542 Batch 0 Loss 0.1832\n",
            "Epoch 542 Loss 0.197566\n",
            "Time taken for 1 epoch 5.659778118133545 sec\n",
            "\n",
            "Epoch 543 Batch 0 Loss 0.1831\n",
            "Epoch 543 Loss 0.198540\n",
            "Time taken for 1 epoch 5.58927583694458 sec\n",
            "\n",
            "Epoch 544 Batch 0 Loss 0.1841\n",
            "Epoch 544 Loss 0.198646\n",
            "Time taken for 1 epoch 5.595035076141357 sec\n",
            "\n",
            "Epoch 545 Batch 0 Loss 0.1843\n",
            "Epoch 545 Loss 0.198374\n",
            "Time taken for 1 epoch 5.6394264698028564 sec\n",
            "\n",
            "Epoch 546 Batch 0 Loss 0.1827\n",
            "Epoch 546 Loss 0.199557\n",
            "Time taken for 1 epoch 5.620769262313843 sec\n",
            "\n",
            "Epoch 547 Batch 0 Loss 0.1855\n",
            "Epoch 547 Loss 0.198535\n",
            "Time taken for 1 epoch 5.665137767791748 sec\n",
            "\n",
            "Epoch 548 Batch 0 Loss 0.1886\n",
            "Epoch 548 Loss 0.198530\n",
            "Time taken for 1 epoch 5.535215139389038 sec\n",
            "\n",
            "Epoch 549 Batch 0 Loss 0.1887\n",
            "Epoch 549 Loss 0.198054\n",
            "Time taken for 1 epoch 5.6120076179504395 sec\n",
            "\n",
            "Epoch 550 Batch 0 Loss 0.1882\n",
            "Epoch 550 Loss 0.196842\n",
            "Time taken for 1 epoch 5.574559211730957 sec\n",
            "\n",
            "Epoch 551 Batch 0 Loss 0.1850\n",
            "Epoch 551 Loss 0.196277\n",
            "Time taken for 1 epoch 5.5709850788116455 sec\n",
            "\n",
            "Epoch 552 Batch 0 Loss 0.1819\n",
            "Epoch 552 Loss 0.195248\n",
            "Time taken for 1 epoch 5.721355199813843 sec\n",
            "\n",
            "Epoch 553 Batch 0 Loss 0.1819\n",
            "Epoch 553 Loss 0.194751\n",
            "Time taken for 1 epoch 5.575478553771973 sec\n",
            "\n",
            "Epoch 554 Batch 0 Loss 0.1818\n",
            "Epoch 554 Loss 0.195573\n",
            "Time taken for 1 epoch 5.65455174446106 sec\n",
            "\n",
            "Epoch 555 Batch 0 Loss 0.1806\n",
            "Epoch 555 Loss 0.195214\n",
            "Time taken for 1 epoch 5.5927956104278564 sec\n",
            "\n",
            "Epoch 556 Batch 0 Loss 0.1826\n",
            "Epoch 556 Loss 0.195995\n",
            "Time taken for 1 epoch 5.69387674331665 sec\n",
            "\n",
            "Epoch 557 Batch 0 Loss 0.1840\n",
            "Epoch 557 Loss 0.196113\n",
            "Time taken for 1 epoch 5.605247259140015 sec\n",
            "\n",
            "Epoch 558 Batch 0 Loss 0.1847\n",
            "Epoch 558 Loss 0.195720\n",
            "Time taken for 1 epoch 5.567188501358032 sec\n",
            "\n",
            "Epoch 559 Batch 0 Loss 0.1827\n",
            "Epoch 559 Loss 0.195997\n",
            "Time taken for 1 epoch 5.533062219619751 sec\n",
            "\n",
            "Epoch 560 Batch 0 Loss 0.1821\n",
            "Epoch 560 Loss 0.196288\n",
            "Time taken for 1 epoch 5.57705545425415 sec\n",
            "\n",
            "Epoch 561 Batch 0 Loss 0.1822\n",
            "Epoch 561 Loss 0.195647\n",
            "Time taken for 1 epoch 5.577420234680176 sec\n",
            "\n",
            "Epoch 562 Batch 0 Loss 0.1837\n",
            "Epoch 562 Loss 0.196362\n",
            "Time taken for 1 epoch 5.549346208572388 sec\n",
            "\n",
            "Epoch 563 Batch 0 Loss 0.1813\n",
            "Epoch 563 Loss 0.195471\n",
            "Time taken for 1 epoch 5.5918073654174805 sec\n",
            "\n",
            "Epoch 564 Batch 0 Loss 0.1806\n",
            "Epoch 564 Loss 0.195621\n",
            "Time taken for 1 epoch 5.54777979850769 sec\n",
            "\n",
            "Epoch 565 Batch 0 Loss 0.1798\n",
            "Epoch 565 Loss 0.195382\n",
            "Time taken for 1 epoch 5.60336709022522 sec\n",
            "\n",
            "Epoch 566 Batch 0 Loss 0.1816\n",
            "Epoch 566 Loss 0.194721\n",
            "Time taken for 1 epoch 5.619149923324585 sec\n",
            "\n",
            "Epoch 567 Batch 0 Loss 0.1826\n",
            "Epoch 567 Loss 0.195170\n",
            "Time taken for 1 epoch 5.609173774719238 sec\n",
            "\n",
            "Epoch 568 Batch 0 Loss 0.1803\n",
            "Epoch 568 Loss 0.195338\n",
            "Time taken for 1 epoch 5.620793342590332 sec\n",
            "\n",
            "Epoch 569 Batch 0 Loss 0.1820\n",
            "Epoch 569 Loss 0.195129\n",
            "Time taken for 1 epoch 5.581692218780518 sec\n",
            "\n",
            "Epoch 570 Batch 0 Loss 0.1821\n",
            "Epoch 570 Loss 0.195651\n",
            "Time taken for 1 epoch 6.434582233428955 sec\n",
            "\n",
            "Epoch 571 Batch 0 Loss 0.1796\n",
            "Epoch 571 Loss 0.195949\n",
            "Time taken for 1 epoch 6.068339109420776 sec\n",
            "\n",
            "Epoch 572 Batch 0 Loss 0.1816\n",
            "Epoch 572 Loss 0.195511\n",
            "Time taken for 1 epoch 5.523592233657837 sec\n",
            "\n",
            "Epoch 573 Batch 0 Loss 0.1816\n",
            "Epoch 573 Loss 0.196456\n",
            "Time taken for 1 epoch 5.575103759765625 sec\n",
            "\n",
            "Epoch 574 Batch 0 Loss 0.1793\n",
            "Epoch 574 Loss 0.195830\n",
            "Time taken for 1 epoch 5.568472623825073 sec\n",
            "\n",
            "Epoch 575 Batch 0 Loss 0.1811\n",
            "Epoch 575 Loss 0.194933\n",
            "Time taken for 1 epoch 5.599065065383911 sec\n",
            "\n",
            "Epoch 576 Batch 0 Loss 0.1836\n",
            "Epoch 576 Loss 0.194851\n",
            "Time taken for 1 epoch 5.550556421279907 sec\n",
            "\n",
            "Epoch 577 Batch 0 Loss 0.1831\n",
            "Epoch 577 Loss 0.194137\n",
            "Time taken for 1 epoch 5.5827131271362305 sec\n",
            "\n",
            "Epoch 578 Batch 0 Loss 0.1819\n",
            "Epoch 578 Loss 0.194871\n",
            "Time taken for 1 epoch 5.505770444869995 sec\n",
            "\n",
            "Epoch 579 Batch 0 Loss 0.1810\n",
            "Epoch 579 Loss 0.195176\n",
            "Time taken for 1 epoch 5.542616605758667 sec\n",
            "\n",
            "Epoch 580 Batch 0 Loss 0.1810\n",
            "Epoch 580 Loss 0.195505\n",
            "Time taken for 1 epoch 5.526808023452759 sec\n",
            "\n",
            "Epoch 581 Batch 0 Loss 0.1815\n",
            "Epoch 581 Loss 0.195233\n",
            "Time taken for 1 epoch 5.579807281494141 sec\n",
            "\n",
            "Epoch 582 Batch 0 Loss 0.1820\n",
            "Epoch 582 Loss 0.194603\n",
            "Time taken for 1 epoch 5.574748992919922 sec\n",
            "\n",
            "Epoch 583 Batch 0 Loss 0.1851\n",
            "Epoch 583 Loss 0.196278\n",
            "Time taken for 1 epoch 5.603993654251099 sec\n",
            "\n",
            "Epoch 584 Batch 0 Loss 0.1843\n",
            "Epoch 584 Loss 0.196493\n",
            "Time taken for 1 epoch 5.671530723571777 sec\n",
            "\n",
            "Epoch 585 Batch 0 Loss 0.1841\n",
            "Epoch 585 Loss 0.196222\n",
            "Time taken for 1 epoch 5.6996307373046875 sec\n",
            "\n",
            "Epoch 586 Batch 0 Loss 0.1819\n",
            "Epoch 586 Loss 0.196406\n",
            "Time taken for 1 epoch 5.6041083335876465 sec\n",
            "\n",
            "Epoch 587 Batch 0 Loss 0.1805\n",
            "Epoch 587 Loss 0.196271\n",
            "Time taken for 1 epoch 5.572639465332031 sec\n",
            "\n",
            "Epoch 588 Batch 0 Loss 0.1807\n",
            "Epoch 588 Loss 0.195691\n",
            "Time taken for 1 epoch 5.577699184417725 sec\n",
            "\n",
            "Epoch 589 Batch 0 Loss 0.1798\n",
            "Epoch 589 Loss 0.196192\n",
            "Time taken for 1 epoch 5.594758033752441 sec\n",
            "\n",
            "Epoch 590 Batch 0 Loss 0.1813\n",
            "Epoch 590 Loss 0.195371\n",
            "Time taken for 1 epoch 6.2303385734558105 sec\n",
            "\n",
            "Epoch 591 Batch 0 Loss 0.1839\n",
            "Epoch 591 Loss 0.195732\n",
            "Time taken for 1 epoch 5.878472328186035 sec\n",
            "\n",
            "Epoch 592 Batch 0 Loss 0.1842\n",
            "Epoch 592 Loss 0.195979\n",
            "Time taken for 1 epoch 5.611154317855835 sec\n",
            "\n",
            "Epoch 593 Batch 0 Loss 0.1844\n",
            "Epoch 593 Loss 0.195477\n",
            "Time taken for 1 epoch 5.661442518234253 sec\n",
            "\n",
            "Epoch 594 Batch 0 Loss 0.1836\n",
            "Epoch 594 Loss 0.195981\n",
            "Time taken for 1 epoch 5.686743497848511 sec\n",
            "\n",
            "Epoch 595 Batch 0 Loss 0.1796\n",
            "Epoch 595 Loss 0.195201\n",
            "Time taken for 1 epoch 5.656270742416382 sec\n",
            "\n",
            "Epoch 596 Batch 0 Loss 0.1803\n",
            "Epoch 596 Loss 0.194870\n",
            "Time taken for 1 epoch 5.629094123840332 sec\n",
            "\n",
            "Epoch 597 Batch 0 Loss 0.1803\n",
            "Epoch 597 Loss 0.197206\n",
            "Time taken for 1 epoch 5.628811359405518 sec\n",
            "\n",
            "Epoch 598 Batch 0 Loss 0.1807\n",
            "Epoch 598 Loss 0.198107\n",
            "Time taken for 1 epoch 5.580693483352661 sec\n",
            "\n",
            "Epoch 599 Batch 0 Loss 0.1819\n",
            "Epoch 599 Loss 0.200028\n",
            "Time taken for 1 epoch 5.604567766189575 sec\n",
            "\n",
            "Epoch 600 Batch 0 Loss 0.1842\n",
            "Epoch 600 Loss 0.200415\n",
            "Time taken for 1 epoch 5.582223653793335 sec\n",
            "\n",
            "Epoch 601 Batch 0 Loss 0.1822\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "coconut monitor outside outside airplane outside herd of smoke outside view outside outside outside kitten herd of coconut monitor outside outside outside outside airplane\n",
            "Epoch 601 Loss 0.198517\n",
            "Time taken for 1 epoch 6.211129903793335 sec\n",
            "\n",
            "Epoch 602 Batch 0 Loss 0.1834\n",
            "Epoch 602 Loss 0.198095\n",
            "Time taken for 1 epoch 5.64751124382019 sec\n",
            "\n",
            "Epoch 603 Batch 0 Loss 0.1807\n",
            "Epoch 603 Loss 0.197352\n",
            "Time taken for 1 epoch 5.646583318710327 sec\n",
            "\n",
            "Epoch 604 Batch 0 Loss 0.1820\n",
            "Epoch 604 Loss 0.196355\n",
            "Time taken for 1 epoch 5.665999174118042 sec\n",
            "\n",
            "Epoch 605 Batch 0 Loss 0.1813\n",
            "Epoch 605 Loss 0.196028\n",
            "Time taken for 1 epoch 5.688380002975464 sec\n",
            "\n",
            "Epoch 606 Batch 0 Loss 0.1804\n",
            "Epoch 606 Loss 0.195437\n",
            "Time taken for 1 epoch 5.677444934844971 sec\n",
            "\n",
            "Epoch 607 Batch 0 Loss 0.1810\n",
            "Epoch 607 Loss 0.195323\n",
            "Time taken for 1 epoch 5.587922811508179 sec\n",
            "\n",
            "Epoch 608 Batch 0 Loss 0.1806\n",
            "Epoch 608 Loss 0.196026\n",
            "Time taken for 1 epoch 5.589940071105957 sec\n",
            "\n",
            "Epoch 609 Batch 0 Loss 0.1805\n",
            "Epoch 609 Loss 0.194944\n",
            "Time taken for 1 epoch 5.6145031452178955 sec\n",
            "\n",
            "Epoch 610 Batch 0 Loss 0.1808\n",
            "Epoch 610 Loss 0.195622\n",
            "Time taken for 1 epoch 5.579307794570923 sec\n",
            "\n",
            "Epoch 611 Batch 0 Loss 0.1790\n",
            "Epoch 611 Loss 0.195516\n",
            "Time taken for 1 epoch 5.613834381103516 sec\n",
            "\n",
            "Epoch 612 Batch 0 Loss 0.1804\n",
            "Epoch 612 Loss 0.195334\n",
            "Time taken for 1 epoch 5.578249216079712 sec\n",
            "\n",
            "Epoch 613 Batch 0 Loss 0.1822\n",
            "Epoch 613 Loss 0.196509\n",
            "Time taken for 1 epoch 5.54250431060791 sec\n",
            "\n",
            "Epoch 614 Batch 0 Loss 0.1797\n",
            "Epoch 614 Loss 0.197189\n",
            "Time taken for 1 epoch 5.607151031494141 sec\n",
            "\n",
            "Epoch 615 Batch 0 Loss 0.1807\n",
            "Epoch 615 Loss 0.195415\n",
            "Time taken for 1 epoch 5.591482400894165 sec\n",
            "\n",
            "Epoch 616 Batch 0 Loss 0.1815\n",
            "Epoch 616 Loss 0.196231\n",
            "Time taken for 1 epoch 5.5856711864471436 sec\n",
            "\n",
            "Epoch 617 Batch 0 Loss 0.1808\n",
            "Epoch 617 Loss 0.197169\n",
            "Time taken for 1 epoch 5.662200927734375 sec\n",
            "\n",
            "Epoch 618 Batch 0 Loss 0.1816\n",
            "Epoch 618 Loss 0.196280\n",
            "Time taken for 1 epoch 5.592700481414795 sec\n",
            "\n",
            "Epoch 619 Batch 0 Loss 0.1811\n",
            "Epoch 619 Loss 0.198034\n",
            "Time taken for 1 epoch 5.584638595581055 sec\n",
            "\n",
            "Epoch 620 Batch 0 Loss 0.1812\n",
            "Epoch 620 Loss 0.201698\n",
            "Time taken for 1 epoch 5.605850458145142 sec\n",
            "\n",
            "Epoch 621 Batch 0 Loss 0.1814\n",
            "Epoch 621 Loss 0.205719\n",
            "Time taken for 1 epoch 5.587831258773804 sec\n",
            "\n",
            "Epoch 622 Batch 0 Loss 0.1798\n",
            "Epoch 622 Loss 0.203721\n",
            "Time taken for 1 epoch 5.591898441314697 sec\n",
            "\n",
            "Epoch 623 Batch 0 Loss 0.1794\n",
            "Epoch 623 Loss 0.208146\n",
            "Time taken for 1 epoch 5.588839530944824 sec\n",
            "\n",
            "Epoch 624 Batch 0 Loss 0.1853\n",
            "Epoch 624 Loss 0.213759\n",
            "Time taken for 1 epoch 5.599703788757324 sec\n",
            "\n",
            "Epoch 625 Batch 0 Loss 0.2001\n",
            "Epoch 625 Loss 0.221253\n",
            "Time taken for 1 epoch 6.395920991897583 sec\n",
            "\n",
            "Epoch 626 Batch 0 Loss 0.2046\n",
            "Epoch 626 Loss 0.221490\n",
            "Time taken for 1 epoch 6.19770622253418 sec\n",
            "\n",
            "Epoch 627 Batch 0 Loss 0.1951\n",
            "Epoch 627 Loss 0.232493\n",
            "Time taken for 1 epoch 5.574086427688599 sec\n",
            "\n",
            "Epoch 628 Batch 0 Loss 0.2071\n",
            "Epoch 628 Loss 0.240841\n",
            "Time taken for 1 epoch 5.527883291244507 sec\n",
            "\n",
            "Epoch 629 Batch 0 Loss 0.2257\n",
            "Epoch 629 Loss 0.260531\n",
            "Time taken for 1 epoch 5.519500494003296 sec\n",
            "\n",
            "Epoch 630 Batch 0 Loss 0.2696\n",
            "Epoch 630 Loss 0.282523\n",
            "Time taken for 1 epoch 5.512967586517334 sec\n",
            "\n",
            "Epoch 631 Batch 0 Loss 0.2565\n",
            "Epoch 631 Loss 0.293874\n",
            "Time taken for 1 epoch 5.588610410690308 sec\n",
            "\n",
            "Epoch 632 Batch 0 Loss 0.2505\n",
            "Epoch 632 Loss 0.302043\n",
            "Time taken for 1 epoch 5.518748760223389 sec\n",
            "\n",
            "Epoch 633 Batch 0 Loss 0.2526\n",
            "Epoch 633 Loss 0.322835\n",
            "Time taken for 1 epoch 5.544963598251343 sec\n",
            "\n",
            "Epoch 634 Batch 0 Loss 0.2757\n",
            "Epoch 634 Loss 0.311671\n",
            "Time taken for 1 epoch 5.567573308944702 sec\n",
            "\n",
            "Epoch 635 Batch 0 Loss 0.2874\n",
            "Epoch 635 Loss 0.298227\n",
            "Time taken for 1 epoch 5.64277982711792 sec\n",
            "\n",
            "Epoch 636 Batch 0 Loss 0.2609\n",
            "Epoch 636 Loss 0.277511\n",
            "Time taken for 1 epoch 5.558971643447876 sec\n",
            "\n",
            "Epoch 637 Batch 0 Loss 0.2432\n",
            "Epoch 637 Loss 0.248802\n",
            "Time taken for 1 epoch 5.60071325302124 sec\n",
            "\n",
            "Epoch 638 Batch 0 Loss 0.2330\n",
            "Epoch 638 Loss 0.230852\n",
            "Time taken for 1 epoch 5.566197872161865 sec\n",
            "\n",
            "Epoch 639 Batch 0 Loss 0.2198\n",
            "Epoch 639 Loss 0.219439\n",
            "Time taken for 1 epoch 5.534348011016846 sec\n",
            "\n",
            "Epoch 640 Batch 0 Loss 0.2054\n",
            "Epoch 640 Loss 0.213493\n",
            "Time taken for 1 epoch 5.561986207962036 sec\n",
            "\n",
            "Epoch 641 Batch 0 Loss 0.2001\n",
            "Epoch 641 Loss 0.205228\n",
            "Time taken for 1 epoch 5.543615818023682 sec\n",
            "\n",
            "Epoch 642 Batch 0 Loss 0.1895\n",
            "Epoch 642 Loss 0.200112\n",
            "Time taken for 1 epoch 5.529246807098389 sec\n",
            "\n",
            "Epoch 643 Batch 0 Loss 0.1843\n",
            "Epoch 643 Loss 0.197167\n",
            "Time taken for 1 epoch 5.608414173126221 sec\n",
            "\n",
            "Epoch 644 Batch 0 Loss 0.1818\n",
            "Epoch 644 Loss 0.196638\n",
            "Time taken for 1 epoch 5.957459449768066 sec\n",
            "\n",
            "Epoch 645 Batch 0 Loss 0.1814\n",
            "Epoch 645 Loss 0.196625\n",
            "Time taken for 1 epoch 6.147762775421143 sec\n",
            "\n",
            "Epoch 646 Batch 0 Loss 0.1820\n",
            "Epoch 646 Loss 0.196670\n",
            "Time taken for 1 epoch 5.520324945449829 sec\n",
            "\n",
            "Epoch 647 Batch 0 Loss 0.1797\n",
            "Epoch 647 Loss 0.197578\n",
            "Time taken for 1 epoch 5.538857460021973 sec\n",
            "\n",
            "Epoch 648 Batch 0 Loss 0.1794\n",
            "Epoch 648 Loss 0.199624\n",
            "Time taken for 1 epoch 5.571639537811279 sec\n",
            "\n",
            "Epoch 649 Batch 0 Loss 0.1838\n",
            "Epoch 649 Loss 0.198216\n",
            "Time taken for 1 epoch 5.655813932418823 sec\n",
            "\n",
            "Epoch 650 Batch 0 Loss 0.1847\n",
            "Epoch 650 Loss 0.197555\n",
            "Time taken for 1 epoch 5.5924530029296875 sec\n",
            "\n",
            "Epoch 651 Batch 0 Loss 0.1811\n",
            "Epoch 651 Loss 0.197482\n",
            "Time taken for 1 epoch 5.559693813323975 sec\n",
            "\n",
            "Epoch 652 Batch 0 Loss 0.1848\n",
            "Epoch 652 Loss 0.196623\n",
            "Time taken for 1 epoch 5.512807369232178 sec\n",
            "\n",
            "Epoch 653 Batch 0 Loss 0.1851\n",
            "Epoch 653 Loss 0.196033\n",
            "Time taken for 1 epoch 5.542444229125977 sec\n",
            "\n",
            "Epoch 654 Batch 0 Loss 0.1821\n",
            "Epoch 654 Loss 0.195514\n",
            "Time taken for 1 epoch 5.571769952774048 sec\n",
            "\n",
            "Epoch 655 Batch 0 Loss 0.1820\n",
            "Epoch 655 Loss 0.195611\n",
            "Time taken for 1 epoch 5.538980960845947 sec\n",
            "\n",
            "Epoch 656 Batch 0 Loss 0.1833\n",
            "Epoch 656 Loss 0.197391\n",
            "Time taken for 1 epoch 5.5585432052612305 sec\n",
            "\n",
            "Epoch 657 Batch 0 Loss 0.1827\n",
            "Epoch 657 Loss 0.197286\n",
            "Time taken for 1 epoch 5.646286725997925 sec\n",
            "\n",
            "Epoch 658 Batch 0 Loss 0.1824\n",
            "Epoch 658 Loss 0.196016\n",
            "Time taken for 1 epoch 5.586538076400757 sec\n",
            "\n",
            "Epoch 659 Batch 0 Loss 0.1811\n",
            "Epoch 659 Loss 0.196508\n",
            "Time taken for 1 epoch 5.64014458656311 sec\n",
            "\n",
            "Epoch 660 Batch 0 Loss 0.1809\n",
            "Epoch 660 Loss 0.195810\n",
            "Time taken for 1 epoch 5.568965673446655 sec\n",
            "\n",
            "Epoch 661 Batch 0 Loss 0.1817\n",
            "Epoch 661 Loss 0.194542\n",
            "Time taken for 1 epoch 5.5892980098724365 sec\n",
            "\n",
            "Epoch 662 Batch 0 Loss 0.1813\n",
            "Epoch 662 Loss 0.193949\n",
            "Time taken for 1 epoch 5.6350624561309814 sec\n",
            "\n",
            "Epoch 663 Batch 0 Loss 0.1802\n",
            "Epoch 663 Loss 0.193709\n",
            "Time taken for 1 epoch 5.630227565765381 sec\n",
            "\n",
            "Epoch 664 Batch 0 Loss 0.1809\n",
            "Epoch 664 Loss 0.194936\n",
            "Time taken for 1 epoch 5.626644611358643 sec\n",
            "\n",
            "Epoch 665 Batch 0 Loss 0.1801\n",
            "Epoch 665 Loss 0.194952\n",
            "Time taken for 1 epoch 5.582011699676514 sec\n",
            "\n",
            "Epoch 666 Batch 0 Loss 0.1804\n",
            "Epoch 666 Loss 0.194862\n",
            "Time taken for 1 epoch 5.635008811950684 sec\n",
            "\n",
            "Epoch 667 Batch 0 Loss 0.1798\n",
            "Epoch 667 Loss 0.195147\n",
            "Time taken for 1 epoch 5.681053876876831 sec\n",
            "\n",
            "Epoch 668 Batch 0 Loss 0.1801\n",
            "Epoch 668 Loss 0.194149\n",
            "Time taken for 1 epoch 5.6476521492004395 sec\n",
            "\n",
            "Epoch 669 Batch 0 Loss 0.1789\n",
            "Epoch 669 Loss 0.193945\n",
            "Time taken for 1 epoch 5.6370556354522705 sec\n",
            "\n",
            "Epoch 670 Batch 0 Loss 0.1784\n",
            "Epoch 670 Loss 0.194465\n",
            "Time taken for 1 epoch 5.710238933563232 sec\n",
            "\n",
            "Epoch 671 Batch 0 Loss 0.1802\n",
            "Epoch 671 Loss 0.194407\n",
            "Time taken for 1 epoch 5.614875078201294 sec\n",
            "\n",
            "Epoch 672 Batch 0 Loss 0.1819\n",
            "Epoch 672 Loss 0.195183\n",
            "Time taken for 1 epoch 5.603848695755005 sec\n",
            "\n",
            "Epoch 673 Batch 0 Loss 0.1792\n",
            "Epoch 673 Loss 0.194751\n",
            "Time taken for 1 epoch 5.616481781005859 sec\n",
            "\n",
            "Epoch 674 Batch 0 Loss 0.1804\n",
            "Epoch 674 Loss 0.194679\n",
            "Time taken for 1 epoch 5.610402584075928 sec\n",
            "\n",
            "Epoch 675 Batch 0 Loss 0.1809\n",
            "Epoch 675 Loss 0.194945\n",
            "Time taken for 1 epoch 5.5971527099609375 sec\n",
            "\n",
            "Epoch 676 Batch 0 Loss 0.1794\n",
            "Epoch 676 Loss 0.194724\n",
            "Time taken for 1 epoch 5.694974422454834 sec\n",
            "\n",
            "Epoch 677 Batch 0 Loss 0.1788\n",
            "Epoch 677 Loss 0.195073\n",
            "Time taken for 1 epoch 5.709301471710205 sec\n",
            "\n",
            "Epoch 678 Batch 0 Loss 0.1802\n",
            "Epoch 678 Loss 0.196017\n",
            "Time taken for 1 epoch 5.673114776611328 sec\n",
            "\n",
            "Epoch 679 Batch 0 Loss 0.1797\n",
            "Epoch 679 Loss 0.194852\n",
            "Time taken for 1 epoch 5.64094877243042 sec\n",
            "\n",
            "Epoch 680 Batch 0 Loss 0.1812\n",
            "Epoch 680 Loss 0.194234\n",
            "Time taken for 1 epoch 6.168984651565552 sec\n",
            "\n",
            "Epoch 681 Batch 0 Loss 0.1777\n",
            "Epoch 681 Loss 0.193137\n",
            "Time taken for 1 epoch 6.41057014465332 sec\n",
            "\n",
            "Epoch 682 Batch 0 Loss 0.1786\n",
            "Epoch 682 Loss 0.193052\n",
            "Time taken for 1 epoch 5.607481002807617 sec\n",
            "\n",
            "Epoch 683 Batch 0 Loss 0.1788\n",
            "Epoch 683 Loss 0.193388\n",
            "Time taken for 1 epoch 5.56713342666626 sec\n",
            "\n",
            "Epoch 684 Batch 0 Loss 0.1785\n",
            "Epoch 684 Loss 0.192888\n",
            "Time taken for 1 epoch 5.540194272994995 sec\n",
            "\n",
            "Epoch 685 Batch 0 Loss 0.1787\n",
            "Epoch 685 Loss 0.193072\n",
            "Time taken for 1 epoch 5.579606294631958 sec\n",
            "\n",
            "Epoch 686 Batch 0 Loss 0.1796\n",
            "Epoch 686 Loss 0.194175\n",
            "Time taken for 1 epoch 5.522512197494507 sec\n",
            "\n",
            "Epoch 687 Batch 0 Loss 0.1785\n",
            "Epoch 687 Loss 0.195431\n",
            "Time taken for 1 epoch 5.507004499435425 sec\n",
            "\n",
            "Epoch 688 Batch 0 Loss 0.1782\n",
            "Epoch 688 Loss 0.195749\n",
            "Time taken for 1 epoch 5.561041831970215 sec\n",
            "\n",
            "Epoch 689 Batch 0 Loss 0.1787\n",
            "Epoch 689 Loss 0.199263\n",
            "Time taken for 1 epoch 5.5166895389556885 sec\n",
            "\n",
            "Epoch 690 Batch 0 Loss 0.1799\n",
            "Epoch 690 Loss 0.199589\n",
            "Time taken for 1 epoch 5.503957033157349 sec\n",
            "\n",
            "Epoch 691 Batch 0 Loss 0.1837\n",
            "Epoch 691 Loss 0.198861\n",
            "Time taken for 1 epoch 5.570432186126709 sec\n",
            "\n",
            "Epoch 692 Batch 0 Loss 0.1818\n",
            "Epoch 692 Loss 0.198550\n",
            "Time taken for 1 epoch 5.541285037994385 sec\n",
            "\n",
            "Epoch 693 Batch 0 Loss 0.1817\n",
            "Epoch 693 Loss 0.196619\n",
            "Time taken for 1 epoch 5.552502870559692 sec\n",
            "\n",
            "Epoch 694 Batch 0 Loss 0.1828\n",
            "Epoch 694 Loss 0.195991\n",
            "Time taken for 1 epoch 5.583889484405518 sec\n",
            "\n",
            "Epoch 695 Batch 0 Loss 0.1834\n",
            "Epoch 695 Loss 0.194516\n",
            "Time taken for 1 epoch 5.5456883907318115 sec\n",
            "\n",
            "Epoch 696 Batch 0 Loss 0.1813\n",
            "Epoch 696 Loss 0.193448\n",
            "Time taken for 1 epoch 5.534200191497803 sec\n",
            "\n",
            "Epoch 697 Batch 0 Loss 0.1793\n",
            "Epoch 697 Loss 0.193100\n",
            "Time taken for 1 epoch 5.531362771987915 sec\n",
            "\n",
            "Epoch 698 Batch 0 Loss 0.1787\n",
            "Epoch 698 Loss 0.193857\n",
            "Time taken for 1 epoch 5.540401220321655 sec\n",
            "\n",
            "Epoch 699 Batch 0 Loss 0.1831\n",
            "Epoch 699 Loss 0.194727\n",
            "Time taken for 1 epoch 6.3246071338653564 sec\n",
            "\n",
            "Epoch 700 Batch 0 Loss 0.2155\n",
            "Epoch 700 Loss 0.204581\n",
            "Time taken for 1 epoch 5.553367853164673 sec\n",
            "\n",
            "Epoch 701 Batch 0 Loss 0.2529\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "herd of smoke outside at <unk> at airplane outside outside outside outside outside outside airplane outside airplane outside view outside outside outside herd of\n",
            "Epoch 701 Loss 0.220112\n",
            "Time taken for 1 epoch 6.2288618087768555 sec\n",
            "\n",
            "Epoch 702 Batch 0 Loss 0.2636\n",
            "Epoch 702 Loss 0.234288\n",
            "Time taken for 1 epoch 5.562210321426392 sec\n",
            "\n",
            "Epoch 703 Batch 0 Loss 0.2540\n",
            "Epoch 703 Loss 0.238697\n",
            "Time taken for 1 epoch 5.527610778808594 sec\n",
            "\n",
            "Epoch 704 Batch 0 Loss 0.3386\n",
            "Epoch 704 Loss 0.265203\n",
            "Time taken for 1 epoch 5.555174112319946 sec\n",
            "\n",
            "Epoch 705 Batch 0 Loss 0.3975\n",
            "Epoch 705 Loss 0.295901\n",
            "Time taken for 1 epoch 5.609346389770508 sec\n",
            "\n",
            "Epoch 706 Batch 0 Loss 0.4141\n",
            "Epoch 706 Loss 0.330772\n",
            "Time taken for 1 epoch 5.549486398696899 sec\n",
            "\n",
            "Epoch 707 Batch 0 Loss 0.4522\n",
            "Epoch 707 Loss 0.373159\n",
            "Time taken for 1 epoch 5.631373405456543 sec\n",
            "\n",
            "Epoch 708 Batch 0 Loss 0.4793\n",
            "Epoch 708 Loss 0.432827\n",
            "Time taken for 1 epoch 5.667142391204834 sec\n",
            "\n",
            "Epoch 709 Batch 0 Loss 0.4692\n",
            "Epoch 709 Loss 0.462527\n",
            "Time taken for 1 epoch 5.574442625045776 sec\n",
            "\n",
            "Epoch 710 Batch 0 Loss 0.5166\n",
            "Epoch 710 Loss 0.461211\n",
            "Time taken for 1 epoch 5.6095733642578125 sec\n",
            "\n",
            "Epoch 711 Batch 0 Loss 0.3822\n",
            "Epoch 711 Loss 0.450777\n",
            "Time taken for 1 epoch 5.595732688903809 sec\n",
            "\n",
            "Epoch 712 Batch 0 Loss 0.4020\n",
            "Epoch 712 Loss 0.405382\n",
            "Time taken for 1 epoch 5.639530658721924 sec\n",
            "\n",
            "Epoch 713 Batch 0 Loss 0.3054\n",
            "Epoch 713 Loss 0.347456\n",
            "Time taken for 1 epoch 5.630805730819702 sec\n",
            "\n",
            "Epoch 714 Batch 0 Loss 0.2683\n",
            "Epoch 714 Loss 0.278488\n",
            "Time taken for 1 epoch 5.637144565582275 sec\n",
            "\n",
            "Epoch 715 Batch 0 Loss 0.2241\n",
            "Epoch 715 Loss 0.239374\n",
            "Time taken for 1 epoch 5.631296396255493 sec\n",
            "\n",
            "Epoch 716 Batch 0 Loss 0.2107\n",
            "Epoch 716 Loss 0.229452\n",
            "Time taken for 1 epoch 5.65984582901001 sec\n",
            "\n",
            "Epoch 717 Batch 0 Loss 0.1979\n",
            "Epoch 717 Loss 0.211961\n",
            "Time taken for 1 epoch 5.670475482940674 sec\n",
            "\n",
            "Epoch 718 Batch 0 Loss 0.1869\n",
            "Epoch 718 Loss 0.200376\n",
            "Time taken for 1 epoch 5.608232498168945 sec\n",
            "\n",
            "Epoch 719 Batch 0 Loss 0.1831\n",
            "Epoch 719 Loss 0.196669\n",
            "Time taken for 1 epoch 5.630033254623413 sec\n",
            "\n",
            "Epoch 720 Batch 0 Loss 0.1809\n",
            "Epoch 720 Loss 0.194332\n",
            "Time taken for 1 epoch 5.621109485626221 sec\n",
            "\n",
            "Epoch 721 Batch 0 Loss 0.1798\n",
            "Epoch 721 Loss 0.193250\n",
            "Time taken for 1 epoch 5.599034547805786 sec\n",
            "\n",
            "Epoch 722 Batch 0 Loss 0.1787\n",
            "Epoch 722 Loss 0.192524\n",
            "Time taken for 1 epoch 5.5841450691223145 sec\n",
            "\n",
            "Epoch 723 Batch 0 Loss 0.1783\n",
            "Epoch 723 Loss 0.192570\n",
            "Time taken for 1 epoch 5.602494239807129 sec\n",
            "\n",
            "Epoch 724 Batch 0 Loss 0.1787\n",
            "Epoch 724 Loss 0.193187\n",
            "Time taken for 1 epoch 5.652467250823975 sec\n",
            "\n",
            "Epoch 725 Batch 0 Loss 0.1795\n",
            "Epoch 725 Loss 0.193227\n",
            "Time taken for 1 epoch 5.641024351119995 sec\n",
            "\n",
            "Epoch 726 Batch 0 Loss 0.1794\n",
            "Epoch 726 Loss 0.192843\n",
            "Time taken for 1 epoch 5.602457523345947 sec\n",
            "\n",
            "Epoch 727 Batch 0 Loss 0.1787\n",
            "Epoch 727 Loss 0.193115\n",
            "Time taken for 1 epoch 5.579252243041992 sec\n",
            "\n",
            "Epoch 728 Batch 0 Loss 0.1785\n",
            "Epoch 728 Loss 0.192913\n",
            "Time taken for 1 epoch 5.649054765701294 sec\n",
            "\n",
            "Epoch 729 Batch 0 Loss 0.1783\n",
            "Epoch 729 Loss 0.193319\n",
            "Time taken for 1 epoch 5.693742990493774 sec\n",
            "\n",
            "Epoch 730 Batch 0 Loss 0.1790\n",
            "Epoch 730 Loss 0.193566\n",
            "Time taken for 1 epoch 5.699951887130737 sec\n",
            "\n",
            "Epoch 731 Batch 0 Loss 0.1800\n",
            "Epoch 731 Loss 0.194110\n",
            "Time taken for 1 epoch 5.6524879932403564 sec\n",
            "\n",
            "Epoch 732 Batch 0 Loss 0.1800\n",
            "Epoch 732 Loss 0.193744\n",
            "Time taken for 1 epoch 5.599781513214111 sec\n",
            "\n",
            "Epoch 733 Batch 0 Loss 0.1778\n",
            "Epoch 733 Loss 0.193780\n",
            "Time taken for 1 epoch 5.61955189704895 sec\n",
            "\n",
            "Epoch 734 Batch 0 Loss 0.1784\n",
            "Epoch 734 Loss 0.193801\n",
            "Time taken for 1 epoch 5.646641492843628 sec\n",
            "\n",
            "Epoch 735 Batch 0 Loss 0.1807\n",
            "Epoch 735 Loss 0.195252\n",
            "Time taken for 1 epoch 6.082234144210815 sec\n",
            "\n",
            "Epoch 736 Batch 0 Loss 0.1790\n",
            "Epoch 736 Loss 0.194599\n",
            "Time taken for 1 epoch 6.632570028305054 sec\n",
            "\n",
            "Epoch 737 Batch 0 Loss 0.1792\n",
            "Epoch 737 Loss 0.194981\n",
            "Time taken for 1 epoch 5.757683992385864 sec\n",
            "\n",
            "Epoch 738 Batch 0 Loss 0.1790\n",
            "Epoch 738 Loss 0.196224\n",
            "Time taken for 1 epoch 5.659636497497559 sec\n",
            "\n",
            "Epoch 739 Batch 0 Loss 0.1782\n",
            "Epoch 739 Loss 0.195867\n",
            "Time taken for 1 epoch 5.681377649307251 sec\n",
            "\n",
            "Epoch 740 Batch 0 Loss 0.1778\n",
            "Epoch 740 Loss 0.194578\n",
            "Time taken for 1 epoch 5.621013164520264 sec\n",
            "\n",
            "Epoch 741 Batch 0 Loss 0.1788\n",
            "Epoch 741 Loss 0.195462\n",
            "Time taken for 1 epoch 5.667999744415283 sec\n",
            "\n",
            "Epoch 742 Batch 0 Loss 0.1795\n",
            "Epoch 742 Loss 0.194962\n",
            "Time taken for 1 epoch 5.704477548599243 sec\n",
            "\n",
            "Epoch 743 Batch 0 Loss 0.1800\n",
            "Epoch 743 Loss 0.194806\n",
            "Time taken for 1 epoch 5.605072975158691 sec\n",
            "\n",
            "Epoch 744 Batch 0 Loss 0.1782\n",
            "Epoch 744 Loss 0.194224\n",
            "Time taken for 1 epoch 5.600652694702148 sec\n",
            "\n",
            "Epoch 745 Batch 0 Loss 0.1794\n",
            "Epoch 745 Loss 0.193471\n",
            "Time taken for 1 epoch 5.64735746383667 sec\n",
            "\n",
            "Epoch 746 Batch 0 Loss 0.1809\n",
            "Epoch 746 Loss 0.193326\n",
            "Time taken for 1 epoch 5.613067865371704 sec\n",
            "\n",
            "Epoch 747 Batch 0 Loss 0.1814\n",
            "Epoch 747 Loss 0.192617\n",
            "Time taken for 1 epoch 5.636231184005737 sec\n",
            "\n",
            "Epoch 748 Batch 0 Loss 0.1788\n",
            "Epoch 748 Loss 0.191557\n",
            "Time taken for 1 epoch 5.5954906940460205 sec\n",
            "\n",
            "Epoch 749 Batch 0 Loss 0.1784\n",
            "Epoch 749 Loss 0.191876\n",
            "Time taken for 1 epoch 5.5194854736328125 sec\n",
            "\n",
            "Epoch 750 Batch 0 Loss 0.1778\n",
            "Epoch 750 Loss 0.192003\n",
            "Time taken for 1 epoch 5.509943246841431 sec\n",
            "\n",
            "Epoch 751 Batch 0 Loss 0.1785\n",
            "Epoch 751 Loss 0.192283\n",
            "Time taken for 1 epoch 5.580291271209717 sec\n",
            "\n",
            "Epoch 752 Batch 0 Loss 0.1787\n",
            "Epoch 752 Loss 0.192318\n",
            "Time taken for 1 epoch 5.52557110786438 sec\n",
            "\n",
            "Epoch 753 Batch 0 Loss 0.1789\n",
            "Epoch 753 Loss 0.192496\n",
            "Time taken for 1 epoch 6.385954856872559 sec\n",
            "\n",
            "Epoch 754 Batch 0 Loss 0.1796\n",
            "Epoch 754 Loss 0.193174\n",
            "Time taken for 1 epoch 5.63753604888916 sec\n",
            "\n",
            "Epoch 755 Batch 0 Loss 0.1790\n",
            "Epoch 755 Loss 0.193535\n",
            "Time taken for 1 epoch 5.536673307418823 sec\n",
            "\n",
            "Epoch 756 Batch 0 Loss 0.1797\n",
            "Epoch 756 Loss 0.192870\n",
            "Time taken for 1 epoch 5.5210349559783936 sec\n",
            "\n",
            "Epoch 757 Batch 0 Loss 0.1794\n",
            "Epoch 757 Loss 0.192931\n",
            "Time taken for 1 epoch 5.5497519969940186 sec\n",
            "\n",
            "Epoch 758 Batch 0 Loss 0.1793\n",
            "Epoch 758 Loss 0.192605\n",
            "Time taken for 1 epoch 5.579896926879883 sec\n",
            "\n",
            "Epoch 759 Batch 0 Loss 0.1793\n",
            "Epoch 759 Loss 0.192790\n",
            "Time taken for 1 epoch 5.614959716796875 sec\n",
            "\n",
            "Epoch 760 Batch 0 Loss 0.1777\n",
            "Epoch 760 Loss 0.192690\n",
            "Time taken for 1 epoch 5.616686582565308 sec\n",
            "\n",
            "Epoch 761 Batch 0 Loss 0.1782\n",
            "Epoch 761 Loss 0.192159\n",
            "Time taken for 1 epoch 5.615766525268555 sec\n",
            "\n",
            "Epoch 762 Batch 0 Loss 0.1787\n",
            "Epoch 762 Loss 0.192692\n",
            "Time taken for 1 epoch 5.6129796504974365 sec\n",
            "\n",
            "Epoch 763 Batch 0 Loss 0.1779\n",
            "Epoch 763 Loss 0.193145\n",
            "Time taken for 1 epoch 5.553144454956055 sec\n",
            "\n",
            "Epoch 764 Batch 0 Loss 0.1813\n",
            "Epoch 764 Loss 0.193647\n",
            "Time taken for 1 epoch 5.595207452774048 sec\n",
            "\n",
            "Epoch 765 Batch 0 Loss 0.1813\n",
            "Epoch 765 Loss 0.194787\n",
            "Time taken for 1 epoch 5.63930606842041 sec\n",
            "\n",
            "Epoch 766 Batch 0 Loss 0.1782\n",
            "Epoch 766 Loss 0.194162\n",
            "Time taken for 1 epoch 5.603731393814087 sec\n",
            "\n",
            "Epoch 767 Batch 0 Loss 0.1797\n",
            "Epoch 767 Loss 0.194678\n",
            "Time taken for 1 epoch 5.5862367153167725 sec\n",
            "\n",
            "Epoch 768 Batch 0 Loss 0.1798\n",
            "Epoch 768 Loss 0.195362\n",
            "Time taken for 1 epoch 5.66283392906189 sec\n",
            "\n",
            "Epoch 769 Batch 0 Loss 0.1781\n",
            "Epoch 769 Loss 0.195514\n",
            "Time taken for 1 epoch 5.64856743812561 sec\n",
            "\n",
            "Epoch 770 Batch 0 Loss 0.1786\n",
            "Epoch 770 Loss 0.194076\n",
            "Time taken for 1 epoch 5.603613376617432 sec\n",
            "\n",
            "Epoch 771 Batch 0 Loss 0.1787\n",
            "Epoch 771 Loss 0.194486\n",
            "Time taken for 1 epoch 5.652354955673218 sec\n",
            "\n",
            "Epoch 772 Batch 0 Loss 0.1780\n",
            "Epoch 772 Loss 0.193898\n",
            "Time taken for 1 epoch 5.643172740936279 sec\n",
            "\n",
            "Epoch 773 Batch 0 Loss 0.1803\n",
            "Epoch 773 Loss 0.193596\n",
            "Time taken for 1 epoch 5.6781370639801025 sec\n",
            "\n",
            "Epoch 774 Batch 0 Loss 0.1812\n",
            "Epoch 774 Loss 0.192839\n",
            "Time taken for 1 epoch 5.690681219100952 sec\n",
            "\n",
            "Epoch 775 Batch 0 Loss 0.1807\n",
            "Epoch 775 Loss 0.192114\n",
            "Time taken for 1 epoch 5.681548118591309 sec\n",
            "\n",
            "Epoch 776 Batch 0 Loss 0.1788\n",
            "Epoch 776 Loss 0.191995\n",
            "Time taken for 1 epoch 5.699312686920166 sec\n",
            "\n",
            "Epoch 777 Batch 0 Loss 0.1775\n",
            "Epoch 777 Loss 0.191988\n",
            "Time taken for 1 epoch 5.679478406906128 sec\n",
            "\n",
            "Epoch 778 Batch 0 Loss 0.1776\n",
            "Epoch 778 Loss 0.192129\n",
            "Time taken for 1 epoch 5.706521511077881 sec\n",
            "\n",
            "Epoch 779 Batch 0 Loss 0.1785\n",
            "Epoch 779 Loss 0.193252\n",
            "Time taken for 1 epoch 5.6792685985565186 sec\n",
            "\n",
            "Epoch 780 Batch 0 Loss 0.1793\n",
            "Epoch 780 Loss 0.193989\n",
            "Time taken for 1 epoch 5.680059432983398 sec\n",
            "\n",
            "Epoch 781 Batch 0 Loss 0.1810\n",
            "Epoch 781 Loss 0.194733\n",
            "Time taken for 1 epoch 5.6647820472717285 sec\n",
            "\n",
            "Epoch 782 Batch 0 Loss 0.1791\n",
            "Epoch 782 Loss 0.194162\n",
            "Time taken for 1 epoch 5.605982303619385 sec\n",
            "\n",
            "Epoch 783 Batch 0 Loss 0.1811\n",
            "Epoch 783 Loss 0.193015\n",
            "Time taken for 1 epoch 5.616246938705444 sec\n",
            "\n",
            "Epoch 784 Batch 0 Loss 0.1810\n",
            "Epoch 784 Loss 0.192824\n",
            "Time taken for 1 epoch 5.627667188644409 sec\n",
            "\n",
            "Epoch 785 Batch 0 Loss 0.1792\n",
            "Epoch 785 Loss 0.192645\n",
            "Time taken for 1 epoch 5.619768142700195 sec\n",
            "\n",
            "Epoch 786 Batch 0 Loss 0.1789\n",
            "Epoch 786 Loss 0.192559\n",
            "Time taken for 1 epoch 5.629594802856445 sec\n",
            "\n",
            "Epoch 787 Batch 0 Loss 0.1796\n",
            "Epoch 787 Loss 0.193064\n",
            "Time taken for 1 epoch 5.602433919906616 sec\n",
            "\n",
            "Epoch 788 Batch 0 Loss 0.1798\n",
            "Epoch 788 Loss 0.192911\n",
            "Time taken for 1 epoch 5.584630489349365 sec\n",
            "\n",
            "Epoch 789 Batch 0 Loss 0.1795\n",
            "Epoch 789 Loss 0.193158\n",
            "Time taken for 1 epoch 5.545788288116455 sec\n",
            "\n",
            "Epoch 790 Batch 0 Loss 0.1777\n",
            "Epoch 790 Loss 0.193440\n",
            "Time taken for 1 epoch 6.033249855041504 sec\n",
            "\n",
            "Epoch 791 Batch 0 Loss 0.1800\n",
            "Epoch 791 Loss 0.193138\n",
            "Time taken for 1 epoch 6.730386257171631 sec\n",
            "\n",
            "Epoch 792 Batch 0 Loss 0.1810\n",
            "Epoch 792 Loss 0.193710\n",
            "Time taken for 1 epoch 5.661198854446411 sec\n",
            "\n",
            "Epoch 793 Batch 0 Loss 0.1779\n",
            "Epoch 793 Loss 0.193049\n",
            "Time taken for 1 epoch 5.58566951751709 sec\n",
            "\n",
            "Epoch 794 Batch 0 Loss 0.1793\n",
            "Epoch 794 Loss 0.192037\n",
            "Time taken for 1 epoch 5.586022853851318 sec\n",
            "\n",
            "Epoch 795 Batch 0 Loss 0.1782\n",
            "Epoch 795 Loss 0.192611\n",
            "Time taken for 1 epoch 5.6265904903411865 sec\n",
            "\n",
            "Epoch 796 Batch 0 Loss 0.1777\n",
            "Epoch 796 Loss 0.193324\n",
            "Time taken for 1 epoch 5.553847074508667 sec\n",
            "\n",
            "Epoch 797 Batch 0 Loss 0.1774\n",
            "Epoch 797 Loss 0.193108\n",
            "Time taken for 1 epoch 5.592707872390747 sec\n",
            "\n",
            "Epoch 798 Batch 0 Loss 0.1780\n",
            "Epoch 798 Loss 0.193245\n",
            "Time taken for 1 epoch 5.599661588668823 sec\n",
            "\n",
            "Epoch 799 Batch 0 Loss 0.1792\n",
            "Epoch 799 Loss 0.193473\n",
            "Time taken for 1 epoch 5.653900861740112 sec\n",
            "\n",
            "Epoch 800 Batch 0 Loss 0.1799\n",
            "Epoch 800 Loss 0.193748\n",
            "Time taken for 1 epoch 5.720027208328247 sec\n",
            "\n",
            "Epoch 801 Batch 0 Loss 0.1802\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "smoke table outside outside standing demolished outside outside outside view outside table outside outside airplane airliner outside standing demolished airplane at <unk> at smoke\n",
            "Epoch 801 Loss 0.194000\n",
            "Time taken for 1 epoch 6.329687118530273 sec\n",
            "\n",
            "Epoch 802 Batch 0 Loss 0.1818\n",
            "Epoch 802 Loss 0.192707\n",
            "Time taken for 1 epoch 5.630336046218872 sec\n",
            "\n",
            "Epoch 803 Batch 0 Loss 0.1816\n",
            "Epoch 803 Loss 0.192963\n",
            "Time taken for 1 epoch 5.618457078933716 sec\n",
            "\n",
            "Epoch 804 Batch 0 Loss 0.1791\n",
            "Epoch 804 Loss 0.192716\n",
            "Time taken for 1 epoch 5.621670722961426 sec\n",
            "\n",
            "Epoch 805 Batch 0 Loss 0.1783\n",
            "Epoch 805 Loss 0.193694\n",
            "Time taken for 1 epoch 5.6675944328308105 sec\n",
            "\n",
            "Epoch 806 Batch 0 Loss 0.1790\n",
            "Epoch 806 Loss 0.193472\n",
            "Time taken for 1 epoch 5.683900594711304 sec\n",
            "\n",
            "Epoch 807 Batch 0 Loss 0.1798\n",
            "Epoch 807 Loss 0.193530\n",
            "Time taken for 1 epoch 6.550767421722412 sec\n",
            "\n",
            "Epoch 808 Batch 0 Loss 0.1797\n",
            "Epoch 808 Loss 0.193275\n",
            "Time taken for 1 epoch 5.642599582672119 sec\n",
            "\n",
            "Epoch 809 Batch 0 Loss 0.1780\n",
            "Epoch 809 Loss 0.194098\n",
            "Time taken for 1 epoch 5.623245477676392 sec\n",
            "\n",
            "Epoch 810 Batch 0 Loss 0.1785\n",
            "Epoch 810 Loss 0.192926\n",
            "Time taken for 1 epoch 5.691955089569092 sec\n",
            "\n",
            "Epoch 811 Batch 0 Loss 0.1797\n",
            "Epoch 811 Loss 0.192877\n",
            "Time taken for 1 epoch 5.632699728012085 sec\n",
            "\n",
            "Epoch 812 Batch 0 Loss 0.1791\n",
            "Epoch 812 Loss 0.192016\n",
            "Time taken for 1 epoch 5.665503263473511 sec\n",
            "\n",
            "Epoch 813 Batch 0 Loss 0.1798\n",
            "Epoch 813 Loss 0.192299\n",
            "Time taken for 1 epoch 5.687725067138672 sec\n",
            "\n",
            "Epoch 814 Batch 0 Loss 0.1787\n",
            "Epoch 814 Loss 0.192622\n",
            "Time taken for 1 epoch 5.636318922042847 sec\n",
            "\n",
            "Epoch 815 Batch 0 Loss 0.1777\n",
            "Epoch 815 Loss 0.192842\n",
            "Time taken for 1 epoch 5.676899433135986 sec\n",
            "\n",
            "Epoch 816 Batch 0 Loss 0.1794\n",
            "Epoch 816 Loss 0.193695\n",
            "Time taken for 1 epoch 5.649653673171997 sec\n",
            "\n",
            "Epoch 817 Batch 0 Loss 0.1823\n",
            "Epoch 817 Loss 0.196019\n",
            "Time taken for 1 epoch 5.652074098587036 sec\n",
            "\n",
            "Epoch 818 Batch 0 Loss 0.1814\n",
            "Epoch 818 Loss 0.196994\n",
            "Time taken for 1 epoch 5.636968374252319 sec\n",
            "\n",
            "Epoch 819 Batch 0 Loss 0.1815\n",
            "Epoch 819 Loss 0.196241\n",
            "Time taken for 1 epoch 5.646285772323608 sec\n",
            "\n",
            "Epoch 820 Batch 0 Loss 0.1842\n",
            "Epoch 820 Loss 0.198427\n",
            "Time taken for 1 epoch 5.625126361846924 sec\n",
            "\n",
            "Epoch 821 Batch 0 Loss 0.1821\n",
            "Epoch 821 Loss 0.197932\n",
            "Time taken for 1 epoch 5.596455335617065 sec\n",
            "\n",
            "Epoch 822 Batch 0 Loss 0.1821\n",
            "Epoch 822 Loss 0.195996\n",
            "Time taken for 1 epoch 5.65295672416687 sec\n",
            "\n",
            "Epoch 823 Batch 0 Loss 0.1797\n",
            "Epoch 823 Loss 0.194331\n",
            "Time taken for 1 epoch 5.602061033248901 sec\n",
            "\n",
            "Epoch 824 Batch 0 Loss 0.1804\n",
            "Epoch 824 Loss 0.192862\n",
            "Time taken for 1 epoch 5.598551034927368 sec\n",
            "\n",
            "Epoch 825 Batch 0 Loss 0.1804\n",
            "Epoch 825 Loss 0.192275\n",
            "Time taken for 1 epoch 5.660894155502319 sec\n",
            "\n",
            "Epoch 826 Batch 0 Loss 0.1787\n",
            "Epoch 826 Loss 0.192192\n",
            "Time taken for 1 epoch 5.717038869857788 sec\n",
            "\n",
            "Epoch 827 Batch 0 Loss 0.1789\n",
            "Epoch 827 Loss 0.192159\n",
            "Time taken for 1 epoch 5.716275691986084 sec\n",
            "\n",
            "Epoch 828 Batch 0 Loss 0.1793\n",
            "Epoch 828 Loss 0.193350\n",
            "Time taken for 1 epoch 5.702547073364258 sec\n",
            "\n",
            "Epoch 829 Batch 0 Loss 0.1794\n",
            "Epoch 829 Loss 0.194379\n",
            "Time taken for 1 epoch 5.726283311843872 sec\n",
            "\n",
            "Epoch 830 Batch 0 Loss 0.1810\n",
            "Epoch 830 Loss 0.193423\n",
            "Time taken for 1 epoch 5.776622533798218 sec\n",
            "\n",
            "Epoch 831 Batch 0 Loss 0.1797\n",
            "Epoch 831 Loss 0.193283\n",
            "Time taken for 1 epoch 5.758739471435547 sec\n",
            "\n",
            "Epoch 832 Batch 0 Loss 0.1790\n",
            "Epoch 832 Loss 0.192954\n",
            "Time taken for 1 epoch 5.773247957229614 sec\n",
            "\n",
            "Epoch 833 Batch 0 Loss 0.1794\n",
            "Epoch 833 Loss 0.193291\n",
            "Time taken for 1 epoch 5.720120906829834 sec\n",
            "\n",
            "Epoch 834 Batch 0 Loss 0.1791\n",
            "Epoch 834 Loss 0.194042\n",
            "Time taken for 1 epoch 5.693660736083984 sec\n",
            "\n",
            "Epoch 835 Batch 0 Loss 0.1807\n",
            "Epoch 835 Loss 0.193755\n",
            "Time taken for 1 epoch 5.746190071105957 sec\n",
            "\n",
            "Epoch 836 Batch 0 Loss 0.1821\n",
            "Epoch 836 Loss 0.195105\n",
            "Time taken for 1 epoch 5.945094108581543 sec\n",
            "\n",
            "Epoch 837 Batch 0 Loss 0.1794\n",
            "Epoch 837 Loss 0.194129\n",
            "Time taken for 1 epoch 7.036476135253906 sec\n",
            "\n",
            "Epoch 838 Batch 0 Loss 0.1802\n",
            "Epoch 838 Loss 0.193296\n",
            "Time taken for 1 epoch 7.178584814071655 sec\n",
            "\n",
            "Epoch 839 Batch 0 Loss 0.1797\n",
            "Epoch 839 Loss 0.193798\n",
            "Time taken for 1 epoch 6.361203670501709 sec\n",
            "\n",
            "Epoch 840 Batch 0 Loss 0.1786\n",
            "Epoch 840 Loss 0.193643\n",
            "Time taken for 1 epoch 5.649669647216797 sec\n",
            "\n",
            "Epoch 841 Batch 0 Loss 0.1781\n",
            "Epoch 841 Loss 0.193854\n",
            "Time taken for 1 epoch 5.637051820755005 sec\n",
            "\n",
            "Epoch 842 Batch 0 Loss 0.1788\n",
            "Epoch 842 Loss 0.194236\n",
            "Time taken for 1 epoch 5.732243537902832 sec\n",
            "\n",
            "Epoch 843 Batch 0 Loss 0.1793\n",
            "Epoch 843 Loss 0.194045\n",
            "Time taken for 1 epoch 5.688537359237671 sec\n",
            "\n",
            "Epoch 844 Batch 0 Loss 0.1800\n",
            "Epoch 844 Loss 0.194288\n",
            "Time taken for 1 epoch 6.395705461502075 sec\n",
            "\n",
            "Epoch 845 Batch 0 Loss 0.1792\n",
            "Epoch 845 Loss 0.193499\n",
            "Time taken for 1 epoch 6.493678569793701 sec\n",
            "\n",
            "Epoch 846 Batch 0 Loss 0.1822\n",
            "Epoch 846 Loss 0.193092\n",
            "Time taken for 1 epoch 5.674628019332886 sec\n",
            "\n",
            "Epoch 847 Batch 0 Loss 0.1820\n",
            "Epoch 847 Loss 0.193563\n",
            "Time taken for 1 epoch 5.664551496505737 sec\n",
            "\n",
            "Epoch 848 Batch 0 Loss 0.1794\n",
            "Epoch 848 Loss 0.193024\n",
            "Time taken for 1 epoch 5.634433031082153 sec\n",
            "\n",
            "Epoch 849 Batch 0 Loss 0.1791\n",
            "Epoch 849 Loss 0.192548\n",
            "Time taken for 1 epoch 5.660820960998535 sec\n",
            "\n",
            "Epoch 850 Batch 0 Loss 0.1780\n",
            "Epoch 850 Loss 0.192610\n",
            "Time taken for 1 epoch 5.741493225097656 sec\n",
            "\n",
            "Epoch 851 Batch 0 Loss 0.1776\n",
            "Epoch 851 Loss 0.191938\n",
            "Time taken for 1 epoch 5.70064377784729 sec\n",
            "\n",
            "Epoch 852 Batch 0 Loss 0.1788\n",
            "Epoch 852 Loss 0.191599\n",
            "Time taken for 1 epoch 5.736287355422974 sec\n",
            "\n",
            "Epoch 853 Batch 0 Loss 0.1789\n",
            "Epoch 853 Loss 0.192643\n",
            "Time taken for 1 epoch 5.646137237548828 sec\n",
            "\n",
            "Epoch 854 Batch 0 Loss 0.1795\n",
            "Epoch 854 Loss 0.192374\n",
            "Time taken for 1 epoch 5.597353935241699 sec\n",
            "\n",
            "Epoch 855 Batch 0 Loss 0.1802\n",
            "Epoch 855 Loss 0.192766\n",
            "Time taken for 1 epoch 5.609953880310059 sec\n",
            "\n",
            "Epoch 856 Batch 0 Loss 0.1789\n",
            "Epoch 856 Loss 0.192668\n",
            "Time taken for 1 epoch 5.540657997131348 sec\n",
            "\n",
            "Epoch 857 Batch 0 Loss 0.1824\n",
            "Epoch 857 Loss 0.192769\n",
            "Time taken for 1 epoch 5.5307300090789795 sec\n",
            "\n",
            "Epoch 858 Batch 0 Loss 0.1810\n",
            "Epoch 858 Loss 0.193579\n",
            "Time taken for 1 epoch 5.5495216846466064 sec\n",
            "\n",
            "Epoch 859 Batch 0 Loss 0.1783\n",
            "Epoch 859 Loss 0.193338\n",
            "Time taken for 1 epoch 5.562053680419922 sec\n",
            "\n",
            "Epoch 860 Batch 0 Loss 0.1788\n",
            "Epoch 860 Loss 0.192299\n",
            "Time taken for 1 epoch 6.382267951965332 sec\n",
            "\n",
            "Epoch 861 Batch 0 Loss 0.1795\n",
            "Epoch 861 Loss 0.193140\n",
            "Time taken for 1 epoch 5.701018810272217 sec\n",
            "\n",
            "Epoch 862 Batch 0 Loss 0.1777\n",
            "Epoch 862 Loss 0.193240\n",
            "Time taken for 1 epoch 5.649006128311157 sec\n",
            "\n",
            "Epoch 863 Batch 0 Loss 0.1784\n",
            "Epoch 863 Loss 0.193797\n",
            "Time taken for 1 epoch 5.665693044662476 sec\n",
            "\n",
            "Epoch 864 Batch 0 Loss 0.1788\n",
            "Epoch 864 Loss 0.195552\n",
            "Time taken for 1 epoch 5.642535924911499 sec\n",
            "\n",
            "Epoch 865 Batch 0 Loss 0.1815\n",
            "Epoch 865 Loss 0.197116\n",
            "Time taken for 1 epoch 5.722804307937622 sec\n",
            "\n",
            "Epoch 866 Batch 0 Loss 0.1829\n",
            "Epoch 866 Loss 0.198319\n",
            "Time taken for 1 epoch 5.711823225021362 sec\n",
            "\n",
            "Epoch 867 Batch 0 Loss 0.1815\n",
            "Epoch 867 Loss 0.197066\n",
            "Time taken for 1 epoch 5.698296308517456 sec\n",
            "\n",
            "Epoch 868 Batch 0 Loss 0.1811\n",
            "Epoch 868 Loss 0.194904\n",
            "Time taken for 1 epoch 5.714777946472168 sec\n",
            "\n",
            "Epoch 869 Batch 0 Loss 0.1802\n",
            "Epoch 869 Loss 0.194143\n",
            "Time taken for 1 epoch 5.723243236541748 sec\n",
            "\n",
            "Epoch 870 Batch 0 Loss 0.1788\n",
            "Epoch 870 Loss 0.193153\n",
            "Time taken for 1 epoch 5.714231252670288 sec\n",
            "\n",
            "Epoch 871 Batch 0 Loss 0.1804\n",
            "Epoch 871 Loss 0.197027\n",
            "Time taken for 1 epoch 5.664883613586426 sec\n",
            "\n",
            "Epoch 872 Batch 0 Loss 0.2019\n",
            "Epoch 872 Loss 0.204003\n",
            "Time taken for 1 epoch 5.69982385635376 sec\n",
            "\n",
            "Epoch 873 Batch 0 Loss 0.2221\n",
            "Epoch 873 Loss 0.241309\n",
            "Time taken for 1 epoch 5.785681247711182 sec\n",
            "\n",
            "Epoch 874 Batch 0 Loss 0.3004\n",
            "Epoch 874 Loss 0.298132\n",
            "Time taken for 1 epoch 5.714964151382446 sec\n",
            "\n",
            "Epoch 875 Batch 0 Loss 0.3546\n",
            "Epoch 875 Loss 0.456459\n",
            "Time taken for 1 epoch 5.751386880874634 sec\n",
            "\n",
            "Epoch 876 Batch 0 Loss 0.5165\n",
            "Epoch 876 Loss 0.623131\n",
            "Time taken for 1 epoch 5.639867782592773 sec\n",
            "\n",
            "Epoch 877 Batch 0 Loss 0.6156\n",
            "Epoch 877 Loss 0.721205\n",
            "Time taken for 1 epoch 5.637320280075073 sec\n",
            "\n",
            "Epoch 878 Batch 0 Loss 0.6178\n",
            "Epoch 878 Loss 0.669253\n",
            "Time taken for 1 epoch 5.685497760772705 sec\n",
            "\n",
            "Epoch 879 Batch 0 Loss 0.5562\n",
            "Epoch 879 Loss 0.602773\n",
            "Time taken for 1 epoch 5.685305118560791 sec\n",
            "\n",
            "Epoch 880 Batch 0 Loss 0.5044\n",
            "Epoch 880 Loss 0.484911\n",
            "Time taken for 1 epoch 5.660992383956909 sec\n",
            "\n",
            "Epoch 881 Batch 0 Loss 0.4027\n",
            "Epoch 881 Loss 0.369076\n",
            "Time taken for 1 epoch 5.679806470870972 sec\n",
            "\n",
            "Epoch 882 Batch 0 Loss 0.3405\n",
            "Epoch 882 Loss 0.287698\n",
            "Time taken for 1 epoch 5.729650020599365 sec\n",
            "\n",
            "Epoch 883 Batch 0 Loss 0.2467\n",
            "Epoch 883 Loss 0.236389\n",
            "Time taken for 1 epoch 5.6946516036987305 sec\n",
            "\n",
            "Epoch 884 Batch 0 Loss 0.2218\n",
            "Epoch 884 Loss 0.218152\n",
            "Time taken for 1 epoch 5.767451763153076 sec\n",
            "\n",
            "Epoch 885 Batch 0 Loss 0.1958\n",
            "Epoch 885 Loss 0.205750\n",
            "Time taken for 1 epoch 5.714890241622925 sec\n",
            "\n",
            "Epoch 886 Batch 0 Loss 0.1888\n",
            "Epoch 886 Loss 0.198461\n",
            "Time taken for 1 epoch 5.752587080001831 sec\n",
            "\n",
            "Epoch 887 Batch 0 Loss 0.1865\n",
            "Epoch 887 Loss 0.195488\n",
            "Time taken for 1 epoch 5.6509809494018555 sec\n",
            "\n",
            "Epoch 888 Batch 0 Loss 0.1838\n",
            "Epoch 888 Loss 0.193387\n",
            "Time taken for 1 epoch 5.728086948394775 sec\n",
            "\n",
            "Epoch 889 Batch 0 Loss 0.1831\n",
            "Epoch 889 Loss 0.192653\n",
            "Time taken for 1 epoch 5.671005487442017 sec\n",
            "\n",
            "Epoch 890 Batch 0 Loss 0.1819\n",
            "Epoch 890 Loss 0.191943\n",
            "Time taken for 1 epoch 5.736477851867676 sec\n",
            "\n",
            "Epoch 891 Batch 0 Loss 0.1814\n",
            "Epoch 891 Loss 0.191781\n",
            "Time taken for 1 epoch 5.736088037490845 sec\n",
            "\n",
            "Epoch 892 Batch 0 Loss 0.1804\n",
            "Epoch 892 Loss 0.191692\n",
            "Time taken for 1 epoch 5.667757749557495 sec\n",
            "\n",
            "Epoch 893 Batch 0 Loss 0.1805\n",
            "Epoch 893 Loss 0.192234\n",
            "Time taken for 1 epoch 5.654597997665405 sec\n",
            "\n",
            "Epoch 894 Batch 0 Loss 0.1803\n",
            "Epoch 894 Loss 0.192569\n",
            "Time taken for 1 epoch 5.658524513244629 sec\n",
            "\n",
            "Epoch 895 Batch 0 Loss 0.1806\n",
            "Epoch 895 Loss 0.193376\n",
            "Time taken for 1 epoch 5.600893020629883 sec\n",
            "\n",
            "Epoch 896 Batch 0 Loss 0.1802\n",
            "Epoch 896 Loss 0.193448\n",
            "Time taken for 1 epoch 5.594763994216919 sec\n",
            "\n",
            "Epoch 897 Batch 0 Loss 0.1799\n",
            "Epoch 897 Loss 0.193014\n",
            "Time taken for 1 epoch 5.62581205368042 sec\n",
            "\n",
            "Epoch 898 Batch 0 Loss 0.1785\n",
            "Epoch 898 Loss 0.192372\n",
            "Time taken for 1 epoch 5.789591550827026 sec\n",
            "\n",
            "Epoch 899 Batch 0 Loss 0.1789\n",
            "Epoch 899 Loss 0.192168\n",
            "Time taken for 1 epoch 6.737728595733643 sec\n",
            "\n",
            "Epoch 900 Batch 0 Loss 0.1785\n",
            "Epoch 900 Loss 0.192235\n",
            "Time taken for 1 epoch 6.049903392791748 sec\n",
            "\n",
            "Epoch 901 Batch 0 Loss 0.1772\n",
            "Real:\n",
            "<start> a fighter jet is flying at a fast speed <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Predicted:\n",
            "herd of smoke outside demolished at <unk> at coconut table at smoke outside outside outside outside herd of smoke at coconut table outside outside\n",
            "Epoch 901 Loss 0.192823\n",
            "Time taken for 1 epoch 6.273153781890869 sec\n",
            "\n",
            "Epoch 902 Batch 0 Loss 0.1771\n",
            "Epoch 902 Loss 0.192781\n",
            "Time taken for 1 epoch 5.666717529296875 sec\n",
            "\n",
            "Epoch 903 Batch 0 Loss 0.1806\n",
            "Epoch 903 Loss 0.193522\n",
            "Time taken for 1 epoch 5.603259086608887 sec\n",
            "\n",
            "Epoch 904 Batch 0 Loss 0.1829\n",
            "Epoch 904 Loss 0.193608\n",
            "Time taken for 1 epoch 5.624180316925049 sec\n",
            "\n",
            "Epoch 905 Batch 0 Loss 0.1796\n",
            "Epoch 905 Loss 0.192323\n",
            "Time taken for 1 epoch 5.740380525588989 sec\n",
            "\n",
            "Epoch 906 Batch 0 Loss 0.1774\n",
            "Epoch 906 Loss 0.192048\n",
            "Time taken for 1 epoch 5.6045756340026855 sec\n",
            "\n",
            "Epoch 907 Batch 0 Loss 0.1776\n",
            "Epoch 907 Loss 0.192926\n",
            "Time taken for 1 epoch 5.570285081863403 sec\n",
            "\n",
            "Epoch 908 Batch 0 Loss 0.1779\n",
            "Epoch 908 Loss 0.193148\n",
            "Time taken for 1 epoch 5.693544864654541 sec\n",
            "\n",
            "Epoch 909 Batch 0 Loss 0.1798\n",
            "Epoch 909 Loss 0.193957\n",
            "Time taken for 1 epoch 5.656333923339844 sec\n",
            "\n",
            "Epoch 910 Batch 0 Loss 0.1777\n",
            "Epoch 910 Loss 0.194688\n",
            "Time taken for 1 epoch 5.5930399894714355 sec\n",
            "\n",
            "Epoch 911 Batch 0 Loss 0.1796\n",
            "Epoch 911 Loss 0.194181\n",
            "Time taken for 1 epoch 5.738232851028442 sec\n",
            "\n",
            "Epoch 912 Batch 0 Loss 0.1809\n",
            "Epoch 912 Loss 0.193308\n",
            "Time taken for 1 epoch 5.829787969589233 sec\n",
            "\n",
            "Epoch 913 Batch 0 Loss 0.1767\n",
            "Epoch 913 Loss 0.192903\n",
            "Time taken for 1 epoch 6.224215507507324 sec\n",
            "\n",
            "Epoch 914 Batch 0 Loss 0.1800\n",
            "Epoch 914 Loss 0.192623\n",
            "Time taken for 1 epoch 6.295400619506836 sec\n",
            "\n",
            "Epoch 915 Batch 0 Loss 0.1824\n",
            "Epoch 915 Loss 0.193292\n",
            "Time taken for 1 epoch 5.806305646896362 sec\n",
            "\n",
            "Epoch 916 Batch 0 Loss 0.1802\n",
            "Epoch 916 Loss 0.193309\n",
            "Time taken for 1 epoch 5.745500326156616 sec\n",
            "\n",
            "Epoch 917 Batch 0 Loss 0.1786\n",
            "Epoch 917 Loss 0.192277\n",
            "Time taken for 1 epoch 5.676228761672974 sec\n",
            "\n",
            "Epoch 918 Batch 0 Loss 0.1790\n",
            "Epoch 918 Loss 0.192145\n",
            "Time taken for 1 epoch 5.626603364944458 sec\n",
            "\n",
            "Epoch 919 Batch 0 Loss 0.1784\n",
            "Epoch 919 Loss 0.191793\n",
            "Time taken for 1 epoch 5.73577094078064 sec\n",
            "\n",
            "Epoch 920 Batch 0 Loss 0.1792\n",
            "Epoch 920 Loss 0.191806\n",
            "Time taken for 1 epoch 5.688912868499756 sec\n",
            "\n",
            "Epoch 921 Batch 0 Loss 0.1783\n",
            "Epoch 921 Loss 0.191238\n",
            "Time taken for 1 epoch 5.679798364639282 sec\n",
            "\n",
            "Epoch 922 Batch 0 Loss 0.1777\n",
            "Epoch 922 Loss 0.191071\n",
            "Time taken for 1 epoch 5.737077951431274 sec\n",
            "\n",
            "Epoch 923 Batch 0 Loss 0.1775\n",
            "Epoch 923 Loss 0.191361\n",
            "Time taken for 1 epoch 5.681608200073242 sec\n",
            "\n",
            "Epoch 924 Batch 0 Loss 0.1775\n",
            "Epoch 924 Loss 0.192305\n",
            "Time taken for 1 epoch 5.682080507278442 sec\n",
            "\n",
            "Epoch 925 Batch 0 Loss 0.1780\n",
            "Epoch 925 Loss 0.191570\n",
            "Time taken for 1 epoch 5.7895097732543945 sec\n",
            "\n",
            "Epoch 926 Batch 0 Loss 0.1775\n",
            "Epoch 926 Loss 0.191876\n",
            "Time taken for 1 epoch 5.75124716758728 sec\n",
            "\n",
            "Epoch 927 Batch 0 Loss 0.1773\n",
            "Epoch 927 Loss 0.191835\n",
            "Time taken for 1 epoch 5.671643972396851 sec\n",
            "\n",
            "Epoch 928 Batch 0 Loss 0.1788\n",
            "Epoch 928 Loss 0.193704\n",
            "Time taken for 1 epoch 5.616587162017822 sec\n",
            "\n",
            "Epoch 929 Batch 0 Loss 0.1796\n",
            "Epoch 929 Loss 0.193127\n",
            "Time taken for 1 epoch 5.688802719116211 sec\n",
            "\n",
            "Epoch 930 Batch 0 Loss 0.1802\n",
            "Epoch 930 Loss 0.192315\n",
            "Time taken for 1 epoch 5.646457672119141 sec\n",
            "\n",
            "Epoch 931 Batch 0 Loss 0.1778\n",
            "Epoch 931 Loss 0.192062\n",
            "Time taken for 1 epoch 5.623337030410767 sec\n",
            "\n",
            "Epoch 932 Batch 0 Loss 0.1766\n",
            "Epoch 932 Loss 0.192270\n",
            "Time taken for 1 epoch 5.645497560501099 sec\n",
            "\n",
            "Epoch 933 Batch 0 Loss 0.1778\n",
            "Epoch 933 Loss 0.193573\n",
            "Time taken for 1 epoch 5.62166166305542 sec\n",
            "\n",
            "Epoch 934 Batch 0 Loss 0.1782\n",
            "Epoch 934 Loss 0.192945\n",
            "Time taken for 1 epoch 5.595990896224976 sec\n",
            "\n",
            "Epoch 935 Batch 0 Loss 0.1784\n",
            "Epoch 935 Loss 0.191752\n",
            "Time taken for 1 epoch 5.617721080780029 sec\n",
            "\n",
            "Epoch 936 Batch 0 Loss 0.1778\n",
            "Epoch 936 Loss 0.191472\n",
            "Time taken for 1 epoch 5.723073720932007 sec\n",
            "\n",
            "Epoch 937 Batch 0 Loss 0.1776\n",
            "Epoch 937 Loss 0.191076\n",
            "Time taken for 1 epoch 5.715288400650024 sec\n",
            "\n",
            "Epoch 938 Batch 0 Loss 0.1791\n",
            "Epoch 938 Loss 0.191689\n",
            "Time taken for 1 epoch 5.749695301055908 sec\n",
            "\n",
            "Epoch 939 Batch 0 Loss 0.1779\n",
            "Epoch 939 Loss 0.192069\n",
            "Time taken for 1 epoch 5.619082689285278 sec\n",
            "\n",
            "Epoch 940 Batch 0 Loss 0.1777\n",
            "Epoch 940 Loss 0.191636\n",
            "Time taken for 1 epoch 5.64912486076355 sec\n",
            "\n",
            "Epoch 941 Batch 0 Loss 0.1778\n",
            "Epoch 941 Loss 0.191917\n",
            "Time taken for 1 epoch 5.782388687133789 sec\n",
            "\n",
            "Epoch 942 Batch 0 Loss 0.1774\n",
            "Epoch 942 Loss 0.191675\n",
            "Time taken for 1 epoch 5.795311689376831 sec\n",
            "\n",
            "Epoch 943 Batch 0 Loss 0.1783\n",
            "Epoch 943 Loss 0.191815\n",
            "Time taken for 1 epoch 5.7504801750183105 sec\n",
            "\n",
            "Epoch 944 Batch 0 Loss 0.1781\n",
            "Epoch 944 Loss 0.192218\n",
            "Time taken for 1 epoch 5.654345989227295 sec\n",
            "\n",
            "Epoch 945 Batch 0 Loss 0.1790\n",
            "Epoch 945 Loss 0.191838\n",
            "Time taken for 1 epoch 5.767538547515869 sec\n",
            "\n",
            "Epoch 946 Batch 0 Loss 0.1796\n",
            "Epoch 946 Loss 0.192655\n",
            "Time taken for 1 epoch 5.727120637893677 sec\n",
            "\n",
            "Epoch 947 Batch 0 Loss 0.1772\n",
            "Epoch 947 Loss 0.192089\n",
            "Time taken for 1 epoch 5.810945272445679 sec\n",
            "\n",
            "Epoch 948 Batch 0 Loss 0.1773\n",
            "Epoch 948 Loss 0.191069\n",
            "Time taken for 1 epoch 5.707387208938599 sec\n",
            "\n",
            "Epoch 949 Batch 0 Loss 0.1775\n",
            "Epoch 949 Loss 0.191000\n",
            "Time taken for 1 epoch 5.709704160690308 sec\n",
            "\n",
            "Epoch 950 Batch 0 Loss 0.1775\n",
            "Epoch 950 Loss 0.190646\n",
            "Time taken for 1 epoch 5.788368225097656 sec\n",
            "\n",
            "Epoch 951 Batch 0 Loss 0.1786\n",
            "Epoch 951 Loss 0.190932\n",
            "Time taken for 1 epoch 5.7741875648498535 sec\n",
            "\n",
            "Epoch 952 Batch 0 Loss 0.1770\n",
            "Epoch 952 Loss 0.190651\n",
            "Time taken for 1 epoch 5.727296829223633 sec\n",
            "\n",
            "Epoch 953 Batch 0 Loss 0.1777\n",
            "Epoch 953 Loss 0.190388\n",
            "Time taken for 1 epoch 6.738735914230347 sec\n",
            "\n",
            "Epoch 954 Batch 0 Loss 0.1777\n",
            "Epoch 954 Loss 0.191069\n",
            "Time taken for 1 epoch 6.244329929351807 sec\n",
            "\n",
            "Epoch 955 Batch 0 Loss 0.1772\n",
            "Epoch 955 Loss 0.191626\n",
            "Time taken for 1 epoch 5.701534986495972 sec\n",
            "\n",
            "Epoch 956 Batch 0 Loss 0.1790\n",
            "Epoch 956 Loss 0.192250\n",
            "Time taken for 1 epoch 5.735869407653809 sec\n",
            "\n",
            "Epoch 957 Batch 0 Loss 0.1780\n",
            "Epoch 957 Loss 0.192130\n",
            "Time taken for 1 epoch 5.735998868942261 sec\n",
            "\n",
            "Epoch 958 Batch 0 Loss 0.1777\n",
            "Epoch 958 Loss 0.191442\n",
            "Time taken for 1 epoch 5.6759092807769775 sec\n",
            "\n",
            "Epoch 959 Batch 0 Loss 0.1776\n",
            "Epoch 959 Loss 0.191834\n",
            "Time taken for 1 epoch 5.741896629333496 sec\n",
            "\n",
            "Epoch 960 Batch 0 Loss 0.1763\n",
            "Epoch 960 Loss 0.192001\n",
            "Time taken for 1 epoch 5.657249450683594 sec\n",
            "\n",
            "Epoch 961 Batch 0 Loss 0.1783\n",
            "Epoch 961 Loss 0.191868\n",
            "Time taken for 1 epoch 5.597286939620972 sec\n",
            "\n",
            "Epoch 962 Batch 0 Loss 0.1800\n",
            "Epoch 962 Loss 0.192402\n",
            "Time taken for 1 epoch 5.675909996032715 sec\n",
            "\n",
            "Epoch 963 Batch 0 Loss 0.1803\n",
            "Epoch 963 Loss 0.192130\n",
            "Time taken for 1 epoch 5.692084550857544 sec\n",
            "\n",
            "Epoch 964 Batch 0 Loss 0.1807\n",
            "Epoch 964 Loss 0.192104\n",
            "Time taken for 1 epoch 5.719169855117798 sec\n",
            "\n",
            "Epoch 965 Batch 0 Loss 0.1783\n",
            "Epoch 965 Loss 0.191868\n",
            "Time taken for 1 epoch 5.692867755889893 sec\n",
            "\n",
            "Epoch 966 Batch 0 Loss 0.1797\n",
            "Epoch 966 Loss 0.191426\n",
            "Time taken for 1 epoch 5.740937232971191 sec\n",
            "\n",
            "Epoch 967 Batch 0 Loss 0.1798\n",
            "Epoch 967 Loss 0.191202\n",
            "Time taken for 1 epoch 6.601819276809692 sec\n",
            "\n",
            "Epoch 968 Batch 0 Loss 0.1787\n",
            "Epoch 968 Loss 0.190838\n",
            "Time taken for 1 epoch 5.64658784866333 sec\n",
            "\n",
            "Epoch 969 Batch 0 Loss 0.1780\n",
            "Epoch 969 Loss 0.191015\n",
            "Time taken for 1 epoch 5.6923909187316895 sec\n",
            "\n",
            "Epoch 970 Batch 0 Loss 0.1769\n",
            "Epoch 970 Loss 0.191406\n",
            "Time taken for 1 epoch 5.786348342895508 sec\n",
            "\n",
            "Epoch 971 Batch 0 Loss 0.1774\n",
            "Epoch 971 Loss 0.191745\n",
            "Time taken for 1 epoch 5.7981061935424805 sec\n",
            "\n",
            "Epoch 972 Batch 0 Loss 0.1781\n",
            "Epoch 972 Loss 0.191816\n",
            "Time taken for 1 epoch 5.7225260734558105 sec\n",
            "\n",
            "Epoch 973 Batch 0 Loss 0.1779\n",
            "Epoch 973 Loss 0.190965\n",
            "Time taken for 1 epoch 5.784064531326294 sec\n",
            "\n",
            "Epoch 974 Batch 0 Loss 0.1781\n",
            "Epoch 974 Loss 0.191081\n",
            "Time taken for 1 epoch 5.8561928272247314 sec\n",
            "\n",
            "Epoch 975 Batch 0 Loss 0.1769\n",
            "Epoch 975 Loss 0.191408\n",
            "Time taken for 1 epoch 5.695729732513428 sec\n",
            "\n",
            "Epoch 976 Batch 0 Loss 0.1782\n",
            "Epoch 976 Loss 0.190959\n",
            "Time taken for 1 epoch 5.635786533355713 sec\n",
            "\n",
            "Epoch 977 Batch 0 Loss 0.1790\n",
            "Epoch 977 Loss 0.191164\n",
            "Time taken for 1 epoch 5.703254222869873 sec\n",
            "\n",
            "Epoch 978 Batch 0 Loss 0.1782\n",
            "Epoch 978 Loss 0.191087\n",
            "Time taken for 1 epoch 5.672164440155029 sec\n",
            "\n",
            "Epoch 979 Batch 0 Loss 0.1785\n",
            "Epoch 979 Loss 0.192123\n",
            "Time taken for 1 epoch 5.696247339248657 sec\n",
            "\n",
            "Epoch 980 Batch 0 Loss 0.1771\n",
            "Epoch 980 Loss 0.191836\n",
            "Time taken for 1 epoch 5.665875673294067 sec\n",
            "\n",
            "Epoch 981 Batch 0 Loss 0.1782\n",
            "Epoch 981 Loss 0.191563\n",
            "Time taken for 1 epoch 5.644546985626221 sec\n",
            "\n",
            "Epoch 982 Batch 0 Loss 0.1786\n",
            "Epoch 982 Loss 0.191535\n",
            "Time taken for 1 epoch 5.600595235824585 sec\n",
            "\n",
            "Epoch 983 Batch 0 Loss 0.1778\n",
            "Epoch 983 Loss 0.191611\n",
            "Time taken for 1 epoch 5.573266983032227 sec\n",
            "\n",
            "Epoch 984 Batch 0 Loss 0.1771\n",
            "Epoch 984 Loss 0.191412\n",
            "Time taken for 1 epoch 5.762192964553833 sec\n",
            "\n",
            "Epoch 985 Batch 0 Loss 0.1763\n",
            "Epoch 985 Loss 0.192296\n",
            "Time taken for 1 epoch 5.6482994556427 sec\n",
            "\n",
            "Epoch 986 Batch 0 Loss 0.1787\n",
            "Epoch 986 Loss 0.192465\n",
            "Time taken for 1 epoch 5.663962125778198 sec\n",
            "\n",
            "Epoch 987 Batch 0 Loss 0.1796\n",
            "Epoch 987 Loss 0.192869\n",
            "Time taken for 1 epoch 5.689078092575073 sec\n",
            "\n",
            "Epoch 988 Batch 0 Loss 0.1785\n",
            "Epoch 988 Loss 0.193697\n",
            "Time taken for 1 epoch 5.694124937057495 sec\n",
            "\n",
            "Epoch 989 Batch 0 Loss 0.1822\n",
            "Epoch 989 Loss 0.193093\n",
            "Time taken for 1 epoch 5.73987340927124 sec\n",
            "\n",
            "Epoch 990 Batch 0 Loss 0.1841\n",
            "Epoch 990 Loss 0.195008\n",
            "Time taken for 1 epoch 5.813710451126099 sec\n",
            "\n",
            "Epoch 991 Batch 0 Loss 0.1806\n",
            "Epoch 991 Loss 0.194154\n",
            "Time taken for 1 epoch 5.7727296352386475 sec\n",
            "\n",
            "Epoch 992 Batch 0 Loss 0.1809\n",
            "Epoch 992 Loss 0.193259\n",
            "Time taken for 1 epoch 5.771663188934326 sec\n",
            "\n",
            "Epoch 993 Batch 0 Loss 0.1792\n",
            "Epoch 993 Loss 0.193641\n",
            "Time taken for 1 epoch 5.820717096328735 sec\n",
            "\n",
            "Epoch 994 Batch 0 Loss 0.1782\n",
            "Epoch 994 Loss 0.192145\n",
            "Time taken for 1 epoch 5.79634428024292 sec\n",
            "\n",
            "Epoch 995 Batch 0 Loss 0.1792\n",
            "Epoch 995 Loss 0.191505\n",
            "Time taken for 1 epoch 5.75366473197937 sec\n",
            "\n",
            "Epoch 996 Batch 0 Loss 0.1790\n",
            "Epoch 996 Loss 0.191530\n",
            "Time taken for 1 epoch 5.720015048980713 sec\n",
            "\n",
            "Epoch 997 Batch 0 Loss 0.1775\n",
            "Epoch 997 Loss 0.191227\n",
            "Time taken for 1 epoch 5.726749420166016 sec\n",
            "\n",
            "Epoch 998 Batch 0 Loss 0.1781\n",
            "Epoch 998 Loss 0.191883\n",
            "Time taken for 1 epoch 6.392060995101929 sec\n",
            "\n",
            "Epoch 999 Batch 0 Loss 0.1781\n",
            "Epoch 999 Loss 0.192595\n",
            "Time taken for 1 epoch 6.538185358047485 sec\n",
            "\n",
            "Epoch 1000 Batch 0 Loss 0.1798\n",
            "Epoch 1000 Loss 0.192738\n",
            "Time taken for 1 epoch 5.779020547866821 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "076siViLWSZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('gdrive/My Drive/bert_translate/loss_plot', loss_plot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw7gXOkHDYOa",
        "colab_type": "code",
        "outputId": "890861cd-7c64-4142-c146-3668eb20ef35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(loss_plot)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Plot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAhGRgFMQiIgEnIJARCTgFAQiIgH3/wHQ2x6rHZs52QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH0Gi1Ex0khG",
        "colab_type": "text"
      },
      "source": [
        "## Caption!\n",
        "\n",
        "* The evaluate function is similar to the training loop, except you don't use teacher forcing here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "* Stop predicting when the model predicts the end token.\n",
        "* And store the attention weights for every time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJtpIHPAzX4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(word):\n",
        "    hidden = decoder.reset_state(batch_size=1)\n",
        "\n",
        "    word_tensor_val = tf.expand_dims(word, 0)\n",
        "    features = encoder(word_tensor_val)\n",
        "\n",
        "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
        "    result = []\n",
        "\n",
        "    for i in range(max_length):\n",
        "        predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
        "\n",
        "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
        "        result.append(tokenizer.index_word[predicted_id])\n",
        "\n",
        "        if tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF4XoEze0nYm",
        "colab_type": "code",
        "outputId": "3cceab6d-0aed-4c90-bb1e-44f875db161f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# captions on the validation set\n",
        "rid = np.random.randint(0, len(word_train))\n",
        "word = word_train[rid]\n",
        "real_caption = ' '.join([tokenizer.index_word[i] for i in cap_train[rid] if i not in [0]])\n",
        "result = evaluate(word)\n",
        "\n",
        "print ('Real Caption:', real_caption)\n",
        "print ('Prediction Caption:', ' '.join(result))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real Caption: <start> white and yellow propeller stunt plane trailing smoke while climbing steeply <end>\n",
            "Prediction Caption: birds airplane flying alone of birds airplane flying alone of birds airplane flying alone of smoke at sunset at sunset standing close of smoke\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJJTODc6ELSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}